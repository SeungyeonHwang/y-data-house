"""
yt-dlp wrapper with download archive functionality.
"""

import logging
import sys
import time
import os
import warnings
from pathlib import Path
from typing import Dict, List, Optional, Any, Set
import re
import signal
import json
import threading

import yt_dlp
from tqdm import tqdm

from .config import settings
from .converter import CaptionConverter

# multiprocessing ê²½ê³  ì–µì œ
warnings.filterwarnings("ignore", category=UserWarning, module="multiprocessing.resource_tracker")

logger = logging.getLogger(__name__)


class WarningCapturer:
    """yt-dlp ê²½ê³  ë©”ì‹œì§€ë¥¼ í•„í„°ë§í•˜ëŠ” í´ë˜ìŠ¤."""
    
    def __init__(self):
        self.original_stderr = sys.stderr
        self.suppressed_msgs = ["nsig extraction failed", "Some formats may be missing"]
    
    def __enter__(self):
        sys.stderr = self
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        sys.stderr = self.original_stderr
    
    def write(self, data):
        # íŠ¹ì • ê²½ê³  ë©”ì‹œì§€ë¥¼ í•„í„°ë§
        if not any(msg in data for msg in self.suppressed_msgs):
            self.original_stderr.write(data)
    
    def flush(self):
        self.original_stderr.flush()


class VideoDownloader:
    """YouTube ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ í´ë˜ìŠ¤."""
    
    def __init__(self):
        """VideoDownloader ì´ˆê¸°í™”."""
        self._setup_logger()
    
    def _setup_logger(self) -> None:
        """yt-dlp ë¡œê±° ì„¤ì •."""
        class YtDlpLogger:
            def debug(self, msg):
                if settings.detailed_debug:
                    logger.debug(f"[yt-dlp] {msg}")
            
            def warning(self, msg):
                # ë¶ˆí•„ìš”í•œ ê²½ê³  ë¬´ì‹œ
                if not any(x in msg for x in ["nsig extraction failed", "Some formats may be missing", 
                                            "Requested format is not available", "SABR streaming", 
                                            "Some web client https formats have been skipped"]):
                    logger.warning(f"[yt-dlp] {msg}")
            
            def error(self, msg):
                logger.error(f"[yt-dlp] {msg}")
        
        self.yt_dlp_logger = YtDlpLogger()
    
    def get_channel_videos(self, channel_url: str, chunk_size: int = 100) -> List[Dict[str, Any]]:
        """
        ì±„ë„ URLì—ì„œ ì˜ìƒ ëª©ë¡ì„ ì²­í¬ ë‹¨ìœ„ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            channel_url: YouTube ì±„ë„ URL
            chunk_size: ì²­í¬ë‹¹ ì˜ìƒ ìˆ˜ (ê¸°ë³¸: 100ê°œ)
            
        Returns:
            List[Dict[str, Any]]: ì˜ìƒ ì •ë³´ ëª©ë¡
        """
        logger.info("ì±„ë„ ì˜ìƒ ëª©ë¡ ìˆ˜ì§‘ ì¤‘ (ì²­í¬ ë‹¨ìœ„ ì²˜ë¦¬)...")
        
        all_videos = []
        chunk_num = 1
        max_chunks = 10  # ìµœëŒ€ 10ì²­í¬ (1000ê°œ ì˜ìƒ)
        
        while chunk_num <= max_chunks:
            start_idx = (chunk_num - 1) * chunk_size + 1
            end_idx = chunk_num * chunk_size
            
            logger.info(f"ğŸ“¦ ì²­í¬ {chunk_num}: ì˜ìƒ {start_idx}-{end_idx} ì²˜ë¦¬ ì¤‘...")
            
            # ğŸ”¥ ì²­í¬ë³„ yt-dlp ì˜µì…˜
            chunk_opts = {
                'quiet': True,  # ì²­í¬ ì²˜ë¦¬ì‹œ ì¶œë ¥ ì¤„ì´ê¸°
                'verbose': False,
                'extract_flat': True,
                'ignoreerrors': True,
                'no_warnings': True,
                'skip_download': True,
                'logger': self.yt_dlp_logger,
                'http_headers': {
                    'User-Agent': settings.user_agent,
                },
                # ğŸ›¡ï¸ ë´‡ ê°ì§€ íšŒí”¼: ë¸Œë¼ìš°ì € ì¿ í‚¤ ì‚¬ìš©
                'cookiesfrombrowser': (settings.browser, None, None, None) if settings.use_browser_cookies else None,
                # ğŸ”¥ í™˜ê²½ë³€ìˆ˜ì—ì„œ rate limiting ì„¤ì • (ë” ì§§ì€ íƒ€ì„ì•„ì›ƒ)
                'socket_timeout': int(os.getenv('YDH_YTDLP_SOCKET_TIMEOUT', '8')),  # 8ì´ˆë¡œ ë‹¨ì¶•
                'retries': int(os.getenv('YDH_YTDLP_RETRIES', '1')),  # 1íšŒë¡œ ë‹¨ì¶•
                'sleep_interval': int(os.getenv('YDH_YTDLP_SLEEP_INTERVAL', '1')),
                'max_sleep_interval': int(os.getenv('YDH_YTDLP_MAX_SLEEP_INTERVAL', '3')),
                'sleep_interval_requests': int(os.getenv('YDH_YTDLP_SLEEP_REQUESTS', '10')),
                # ğŸ”¥ ì²­í¬ ë²”ìœ„ ì„¤ì •
                'playliststart': start_idx,
                'playlistend': end_idx,
            }
            
            chunk_videos = self._get_chunk_videos(channel_url, chunk_opts, chunk_num)
            
            if not chunk_videos:
                logger.info(f"ğŸ“¦ ì²­í¬ {chunk_num}: ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. ìˆ˜ì§‘ ì™„ë£Œ")
                break
            
            all_videos.extend(chunk_videos)
            logger.info(f"ğŸ“¦ ì²­í¬ {chunk_num}: {len(chunk_videos)}ê°œ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ")
            
            # ë§ˆì§€ë§‰ ì²­í¬ê°€ ê½‰ ì°¨ì§€ ì•Šìœ¼ë©´ ë
            if len(chunk_videos) < chunk_size:
                logger.info(f"ğŸ“¦ ë§ˆì§€ë§‰ ì²­í¬ ê°ì§€. ì´ {len(all_videos)}ê°œ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ")
                break
                
            chunk_num += 1
            
            # ì²­í¬ ê°„ ì§€ì—°
            time.sleep(2)
        
        logger.info(f"âœ… ì „ì²´ ìˆ˜ì§‘ ì™„ë£Œ: {len(all_videos)}ê°œ ì˜ìƒ")
        return all_videos
    
    def check_for_new_videos_fast(self, channel_url: str, channel_name: str, check_count: int = 20) -> Dict[str, Any]:
        """
        ğŸš€ OPTIMIZED: ì±„ë„ì— ì‹ ê·œ ì˜ìƒì´ ìˆëŠ”ì§€ ë¹ ë¥´ê²Œ í™•ì¸í•©ë‹ˆë‹¤.
        
        Args:
            channel_url: YouTube ì±„ë„ URL
            channel_name: ì±„ë„ ì´ë¦„ (ì•„ì¹´ì´ë¸Œ íŒŒì¼ìš©)
            check_count: í™•ì¸í•  ìµœì‹  ì˜ìƒ ìˆ˜ (ê¸°ë³¸: 20ê°œ)
            
        Returns:
            Dict[str, Any]: {
                'has_new_videos': bool,
                'new_video_count': int,
                'latest_videos': List[Dict],
                'total_checked': int
            }
        """
        logger.info(f"ğŸ” ì‹ ê·œ ì˜ìƒ ë¹ ë¥¸ í™•ì¸ ì¤‘... (ìµœì‹  {check_count}ê°œ ì˜ìƒ ì²´í¬)")
        start_time = time.time()
        
        # ê¸°ì¡´ ë‹¤ìš´ë¡œë“œ ì•„ì¹´ì´ë¸Œ ë¡œë“œ
        downloaded_ids = self._load_downloaded_archive(channel_name)
        logger.info(f"ğŸ“‹ ê¸°ì¡´ ë‹¤ìš´ë¡œë“œ: {len(downloaded_ids)}ê°œ ì˜ìƒ")
        
        # downloads í´ë”ì˜ ì§„í–‰ì¤‘ì¸ ì˜ìƒ í™•ì¸
        downloading_ids = self._check_downloads_folder(channel_name)
        
        # ì „ì²´ ì œì™¸í•  ì˜ìƒ ID ëª©ë¡ (ì•„ì¹´ì´ë¸Œ + ì§„í–‰ì¤‘)
        all_excluded_ids = downloaded_ids | downloading_ids
        
        # ìµœì‹  ì˜ìƒë§Œ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜¤ê¸°
        latest_videos = self._get_latest_videos_only(channel_url, check_count)
        
        if not latest_videos:
            logger.warning("âš ï¸ ìµœì‹  ì˜ìƒ ëª©ë¡ì„ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return {
                'has_new_videos': False,
                'new_video_count': 0,
                'latest_videos': [],
                'total_checked': 0
            }
        
        # ì‹ ê·œ ì˜ìƒ í•„í„°ë§ (ì•„ì¹´ì´ë¸Œ + ì§„í–‰ì¤‘ ì˜ìƒ ëª¨ë‘ ì œì™¸)
        new_videos = [v for v in latest_videos if v.get('id') not in all_excluded_ids]
        
        elapsed = time.time() - start_time
        logger.info(f"âš¡ ë¹ ë¥¸ í™•ì¸ ì™„ë£Œ: {len(latest_videos)}ê°œ í™•ì¸, {len(new_videos)}ê°œ ì‹ ê·œ ({elapsed:.1f}ì´ˆ)")
        
        return {
            'has_new_videos': len(new_videos) > 0,
            'new_video_count': len(new_videos),
            'latest_videos': new_videos,
            'total_checked': len(latest_videos)
        }
    
    def _get_latest_videos_only(self, channel_url: str, count: int = 20) -> List[Dict[str, Any]]:
        """
        ì±„ë„ì˜ ìµœì‹  ì˜ìƒë§Œ ë¹ ë¥´ê²Œ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            channel_url: YouTube ì±„ë„ URL
            count: ê°€ì ¸ì˜¬ ìµœì‹  ì˜ìƒ ìˆ˜
            
        Returns:
            List[Dict[str, Any]]: ìµœì‹  ì˜ìƒ ëª©ë¡
        """
        # ğŸ”¥ ìµœì í™”ëœ yt-dlp ì˜µì…˜ (ìµœì†Œí•œì˜ ë°ì´í„°ë§Œ)
        opts = {
            'quiet': True,
            'verbose': False,
            'extract_flat': True,
            'ignoreerrors': True,
            'no_warnings': True,
            'skip_download': True,
            'logger': self.yt_dlp_logger,
            'http_headers': {
                'User-Agent': settings.user_agent,
            },
            # ğŸ›¡ï¸ ë´‡ ê°ì§€ íšŒí”¼
            'cookiesfrombrowser': (settings.browser, None, None, None) if settings.use_browser_cookies else None,
            # ğŸ”¥ íƒ€ì„ì•„ì›ƒ 60ì´ˆë¡œ ì¦ê°€
            'socket_timeout': 60,  # 60ì´ˆë¡œ ì¦ê°€
            'retries': int(os.getenv('YDH_YTDLP_RETRIES', '1')),  # 1íšŒë§Œ
            'sleep_interval': int(os.getenv('YDH_YTDLP_SLEEP_INTERVAL', '0')),  # ì§€ì—° ìµœì†Œí™”
            'max_sleep_interval': int(os.getenv('YDH_YTDLP_MAX_SLEEP_INTERVAL', '1')),
            'sleep_interval_requests': int(os.getenv('YDH_YTDLP_SLEEP_REQUESTS', '5')),
            # ğŸ”¥ í•µì‹¬: ìµœì‹  ì˜ìƒë§Œ ê°€ì ¸ì˜¤ê¸°
            'playliststart': 1,
            'playlistend': count,
            # ğŸ”¥ ì¸ì¦ ì²´í¬ ìŠ¤í‚µ ê°•í™”
            'extractor_args': {
                'youtube': {
                    'skip': ['webpage'],
                    'player_client': ['android'],
                },
                'youtubetab': {
                    'skip': ['webpage', 'authcheck'],  # authcheck ìŠ¤í‚µ
                    'approximate_date': False,  # ì •í™•í•œ ë‚ ì§œ ìŠ¤í‚µ
                }
            }
        }
        
        try:
            # URL ì „ì²˜ë¦¬
            import urllib.parse
            decoded_url = urllib.parse.unquote(channel_url)
            videos_url = decoded_url
            
            if '@' in decoded_url and not decoded_url.endswith('/videos'):
                videos_url = f"{decoded_url}/videos"
            elif ('/c/' in decoded_url or '/channel/' in decoded_url) and not decoded_url.endswith('/videos'):
                videos_url = f"{decoded_url}/videos"
            
            logger.info(f"ğŸŒ ìµœì‹  ì˜ìƒ ìˆ˜ì§‘ ì¤‘... URL: {videos_url}")
            
            with yt_dlp.YoutubeDL(opts) as ydl:
                result = ydl.extract_info(videos_url, download=False)
                
            if not result or 'entries' not in result:
                # Fallback: videos URL ì‹¤íŒ¨ì‹œ ì›ë³¸ URL ì‹œë„
                logger.warning("videos URL ì‹¤íŒ¨, ì›ë³¸ URLë¡œ ì¬ì‹œë„...")
                fallback_url = channel_url if videos_url != channel_url else channel_url.replace('/videos', '')
                with yt_dlp.YoutubeDL(opts) as ydl:
                    result = ydl.extract_info(fallback_url, download=False)
                    
                if not result or 'entries' not in result:
                    logger.error("âŒ ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    return []
            
            # ìœ íš¨í•œ ì˜ìƒë§Œ í•„í„°ë§
            videos = [v for v in result['entries'] if v and v.get('id')]
            logger.info(f"âœ… ìµœì‹  {len(videos)}ê°œ ì˜ìƒ ìˆ˜ì§‘ ì™„ë£Œ")
            return videos
            
        except Exception as e:
            logger.error(f"âŒ ìµœì‹  ì˜ìƒ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
            return []

    def _extract_channel_id(self, channel_url: str) -> Optional[str]:
        """
        ì±„ë„ URLì—ì„œ ì±„ë„ IDë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        
        Args:
            channel_url: YouTube ì±„ë„ URL
            
        Returns:
            Optional[str]: ì¶”ì¶œëœ ì±„ë„ ID (UC...) ë˜ëŠ” None
        """
        try:
            # URL ë””ì½”ë”©
            import urllib.parse
            decoded_url = urllib.parse.unquote(channel_url)
            
            # 1. /channel/UC... í˜•íƒœ
            if '/channel/' in decoded_url:
                channel_id = decoded_url.split('/channel/')[-1].split('/')[0]
                if channel_id.startswith('UC') and len(channel_id) == 24:
                    return channel_id
            
            # 2. @handle í˜•íƒœ - yt-dlpë¡œ ì±„ë„ ID ì¶”ì¶œ
            if '@' in decoded_url:
                return self._get_channel_id_from_handle(decoded_url)
            
            # 3. /c/ ë˜ëŠ” /user/ í˜•íƒœ - yt-dlpë¡œ ì±„ë„ ID ì¶”ì¶œ
            if '/c/' in decoded_url or '/user/' in decoded_url:
                return self._get_channel_id_from_handle(decoded_url)
                
            return None
            
        except Exception as e:
            logger.warning(f"ì±„ë„ ID ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def _get_channel_id_from_handle(self, channel_url: str) -> Optional[str]:
        """
        í•¸ë“¤/ì‚¬ìš©ìëª…ìœ¼ë¡œë¶€í„° ì±„ë„ IDë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        """
        try:
            opts = {
                'quiet': True,
                'no_warnings': True,
                'extract_flat': True,
                'skip_download': True,
                'socket_timeout': 60,  # 60ì´ˆë¡œ ì¦ê°€
                'retries': 1,
                'extractor_args': {
                    'youtube': {
                        'skip': ['webpage'],
                        'player_client': ['android'],
                    },
                    'youtubetab': {
                        'skip': ['webpage', 'authcheck'],
                    }
                }
            }
            
            logger.info(f"ğŸ” ì±„ë„ ID ì¶”ì¶œ ì¤‘: {channel_url}")
            start_time = time.time()
            last_progress_time = start_time
            
            def progress_monitor():
                """5ì´ˆë§ˆë‹¤ ì§„í–‰ìƒí™© ë¡œê·¸ ì¶œë ¥"""
                nonlocal last_progress_time
                while True:
                    time.sleep(5)
                    current_time = time.time()
                    if current_time - last_progress_time > 4:  # 4ì´ˆ ì´ìƒ ì§€ë‚¬ìœ¼ë©´
                        elapsed = current_time - start_time
                        logger.info(f"ğŸ“Š ì±„ë„ ID ì¶”ì¶œ ì§„í–‰ ì¤‘... ({elapsed:.1f}ì´ˆ ê²½ê³¼)")
                        last_progress_time = current_time
                    else:
                        break  # ë©”ì¸ ì‘ì—…ì´ ì™„ë£Œë¨
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ ì‹œì‘
            monitor_thread = threading.Thread(target=progress_monitor, daemon=True)
            monitor_thread.start()
            
            try:
                with yt_dlp.YoutubeDL(opts) as ydl:
                    result = ydl.extract_info(channel_url, download=False)
                
                # ì‘ì—… ì™„ë£Œ - ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨
                last_progress_time = time.time()
                
                # resultê°€ Noneì´ê±°ë‚˜ dictê°€ ì•„ë‹ˆë©´ ì¦‰ì‹œ ë°˜í™˜
                if not result or not isinstance(result, dict):
                    return None
                
                # 1. ì§ì ‘ ID í™•ì¸
                if 'id' in result and result['id']:
                    channel_id = result['id']
                    if isinstance(channel_id, str) and channel_id.startswith('UC') and len(channel_id) == 24:
                        logger.info(f"âœ… ì±„ë„ ID ì¶”ì¶œ ì„±ê³µ: {channel_id}")
                        return channel_id
                        
                # 2. uploader_id í™•ì¸
                if 'uploader_id' in result and result['uploader_id']:
                    uploader_id = result['uploader_id']
                    if isinstance(uploader_id, str) and uploader_id.startswith('UC') and len(uploader_id) == 24:
                        logger.info(f"âœ… ì±„ë„ ID ì¶”ì¶œ ì„±ê³µ (uploader_id): {uploader_id}")
                        return uploader_id
                
                # 3. entriesì—ì„œ ì°¾ê¸° (ë§¤ìš° ì•ˆì „í•˜ê²Œ)
                if 'entries' in result:
                    entries = result['entries']
                    # entriesê°€ ë¦¬ìŠ¤íŠ¸ì¸ì§€ í™•ì¸
                    if isinstance(entries, (list, tuple)):
                        for entry in entries:
                            # entryê°€ dictì´ê³  channel_idê°€ ìˆëŠ”ì§€ í™•ì¸
                            if (isinstance(entry, dict) and 
                                'channel_id' in entry and 
                                entry['channel_id']):
                                
                                channel_id = entry['channel_id']
                                if (isinstance(channel_id, str) and 
                                    channel_id.startswith('UC') and 
                                    len(channel_id) == 24):
                                    logger.info(f"âœ… ì±„ë„ ID ì¶”ì¶œ ì„±ê³µ (entries): {channel_id}")
                                    return channel_id
                
                return None
                
            except Exception as e:
                # ì‘ì—… ì™„ë£Œ (ì—ëŸ¬) - ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨
                last_progress_time = time.time()
                raise e
                
        except Exception as e:
            logger.warning(f"í•¸ë“¤ì—ì„œ ì±„ë„ ID ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None

    def _convert_to_uploads_playlist(self, channel_id: str) -> str:
        """
        ì±„ë„ ID (UC...)ë¥¼ Uploads ì¬ìƒëª©ë¡ ID (UU...)ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
        
        Args:
            channel_id: ì±„ë„ ID (UCë¡œ ì‹œì‘)
            
        Returns:
            str: Uploads ì¬ìƒëª©ë¡ URL
        """
        if not channel_id.startswith('UC') or len(channel_id) != 24:
            raise ValueError(f"ì˜ëª»ëœ ì±„ë„ ID í˜•ì‹: {channel_id}")
        
        # UCë¥¼ UUë¡œ ë³€í™˜
        uploads_playlist_id = 'UU' + channel_id[2:]
        uploads_url = f"https://www.youtube.com/playlist?list={uploads_playlist_id}"
        
        logger.info(f"ğŸ”„ Uploads ì¬ìƒëª©ë¡ ë³€í™˜: {channel_id} â†’ {uploads_playlist_id}")
        return uploads_url

    def _get_chunk_videos(self, channel_url: str, opts: dict, chunk_num: int) -> List[Dict[str, Any]]:
        """
        íŠ¹ì • ì²­í¬ì˜ ì˜ìƒì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
        Uploads ì¬ìƒëª©ë¡ ë°©ì‹ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        try:
            # ì±„ë„ ID ì¶”ì¶œ
            channel_id = self._extract_channel_id(channel_url)
            
            if not channel_id:
                logger.warning(f"ì±„ë„ ID ì¶”ì¶œ ì‹¤íŒ¨: {channel_url}")
                return []
            
            # Uploads ì¬ìƒëª©ë¡ URL ìƒì„±
            uploads_url = self._convert_to_uploads_playlist(channel_id)
            logger.info(f"ğŸŒ ì²­í¬ {chunk_num} ìˆ˜ì§‘ ì¤‘... Uploads URL: {uploads_url}")
            
            # ì˜µì…˜ ì„¤ì • (íƒ€ì„ì•„ì›ƒ ì œê±°)
            enhanced_opts = {
                **opts,
                'extract_flat': 'in_playlist',
                'playlist_items': f"{(chunk_num-1)*100 + 1}-{chunk_num*100}",
                'extractor_retries': 1,
                'skip_unavailable_fragments': True,
                'socket_timeout': 60,  # yt-dlp ë‚´ë¶€ ì†Œì¼“ íƒ€ì„ì•„ì›ƒë§Œ ìœ ì§€ (60ì´ˆ)
                'retries': 1,
                'extractor_args': {
                    'youtube': {
                        'skip': ['webpage'],
                        'player_client': ['android'],
                    },
                    'youtubetab': {
                        'skip': ['webpage', 'authcheck'],
                        'limit': 200,
                    }
                }
            }
            
            logger.info(f"âš¡ íƒ€ì„ì•„ì›ƒ ì œê±°ë¨, í•„ìš”í•œ ë§Œí¼ ëŒ€ê¸°")
            
            start_time = time.time()
            last_progress_time = start_time
            
            # ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ì„ ìœ„í•œ ìŠ¤ë ˆë“œ ì‹œì‘
            def progress_monitor():
                """5ì´ˆë§ˆë‹¤ ì§„í–‰ìƒí™© ë¡œê·¸ ì¶œë ¥"""
                nonlocal last_progress_time
                while True:
                    time.sleep(5)
                    current_time = time.time()
                    if current_time - last_progress_time > 4:  # 4ì´ˆ ì´ìƒ ì§€ë‚¬ìœ¼ë©´
                        elapsed = current_time - start_time
                        logger.info(f"ğŸ“Š ì²­í¬ {chunk_num} ì§„í–‰ ì¤‘... ({elapsed:.1f}ì´ˆ ê²½ê³¼)")
                        last_progress_time = current_time
                    else:
                        break  # ë©”ì¸ ì‘ì—…ì´ ì™„ë£Œë¨
            
            # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ ì‹œì‘
            monitor_thread = threading.Thread(target=progress_monitor, daemon=True)
            monitor_thread.start()
            
            try:
                # ì§ì ‘ ì‹¤í–‰ (ThreadPoolExecutor íƒ€ì„ì•„ì›ƒ ì œê±°)
                with yt_dlp.YoutubeDL(enhanced_opts) as ydl:
                    result = ydl.extract_info(uploads_url, download=False)
                
                # ì‘ì—… ì™„ë£Œ - ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨
                last_progress_time = time.time()
                
                elapsed = time.time() - start_time
                logger.info(f"âš¡ ì¶”ì¶œ ì™„ë£Œ ì‹œê°„: {elapsed:.1f}ì´ˆ")
                
                if result and 'entries' in result:
                    videos = [v for v in result['entries'] if v and v.get('id')]
                    logger.info(f"âœ… ì²­í¬ {chunk_num}: {len(videos)}ê°œ ì˜ìƒ ë°œê²¬")
                    return videos
                else:
                    logger.warning(f"ì²­í¬ {chunk_num}: entries ì—†ìŒ")
                    return []
                    
            except Exception as e:
                # ì‘ì—… ì™„ë£Œ (ì—ëŸ¬) - ì§„í–‰ìƒí™© ëª¨ë‹ˆí„°ë§ ì¤‘ë‹¨
                last_progress_time = time.time()
                raise e
                
        except Exception as e:
            logger.error(f"âŒ ì²­í¬ {chunk_num} ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
            return []

    def get_video_info(self, video_url: str) -> Optional[Dict[str, Any]]:
        """
        ë¹„ë””ì˜¤ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        
        Args:
            video_url: YouTube ë¹„ë””ì˜¤ URL
            
        Returns:
            Optional[Dict[str, Any]]: ë¹„ë””ì˜¤ ì •ë³´
        """
        ydl_opts = {
            'quiet': True,
            'no_warnings': True,
            'logger': self.yt_dlp_logger,
            'http_headers': {
                'User-Agent': settings.user_agent,
            },
            # ğŸ›¡ï¸ ë´‡ ê°ì§€ íšŒí”¼: ë¸Œë¼ìš°ì € ì¿ í‚¤ ì‚¬ìš©
            'cookiesfrombrowser': (settings.browser, None, None, None) if settings.use_browser_cookies else None,
            # ğŸ”¥ í™˜ê²½ë³€ìˆ˜ì—ì„œ rate limiting ë° íƒ€ì„ì•„ì›ƒ ì„¤ì • ì½ê¸°
            'socket_timeout': int(os.getenv('YDH_YTDLP_SOCKET_TIMEOUT', '30')),
            'retries': int(os.getenv('YDH_YTDLP_RETRIES', '2')),
            'sleep_interval': int(os.getenv('YDH_YTDLP_SLEEP_INTERVAL', '1')),
            'max_sleep_interval': int(os.getenv('YDH_YTDLP_MAX_SLEEP_INTERVAL', '3')),
            'sleep_interval_requests': int(os.getenv('YDH_YTDLP_SLEEP_REQUESTS', '10')),
        }
        
        try:
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                return ydl.extract_info(video_url, download=False)
        except Exception as e:
            logger.error(f"ë¹„ë””ì˜¤ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    # ë‚˜ë¨¸ì§€ ë©”ì„œë“œë“¤ì€ ê¸°ì¡´ê³¼ ë™ì¼í•˜ê²Œ ìœ ì§€
    def sanitize_filename(self, name: str) -> str:
        """íŒŒì¼/í´ë” ì´ë¦„ì— ì‚¬ìš©í•  ìˆ˜ ì—†ëŠ” ë¬¸ìë¥¼ '_'ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤."""
        return re.sub(r'[\\/*?:"<>|]', "_", name)
    
    def create_video_folder(self, video_info: Dict[str, Any]) -> Path:
        """ê° ì˜ìƒë³„ í´ë”ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        title = video_info.get('title', 'ì œëª© ì—†ìŒ')
        upload_date = video_info.get('upload_date', '')
        
        # ì œëª©ì—ì„œ í´ë”ëª…ì— ì í•©í•˜ì§€ ì•Šì€ ë¬¸ì ì œê±°
        safe_title = self.sanitize_filename(title)
        
        # ì œëª©ì´ ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ì„œ ì‚¬ìš©
        if len(safe_title) > 50:
            safe_title = safe_title[:50]
        
        # í´ë”ëª… í˜•ì‹: YYYYMMDD_Title
        folder_name = f"{upload_date}_{safe_title}"
        folder_path = settings.download_path / folder_name
        
        # í´ë”ê°€ ì—†ìœ¼ë©´ ìƒì„±
        folder_path.mkdir(parents=True, exist_ok=True)
        
        return folder_path
    
    def download_video(self, video_info: Dict[str, Any], output_folder: Path, channel_name: str = "") -> bool:
        """ê°œë³„ ë¹„ë””ì˜¤ë¥¼ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤."""
        video_id = video_info.get('id', '')
        title = video_info.get('title', 'ì œëª© ì—†ìŒ')
        
        if not video_id:
            logger.error("ë¹„ë””ì˜¤ IDê°€ ì—†ìŠµë‹ˆë‹¤.")
            return False
        
        # í’ˆì§ˆ ì„ íƒ
        format_selector = 'bestvideo[ext=mp4][height<=1080]+bestaudio[ext=m4a]/best[height<=1080]/best'
        if settings.max_quality:
            if settings.max_quality == "480p" or settings.max_quality == "low":
                format_selector = 'bestvideo[ext=mp4][height<=480]+bestaudio[ext=m4a]/best[height<=480]/best'
        
        # yt-dlp ì˜µì…˜ ì„¤ì •
        ydl_opts = {
            'outtmpl': str(output_folder / f'{title}.%(ext)s'),
            'format': format_selector,
            'merge_output_format': 'mp4',
            'logger': self.yt_dlp_logger,
            'ignoreerrors': True,
            'quiet': True,
            'no_warnings': True,
            'http_headers': {
                'User-Agent': settings.user_agent,
            },
            # ğŸ”¥ í™˜ê²½ë³€ìˆ˜ì—ì„œ rate limiting ì„¤ì •
            'socket_timeout': int(os.getenv('YDH_YTDLP_SOCKET_TIMEOUT', '30')),
            'retries': int(os.getenv('YDH_YTDLP_RETRIES', '3')),
            'sleep_interval': int(os.getenv('YDH_YTDLP_SLEEP_INTERVAL', '1')),
            'max_sleep_interval': int(os.getenv('YDH_YTDLP_MAX_SLEEP_INTERVAL', '3')),
            'sleep_interval_requests': int(os.getenv('YDH_YTDLP_SLEEP_REQUESTS', '10')),
            # ğŸ›¡ï¸ ë´‡ ê°ì§€ íšŒí”¼: ë¸Œë¼ìš°ì € ì¿ í‚¤ ì‚¬ìš©
            'cookiesfrombrowser': (settings.browser, None, None, None) if settings.use_browser_cookies else None,
            # ìë§‰ ë‹¤ìš´ë¡œë“œ ì˜µì…˜
            'writesubtitles': True,
            'writeautomaticsub': True,
            'subtitleslangs': settings.subtitle_languages,
            'subtitlesformat': 'vtt',
        }
        
        try:
            video_url = f"https://www.youtube.com/watch?v={video_id}"
            
            with yt_dlp.YoutubeDL(ydl_opts) as ydl:
                error_code = ydl.download([video_url])
                
                if error_code == 0:
                    logger.info(f"ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {title}")
                    self._save_video_metadata(video_info, output_folder)
                    self._add_to_archive(video_id, channel_name)
                    return True
                else:
                    logger.error(f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {title}")
                    return False
                    
        except Exception as e:
            logger.error(f"ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return False
    
    def _save_video_metadata(self, video_info: Dict[str, Any], output_folder: Path) -> None:
        """ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤."""
        try:
            import json
            
            # í•„ìš”í•œ ë©”íƒ€ë°ì´í„°ë§Œ ì¶”ì¶œ
            metadata = {
                'id': video_info.get('id', ''),
                'title': video_info.get('title', ''),
                'upload_date': video_info.get('upload_date', ''),
                'uploader': video_info.get('uploader', ''),
                'duration': video_info.get('duration', 0),
                'view_count': video_info.get('view_count', 0),
                'description': video_info.get('description', ''),
                'webpage_url': video_info.get('webpage_url', ''),
            }
            
            # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì €ì¥
            metadata_file = output_folder / 'metadata.json'
            with open(metadata_file, 'w', encoding='utf-8') as f:
                json.dump(metadata, f, ensure_ascii=False, indent=2)
            
        except Exception as e:
            logger.warning(f"ë©”íƒ€ë°ì´í„° ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_downloaded_archive_path(self, channel_name: str) -> Path:
        """ì±„ë„ë³„ downloaded ì•„ì¹´ì´ë¸Œ íŒŒì¼ ê²½ë¡œë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
        safe_channel_name = re.sub(r'[\\/*?:"<>|]', "_", channel_name)
        return settings.download_path / f"{safe_channel_name}_downloaded.txt"
    
    def _load_downloaded_archive(self, channel_name: str) -> Set[str]:
        """ë‹¤ìš´ë¡œë“œ ì•„ì¹´ì´ë¸Œ íŒŒì¼ì—ì„œ ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ì˜ìƒ ID ëª©ë¡ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
        archive_path = self.get_downloaded_archive_path(channel_name)
        downloaded_ids = set()
        
        if archive_path.exists():
            try:
                with open(archive_path, 'r', encoding='utf-8') as f:
                    for line in f:
                        line = line.strip()
                        if line and line.startswith('youtube '):
                            video_id = line.split(' ', 1)[1]
                            downloaded_ids.add(video_id)
                            
                logger.debug(f"ì•„ì¹´ì´ë¸Œì—ì„œ {len(downloaded_ids)}ê°œ ì˜ìƒ ID ë¡œë“œì™„ë£Œ")
                    
            except Exception as e:
                logger.warning(f"ì•„ì¹´ì´ë¸Œ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}")
        
        return downloaded_ids
    
    def _check_downloads_folder(self, channel_name: str) -> Set[str]:
        """
        downloads í´ë”ì—ì„œ ì´ë¯¸ ë‹¤ìš´ë¡œë“œ ì§„í–‰ì¤‘ì¸ ì˜ìƒ IDë“¤ì„ í™•ì¸í•©ë‹ˆë‹¤.
        
        Args:
            channel_name: ì±„ë„ ì´ë¦„
            
        Returns:
            Set[str]: downloads í´ë”ì— ìˆëŠ” ì˜ìƒ ID ëª©ë¡
        """
        downloading_ids = set()
        
        try:
            # downloads í´ë” í™•ì¸
            if not settings.download_path.exists():
                return downloading_ids
            
            # downloads í´ë”ì˜ ëª¨ë“  í•˜ìœ„ í´ë” í™•ì¸
            for item in settings.download_path.iterdir():
                if item.is_dir():
                    try:
                        # í´ë” ì´ë¦„ì—ì„œ video ID ì¶”ì¶œ ì‹œë„
                        folder_name = item.name
                        
                        # 1. metadata.json íŒŒì¼ì—ì„œ video ID í™•ì¸
                        metadata_file = item / 'metadata.json'
                        if metadata_file.exists():
                            try:
                                import json
                                with open(metadata_file, 'r', encoding='utf-8') as f:
                                    metadata = json.load(f)
                                    video_id = metadata.get('id')
                                    if video_id:
                                        downloading_ids.add(video_id)
                                        continue
                            except Exception:
                                pass
                        
                        # 2. í´ë” ì´ë¦„ì—ì„œ YouTube ID íŒ¨í„´ ì°¾ê¸° (11ìë¦¬ ì˜ìˆ«ì)
                        import re
                        id_pattern = r'[a-zA-Z0-9_-]{11}'
                        matches = re.findall(id_pattern, folder_name)
                        for match in matches:
                            # YouTube video IDëŠ” ë³´í†µ íŠ¹ì • íŒ¨í„´ì„ ê°€ì§€ë¯€ë¡œ ë” ì—„ê²©í•˜ê²Œ ì²´í¬
                            if len(match) == 11 and not match.isdigit():
                                downloading_ids.add(match)
                                break
                        
                        # 3. í´ë” ë‚´ ë¹„ë””ì˜¤ íŒŒì¼ì—ì„œ ID ì¶”ì¶œ
                        for video_file in item.glob("*.mp4"):
                            video_name = video_file.stem
                            matches = re.findall(id_pattern, video_name)
                            for match in matches:
                                if len(match) == 11 and not match.isdigit():
                                    downloading_ids.add(match)
                                    break
                    except Exception as e:
                        logger.debug(f"í´ë” ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {item} - {e}")
                        continue
            
            if downloading_ids:
                logger.info(f"ğŸ“ downloads í´ë”ì—ì„œ {len(downloading_ids)}ê°œ ì§„í–‰ì¤‘ ì˜ìƒ ë°œê²¬")
                logger.debug(f"ì§„í–‰ì¤‘ ì˜ìƒ IDë“¤: {list(downloading_ids)[:5]}...")  # ì²˜ìŒ 5ê°œë§Œ ë¡œê·¸
            
        except Exception as e:
            logger.warning(f"downloads í´ë” í™•ì¸ ì¤‘ ì˜¤ë¥˜: {e}")
        
        return downloading_ids

    def download_channel_videos(self, channel_url: str, channel_name: str = "", full_scan: bool = False) -> Dict[str, int]:
        """
        ğŸš€ 2-STAGE OPTIMIZED: ì±„ë„ì˜ ìƒˆ ì˜ìƒì„ 2ë‹¨ê³„ ë°©ì‹ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤.
        
        Args:
            channel_url: YouTube ì±„ë„ URL
            channel_name: ì±„ë„ ì´ë¦„
            full_scan: Trueë©´ ì „ì²´ ë¬´ê²°ì„± ê²€ì‚¬ ëª¨ë“œ, Falseë©´ ë¹ ë¥¸ í™•ì¸ ëª¨ë“œ (ê¸°ë³¸ê°’)
        
        Returns:
            Dict[str, int]: ë‹¤ìš´ë¡œë“œ í†µê³„
            
        ë‘ ê°€ì§€ ëª¨ë“œ:
        - ë¹ ë¥¸ í™•ì¸ ëª¨ë“œ (ê¸°ë³¸): ìµœì‹  ì˜ìƒë§Œ í™•ì¸í•˜ì—¬ ì‹ ê·œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ
        - ì „ì²´ ê²€ì‚¬ ëª¨ë“œ (--full-scan): ëª¨ë“  ì˜ìƒê³¼ ì•„ì¹´ì´ë¸Œ ë¹„êµí•˜ì—¬ ëˆ„ë½ ì˜ìƒ ë³µêµ¬
        """
        # ë‹¤ìš´ë¡œë“œ ê²½ë¡œ ìƒì„±
        settings.download_path.mkdir(parents=True, exist_ok=True)
        
        # ëª¨ë“œë³„ ë¡œê¹…
        mode_text = "ì „ì²´ ë¬´ê²°ì„± ê²€ì‚¬" if full_scan else "ë¹ ë¥¸ í™•ì¸"
        logger.info(f"ğŸš€ {mode_text} ëª¨ë“œ ì‹œì‘: {channel_url}")
        total_start_time = time.time()
        
        if full_scan:
            # ì „ì²´ ë¬´ê²°ì„± ê²€ì‚¬ ëª¨ë“œ
            return self._full_integrity_scan_and_download(channel_url, channel_name, total_start_time)
        else:
            # ë¹ ë¥¸ í™•ì¸ ëª¨ë“œ (ê¸°ë³¸)
            return self._fast_check_and_download(channel_url, channel_name, total_start_time)
    
    def _fast_check_and_download(self, channel_url: str, channel_name: str, start_time: float) -> Dict[str, int]:
        """ë¹ ë¥¸ í™•ì¸ ëª¨ë“œ: ìµœì‹  ì˜ìƒë§Œ í™•ì¸í•˜ì—¬ ì‹ ê·œ ì˜ìƒ ë‹¤ìš´ë¡œë“œ"""
        logger.info("âš¡ 1ë‹¨ê³„: ë¹ ë¥¸ ì‹ ê·œ ì˜ìƒ í™•ì¸")
        
        # ë¹ ë¥¸ ì‹ ê·œ ì˜ìƒ í™•ì¸
        fast_check = self.check_for_new_videos_fast(channel_url, channel_name)
        
        if not fast_check['has_new_videos']:
            logger.info("âœ… ì‹ ê·œ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. ë‹¤ìš´ë¡œë“œë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.")
            elapsed = time.time() - start_time
            logger.info(f"âš¡ ì´ ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ")
            return {
                "total": fast_check['total_checked'], 
                "downloaded": 0, 
                "skipped": fast_check['total_checked'], 
                "failed": 0
            }
        
        logger.info(f"ğŸ¯ ì‹ ê·œ ì˜ìƒ ê°ì§€: {fast_check['new_video_count']}ê°œ")
        
        # ì‹ ê·œ ì˜ìƒì´ ìˆëŠ” ê²½ìš°, ì¶”ê°€ ìˆ˜ì§‘ ì—¬ë¶€ ê²°ì •
        if fast_check['new_video_count'] >= 15:  # ìµœì‹  20ê°œ ì¤‘ 15ê°œ ì´ìƒì´ ì‹ ê·œë©´ ë” ìˆ˜ì§‘
            logger.info("ğŸ“š ì‹ ê·œ ì˜ìƒì´ ë§ì•„ ì „ì²´ ìŠ¤ìº”ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤...")
            videos = self.get_channel_videos(channel_url)
            
            # ê¸°ì¡´ ë‹¤ìš´ë¡œë“œ ì•„ì¹´ì´ë¸Œì™€ ë¹„êµ
            downloaded_ids = self._load_downloaded_archive(channel_name)
            # downloads í´ë”ì— ìˆëŠ” ì§„í–‰ì¤‘ì¸ ì˜ìƒë“¤ë„ ì œì™¸
            downloading_ids = self._check_downloads_folder(channel_name)
            all_excluded_ids = downloaded_ids | downloading_ids
            
            new_videos = [v for v in videos if v.get('id') not in all_excluded_ids]
            skipped_count = len(videos) - len(new_videos)
            
        else:
            # ìµœì‹  ì˜ìƒë§Œìœ¼ë¡œ ì¶©ë¶„ (fast_checkì—ì„œ ì´ë¯¸ downloads í´ë” ì²´í¬ë¨)
            logger.info("ğŸ“‹ ìµœì‹  ì˜ìƒë§Œìœ¼ë¡œ ë‹¤ìš´ë¡œë“œë¥¼ ì§„í–‰í•©ë‹ˆë‹¤...")
            new_videos = fast_check['latest_videos']
            skipped_count = fast_check['total_checked'] - len(new_videos)
        
        # ì‹¤ì œ ë‹¤ìš´ë¡œë“œ ì§„í–‰
        return self._execute_download(new_videos, skipped_count, start_time, "ë¹ ë¥¸ í™•ì¸", channel_name)
    
    def _full_integrity_scan_and_download(self, channel_url: str, channel_name: str, start_time: float) -> Dict[str, int]:
        """ì „ì²´ ë¬´ê²°ì„± ê²€ì‚¬ ëª¨ë“œ: ëª¨ë“  ì˜ìƒê³¼ ì•„ì¹´ì´ë¸Œë¥¼ ë¹„êµí•˜ì—¬ ëˆ„ë½ ì˜ìƒ ë³µêµ¬"""
        logger.info("ğŸ” ì „ì²´ ë¬´ê²°ì„± ê²€ì‚¬ ëª¨ë“œ")
        logger.warning("â° ì´ ì‘ì—…ì€ ëª‡ ë¶„ì´ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤...")
        
        # 1ë‹¨ê³„: ì „ì²´ ì˜ìƒ ëª©ë¡ ìˆ˜ì§‘
        logger.info("ğŸ“š 1ë‹¨ê³„: ì±„ë„ì˜ ì „ì²´ ì˜ìƒ ëª©ë¡ ìˆ˜ì§‘ ì¤‘...")
        all_videos = self.get_channel_videos(channel_url)
        
        if not all_videos:
            logger.warning("ì±„ë„ì—ì„œ ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            elapsed = time.time() - start_time
            logger.info(f"âš¡ ì´ ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ")
            return {"total": 0, "downloaded": 0, "skipped": 0, "failed": 0}
        
        logger.info(f"ğŸ“Š ì±„ë„ ì „ì²´ ì˜ìƒ: {len(all_videos)}ê°œ")
        
        # 2ë‹¨ê³„: ë¡œì»¬ ì•„ì¹´ì´ë¸Œì™€ ë¹„êµ
        logger.info("ğŸ“‹ 2ë‹¨ê³„: ë¡œì»¬ ì•„ì¹´ì´ë¸Œì™€ ë¹„êµ ì¤‘...")
        downloaded_ids = self._load_downloaded_archive(channel_name)
        logger.info(f"ğŸ“¥ ì´ë¯¸ ë‹¤ìš´ë¡œë“œëœ ì˜ìƒ: {len(downloaded_ids)}ê°œ")
        
        # 3ë‹¨ê³„: downloads í´ë”ì˜ ì§„í–‰ì¤‘ì¸ ì˜ìƒ í™•ì¸
        logger.info("ğŸ“ 3ë‹¨ê³„: downloads í´ë”ì˜ ì§„í–‰ì¤‘ ì˜ìƒ í™•ì¸ ì¤‘...")
        downloading_ids = self._check_downloads_folder(channel_name)
        
        # 4ë‹¨ê³„: ëˆ„ë½ëœ ì˜ìƒ ì‹ë³„ (ì•„ì¹´ì´ë¸Œ + ì§„í–‰ì¤‘ ì˜ìƒ ëª¨ë‘ ì œì™¸)
        all_excluded_ids = downloaded_ids | downloading_ids
        missing_videos = [v for v in all_videos if v.get('id') not in all_excluded_ids]
        skipped_count = len(all_videos) - len(missing_videos)
        
        if downloading_ids:
            logger.info(f"ğŸ”„ downloads í´ë”ì˜ {len(downloading_ids)}ê°œ ì§„í–‰ì¤‘ ì˜ìƒ ê±´ë„ˆëœ€")
        
        if not missing_videos:
            logger.info("âœ… ëˆ„ë½ëœ ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ì˜ìƒì´ ì™„ì „íˆ ë‹¤ìš´ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            elapsed = time.time() - start_time
            logger.info(f"âš¡ ì´ ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ")
            return {
                "total": len(all_videos), 
                "downloaded": 0, 
                "skipped": skipped_count, 
                "failed": 0
            }
        
        logger.info(f"ğŸ” ëˆ„ë½ëœ ì˜ìƒ ë°œê²¬: {len(missing_videos)}ê°œ")
        logger.info("ğŸ“¥ ëˆ„ë½ëœ ì˜ìƒë“¤ì„ ë‹¤ìš´ë¡œë“œí•©ë‹ˆë‹¤...")
        
        # 4ë‹¨ê³„: ëˆ„ë½ëœ ì˜ìƒë“¤ ë‹¤ìš´ë¡œë“œ
        return self._execute_download(missing_videos, skipped_count, start_time, "ë¬´ê²°ì„± ê²€ì‚¬", channel_name)
    
    def _execute_download(self, videos_to_download: List[Dict[str, Any]], skipped_count: int, start_time: float, mode_name: str, channel_name: str = "") -> Dict[str, int]:
        """ì‹¤ì œ ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤í–‰"""
        if not videos_to_download:
            logger.info("ë‹¤ìš´ë¡œë“œí•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤.")
            elapsed = time.time() - start_time
            logger.info(f"âš¡ ì´ ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ")
            return {"total": 0, "downloaded": 0, "skipped": skipped_count, "failed": 0}
        
        logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ëŒ€ìƒ: {len(videos_to_download)}ê°œ ì˜ìƒ")
        
        # ë‹¤ìš´ë¡œë“œ ìˆ˜ ì œí•œ ì ìš© (ë¹ ë¥¸ í™•ì¸ ëª¨ë“œì—ì„œë§Œ)
        if mode_name == "ë¹ ë¥¸ í™•ì¸" and settings.max_downloads_per_run > 0:
            original_count = len(videos_to_download)
            videos_to_download = videos_to_download[:settings.max_downloads_per_run]
            if original_count > len(videos_to_download):
                logger.info(f"ë‹¤ìš´ë¡œë“œ ìˆ˜ ì œí•œ: {original_count}ê°œ ì¤‘ {len(videos_to_download)}ê°œë§Œ ë‹¤ìš´ë¡œë“œ (ìµœì‹  ìˆœ)")
        
        # ë‹¤ìš´ë¡œë“œ í†µê³„ ì´ˆê¸°í™”
        stats = {"total": len(videos_to_download), "downloaded": 0, "skipped": skipped_count, "failed": 0}
        
        # ê°„ë‹¨í•œ ì§„í–‰ë¥  í‘œì‹œ - multiprocessing ì´ìŠˆ ë°©ì§€
        total_videos = len(videos_to_download)
        logger.info(f"ğŸ“¥ {mode_name} ë‹¤ìš´ë¡œë“œ ì‹œì‘: {total_videos}ê°œ ì˜ìƒ")
        
        try:
            with WarningCapturer():
                for idx, video in enumerate(videos_to_download):
                    current_progress = idx + 1
                    progress_percent = (current_progress / total_videos) * 100
                    
                    video_id = video.get('id')
                    if not video_id:
                        logger.warning(f"[{current_progress}/{total_videos}] ({progress_percent:.1f}%) ë¹„ë””ì˜¤ ID ì—†ìŒ")
                        stats["failed"] += 1
                        continue
                    
                    try:
                        # ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                        video_url = f"https://www.youtube.com/watch?v={video_id}"
                        video_info = self.get_video_info(video_url)
                        
                        if not video_info:
                            logger.warning(f"[{current_progress}/{total_videos}] ({progress_percent:.1f}%) ë¹„ë””ì˜¤ ì •ë³´ ì—†ìŒ: {video_id}")
                            stats["failed"] += 1
                            continue
                        
                        video_title = video_info.get('title', 'ì œëª© ì—†ìŒ')
                        logger.info(f"[{current_progress}/{total_videos}] ({progress_percent:.1f}%) ë‹¤ìš´ë¡œë“œ ì¤‘: {video_title}")
                        
                        # ì˜ìƒë³„ í´ë” ìƒì„±
                        folder_path = self.create_video_folder(video_info)
                        
                        # ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë“œ - ì „ë‹¬ë°›ì€ ì±„ë„ ì´ë¦„ ì‚¬ìš©, fallbackìœ¼ë¡œ ì˜ìƒ ì •ë³´ì—ì„œ ì¶”ì¶œ
                        final_channel_name = channel_name or video_info.get('uploader', '') or video_info.get('channel', '')
                        if self.download_video(video_info, folder_path, final_channel_name):
                            stats["downloaded"] += 1
                            logger.info(f"âœ… [{current_progress}/{total_videos}] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {video_title}")
                        else:
                            stats["failed"] += 1
                            logger.error(f"âŒ [{current_progress}/{total_videos}] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {video_title}")
                        
                        # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ì§€ì—°
                        time.sleep(0.5)
                        
                    except Exception as e:
                        logger.error(f"âŒ [{current_progress}/{total_videos}] ì˜ìƒ ì²˜ë¦¬ ì¤‘ ì˜ˆì™¸ ë°œìƒ: {e}")
                        stats["failed"] += 1
            
            # ê²°ê³¼ ìš”ì•½
            elapsed = time.time() - start_time
            logger.info("-" * 50)
            logger.info(f"âœ… {mode_name} ëª¨ë“œ ì™„ë£Œ!")
            logger.info(f"ğŸ“¥ ë‹¤ìš´ë¡œë“œ ì„±ê³µ: {stats['downloaded']}ê°œ")
            logger.info(f"â­ï¸ ê±´ë„ˆë›´ ì˜ìƒ: {stats['skipped']}ê°œ") 
            logger.info(f"âŒ ì‹¤íŒ¨í•œ ì˜ìƒ: {stats['failed']}ê°œ")
            logger.info(f"âš¡ ì´ ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ")
            logger.info(f"ğŸ“‚ ë‹¤ìš´ë¡œë“œ ìœ„ì¹˜: {settings.download_path.absolute()}")
            
            return stats
            
        except Exception as e:
            logger.error(f"ë‹¤ìš´ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            elapsed = time.time() - start_time
            logger.info(f"âš¡ ì´ ì†Œìš”ì‹œê°„: {elapsed:.1f}ì´ˆ")
            return stats
            
        finally:
            # ì§„í–‰ë¥  í‘œì‹œ ì™„ë£Œ
            logger.info(f"ğŸ“Š {mode_name} ëª¨ë“œ ì§„í–‰ë¥  í‘œì‹œ ì™„ë£Œ")
    
    def _add_to_archive(self, video_id: str, channel_name: str) -> None:
        """ë‹¤ìš´ë¡œë“œëœ ì˜ìƒì„ ì•„ì¹´ì´ë¸Œì— ì¶”ê°€í•©ë‹ˆë‹¤."""
        archive_path = self.get_downloaded_archive_path(channel_name)
        with open(archive_path, 'a', encoding='utf-8') as f:
            f.write(f"youtube {video_id}\n")
        logger.debug(f"ì•„ì¹´ì´ë¸Œì— ì˜ìƒ ì¶”ê°€: {video_id}")
    
    def retry_failed_downloads(self, channel_name: str = "") -> Dict[str, int]:
        """ì‹¤íŒ¨í•œ ë‹¤ìš´ë¡œë“œë¥¼ ì¬ì‹œë„í•©ë‹ˆë‹¤."""
        return {"total": 0, "downloaded": 0, "failed": 0}
    
    def cleanup_incomplete_downloads(self) -> int:
        """ë¶ˆì™„ì „í•œ ë‹¤ìš´ë¡œë“œ íŒŒì¼ë“¤ì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
        return 0