# ğŸ¤– Y-Data-House AI ì§ˆë¬¸ ê¸°ëŠ¥ ê³ ë„í™” ê°œë°œ ìš”ì²­ì„œ

## ğŸ¯ í•µì‹¬ ê°€ì¹˜ ì œì•ˆ: **ì™„ì „ ìë™í™”ëœ AI ì–´ì‹œìŠ¤í„´íŠ¸**

### ğŸ’¡ **í”„ë¡¬í”„íŠ¸ ì‘ì„± ë¶ˆí•„ìš” ì‹œìŠ¤í…œ**
ì‚¬ìš©ìê°€ ìˆ˜ë™ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•  í•„ìš”ê°€ **ì „í˜€ ì—†ëŠ”** ì™„ì „ ìë™í™”ëœ AI ì§ˆë¬¸ ì‹œìŠ¤í…œ êµ¬ì¶•ì´ ëª©í‘œì…ë‹ˆë‹¤.

#### ğŸ”„ **ì›Œí¬í”Œë¡œìš°**
1. **ë²¡í„° ì„ë² ë”© ìƒì„±** (ê¸°ì¡´) â†’ `make embed`
2. **ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±** (1íšŒ) â†’ `python auto_prompt.py batch`
3. **ì¦‰ì‹œ ì‚¬ìš©** â†’ ì±„ë„ ì„ íƒ í›„ ë°”ë¡œ AI ì§ˆë¬¸
4. **ì§€ì† í™œìš©** â†’ í•œ ë²ˆ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ë¡œ ê³„ì† ì‚¬ìš©

#### ğŸ¨ **ìë™ ìƒì„±ë˜ëŠ” ìš”ì†Œë“¤**
- **í˜ë¥´ì†Œë‚˜**: "10ë…„ì°¨ ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ì ì „ë¬¸ê°€"
- **í†¤ & ìŠ¤íƒ€ì¼**: "ì¹œê·¼í•˜ì§€ë§Œ ì „ë¬¸ì ì´ê³ , êµ¬ì²´ì  ìˆ˜ì¹˜ ì¤‘ì‹œ"
- **ë‹µë³€ ê·œì¹™**: "ì‹¤ì œ ê²½í—˜ê³¼ ì‚¬ë¡€ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…"
- **ì¶œë ¥ í˜•ì‹**: "ğŸš€ ìš”ì•½ â†’ ğŸ“Š ë°ì´í„° â†’ ğŸ“š ê·¼ê±° â†’ ğŸ“ ì‹¤í–‰ë‹¨ê³„"

## ğŸ“‹ í”„ë¡œì íŠ¸ ê°œìš”
Y-Data-HouseëŠ” YouTube ë¹„ë””ì˜¤ ë‹¤ìš´ë¡œë”ì™€ ì „ì‚¬ ì‹œìŠ¤í…œìœ¼ë¡œ, í˜„ì¬ **ê¸°ë³¸ì ì¸ DeepSeek RAG ì‹œìŠ¤í…œ**ì´ êµ¬í˜„ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ì´ë¥¼ **ì™„ì „ ìë™í™”ëœ ì±„ë„ë³„ ë§ì¶¤í˜• AI ì–´ì‹œìŠ¤í„´íŠ¸**ë¡œ ë°œì „ì‹œì¼œ, ì‚¬ìš©ìê°€ í”„ë¡¬í”„íŠ¸ ì‘ì„± ì—†ì´ë„ ê° ì±„ë„ì˜ íŠ¹ì„±ì— ë§ëŠ” ì „ë¬¸ì ì¸ ë‹µë³€ì„ ë°›ì„ ìˆ˜ ìˆë„ë¡ í•˜ëŠ” ê²ƒì´ ëª©í‘œì…ë‹ˆë‹¤.

## ğŸ¯ í˜„ì¬ ìƒíƒœ ë¶„ì„

### âœ… ì´ë¯¸ êµ¬í˜„ëœ ê¸°ëŠ¥
1. **ë²¡í„° DB êµ¬ì¶• ì™„ë£Œ**: ChromaDB ê¸°ë°˜ ì±„ë„ë³„ ê²©ë¦¬ ì„ë² ë”©
2. **ê¸°ë³¸ RAG ì‹œìŠ¤í…œ**: `vault/90_indices/rag.py`ì— HyDE + Query Rewriting êµ¬í˜„
3. **Tauri ë°±ì—”ë“œ**: `ask_rag` í•¨ìˆ˜ë¡œ Python ìŠ¤í¬ë¦½íŠ¸ í˜¸ì¶œ
4. **React í”„ë¡ íŠ¸ì—”ë“œ**: ê°„ë‹¨í•œ ì§ˆë¬¸-ë‹µë³€ UI êµ¬í˜„
5. **ì±„ë„ë³„ ë°ì´í„° ê´€ë¦¬**: ì±„ë„ëª…ìœ¼ë¡œ ì»¬ë ‰ì…˜ ë¶„ë¦¬ ì €ì¥

### ğŸš¨ í˜„ì¬ ë¬¸ì œì  ë° ê°œì„  í•„ìš”ì‚¬í•­
1. **ìˆ˜ë™ í”„ë¡¬í”„íŠ¸ ì‘ì„±**: ì‚¬ìš©ìê°€ ì§ì ‘ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•´ì•¼ í•¨ âŒ
2. **ì±„ë„ íŠ¹ì„± ë¬´ì‹œ**: ëª¨ë“  ì±„ë„ì— ë™ì¼í•œ ì¼ë°˜ì  í”„ë¡¬í”„íŠ¸ ì‚¬ìš© âŒ
3. **ë‹¨ìˆœí•œ ì§ˆë¬¸-ë‹µë³€**: ì±„ë„ ì„ íƒ ì—†ì´ ì „ì²´ í†µí•© ê²€ìƒ‰ë§Œ ê°€ëŠ¥ âŒ
4. **UI ì œì•½**: ì˜ìƒ ë§í¬ í´ë¦­, íƒ€ì„ìŠ¤íƒ¬í”„ ì´ë™ ë“± ì¸í„°ë™ì…˜ ë¶€ì¡± âŒ

### âœ… **ëª©í‘œ: Zero Manual Prompt Writing**
- **ë²¡í„° ë°ì´í„° ìë™ ë¶„ì„** â†’ ì±„ë„ íŠ¹ì„± íŒŒì•…
- **AI í˜ë¥´ì†Œë‚˜ ìë™ ìƒì„±** â†’ ì „ë¬¸ê°€ ìºë¦­í„° ì„¤ì •
- **í”„ë¡¬í”„íŠ¸ ìë™ ì‘ì„±** â†’ ì‚¬ìš©ì ê°œì… ë¶ˆí•„ìš”
- **1íšŒ ìƒì„± í›„ ì§€ì† ì‚¬ìš©** â†’ ê³„ì† í™œìš© ê°€ëŠ¥

## ğŸ¨ ìš”êµ¬ì‚¬í•­ ëª…ì„¸

### 1. ì±„ë„ë³„ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ êµ¬ì¶• (íŒŒì¼ ê¸°ë°˜)

#### 1.1 í”„ë¡¬í”„íŠ¸ íŒŒì¼ êµ¬ì¡°
```
vault/90_indices/prompts/
â”œâ”€â”€ takaki_takehana/
â”‚   â”œâ”€â”€ prompt_v1.json
â”‚   â”œâ”€â”€ prompt_v2.json
â”‚   â””â”€â”€ active.txt          # í˜„ì¬ í™œì„± ë²„ì „ ë²ˆí˜¸
â”œâ”€â”€ ë„ì¿„ë¶€ë™ì‚°/
â”‚   â”œâ”€â”€ prompt_v1.json
â”‚   â””â”€â”€ active.txt
â””â”€â”€ default/
    â””â”€â”€ prompt_v1.json      # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
```

#### 1.2 í”„ë¡¬í”„íŠ¸ JSON êµ¬ì¡°
```json
{
  "version": 1,
  "channel_name": "takaki_takehana",
  "created_at": "2024-01-15T10:30:00Z",
  "persona": "10ë…„ì°¨ ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ì ì „ë¬¸ê°€ì´ë©° ì‹¤ì „ ê²½í—˜ì´ í’ë¶€í•œ ì»¨ì„¤í„´íŠ¸",
  "tone": "ì¹œê·¼í•˜ì§€ë§Œ ì „ë¬¸ì ì´ê³ , êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ ì‚¬ë¡€ë¥¼ ì¤‘ì‹œí•˜ëŠ” ìŠ¤íƒ€ì¼",
  "system_prompt": "ë‹¹ì‹ ì€ {{channel_name}} ì±„ë„ì„ ëŒ€í‘œí•˜ëŠ” ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ì ì „ë¬¸ AIì…ë‹ˆë‹¤. ì´ ì±„ë„ì˜ ì •ë³´ë§Œì„ í™œìš©í•˜ì—¬ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.",
  "rules": [
    "ë°˜ë“œì‹œ ì´ ì±„ë„ì˜ ì •ë³´ë§Œ í™œìš©í•˜ì—¬ ë‹µë³€",
    "ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡ ê¸ˆì§€, 'ì •ë³´ ë¶€ì¡±' ëª…ì‹œ",
    "ë‹µë³€ êµ¬ì¡°: BLUF â†’ ê·¼ê±° â†’ ì‹¤í–‰ë‹¨ê³„"
  ],
  "output_format": {
    "structure": "ğŸš€ í•µì‹¬ ìš”ì•½ â†’ ğŸ“š ê·¼ê±°/ì¶œì²˜ â†’ ğŸ“ ì‹¤í–‰ ë‹¨ê³„ â†’ ğŸ’¡ í•œì¤„ ìš”ì•½",
    "max_bullets": 5,
    "include_video_links": true
  },
  "examples": [
    {
      "question": "ë„ì¿„ ì›ë£¸ íˆ¬ì ìˆ˜ìµë¥ ì€?",
      "expected_approach": "ì´ ì±„ë„ì˜ ì‹¤ì œ ì‚¬ë¡€ â†’ ì§€ì—­ë³„ ë¹„êµ â†’ ìœ„í—˜ìš”ì†Œ â†’ ì‹¤í–‰ ê°€ì´ë“œ"
    }
  ]
}
```

### 2. ê³ ë„í™”ëœ RAG íŒŒì´í”„ë¼ì¸

#### 2.1 ì±„ë„ë³„ ë²¡í„° ë¶„ì„ ë° ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„± (`vault/90_indices/channel_analyzer.py`)
```python
import chromadb
from collections import Counter
import re
from typing import Dict, List, Tuple

class ChannelAnalyzer:
    def __init__(self, chroma_path: Path):
        self.client = chromadb.PersistentClient(path=str(chroma_path))
    
    def analyze_channel_content(self, channel_name: str) -> Dict:
        """ì±„ë„ ë²¡í„° ë°ì´í„° ë¶„ì„í•˜ì—¬ íŠ¹ì„± ì¶”ì¶œ"""
        collection_name = f"channel_{self._sanitize_name(channel_name)}"
        
        try:
            collection = self.client.get_collection(collection_name)
            data = collection.get(include=['documents', 'metadatas'])
            
            if not data['documents']:
                return {}
            
            # 1. ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ
            keywords = self._extract_keywords(data['documents'])
            
            # 2. ì½˜í…ì¸  íŒ¨í„´ ë¶„ì„
            patterns = self._analyze_content_patterns(data['documents'])
            
            # 3. ì±„ë„ ë©”íƒ€ë°ì´í„° ë¶„ì„
            metadata_insights = self._analyze_metadata(data['metadatas'])
            
            # 4. í†¤ & ìŠ¤íƒ€ì¼ ë¶„ì„
            tone_analysis = self._analyze_tone(data['documents'])
            
            return {
                'channel_name': channel_name,
                'keywords': keywords,
                'content_patterns': patterns,
                'metadata_insights': metadata_insights,
                'tone_analysis': tone_analysis,
                'total_videos': len(data['documents']),
                'analysis_timestamp': datetime.now().isoformat()
            }
            
        except Exception as e:
            print(f"âš ï¸ ì±„ë„ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return {}
    
    def _extract_keywords(self, documents: List[str]) -> Dict[str, int]:
        """ë¬¸ì„œì—ì„œ ì£¼ìš” í‚¤ì›Œë“œ ì¶”ì¶œ"""
        all_text = ' '.join(documents)
        
        # í•œê¸€, ì˜ë¬¸, ìˆ«ì í‚¤ì›Œë“œ ì¶”ì¶œ
        korean_keywords = re.findall(r'[ê°€-í£]{2,}', all_text)
        english_keywords = re.findall(r'[A-Za-z]{3,}', all_text.lower())
        number_patterns = re.findall(r'\d+[ë…„ì›”ì¼%ì–µë§Œì›í‰]', all_text)
        
        # ë¹ˆë„ ê³„ì‚°
        keyword_counts = Counter(korean_keywords + english_keywords + number_patterns)
        
        # ìƒìœ„ 30ê°œ í‚¤ì›Œë“œ ë°˜í™˜
        return dict(keyword_counts.most_common(30))
    
    def _analyze_content_patterns(self, documents: List[str]) -> Dict:
        """ì½˜í…ì¸  íŒ¨í„´ ë¶„ì„"""
        patterns = {
            'investment_terms': 0,
            'location_mentions': 0,
            'numerical_data': 0,
            'experience_sharing': 0,
            'analysis_depth': 'medium'
        }
        
        for doc in documents:
            # íˆ¬ì ê´€ë ¨ ìš©ì–´
            investment_terms = ['íˆ¬ì', 'ìˆ˜ìµë¥ ', 'ë§¤ë§¤', 'ì„ëŒ€', 'ìì‚°', 'í¬íŠ¸í´ë¦¬ì˜¤']
            patterns['investment_terms'] += sum(doc.count(term) for term in investment_terms)
            
            # ì§€ì—­ ì–¸ê¸‰
            locations = ['ë„ì¿„', 'ì˜¤ì‚¬ì¹´', 'êµí† ', 'ìš”ì½”í•˜ë§ˆ', 'ì‹œë¶€ì•¼', 'ì‹ ì£¼ì¿ ']
            patterns['location_mentions'] += sum(doc.count(loc) for loc in locations)
            
            # ìˆ˜ì¹˜ ë°ì´í„°
            patterns['numerical_data'] += len(re.findall(r'\d+[%ì–µë§Œì›í‰ë…„]', doc))
            
            # ê²½í—˜ ê³µìœ  í‘œí˜„
            experience_words = ['ê²½í—˜', 'ì‹¤ì œë¡œ', 'ì§ì ‘', 'í•´ë³´ë‹ˆ', 'ëŠë‚€ì ']
            patterns['experience_sharing'] += sum(doc.count(word) for word in experience_words)
        
        # ë¶„ì„ ê¹Šì´ íŒë‹¨
        if patterns['numerical_data'] > 100 and patterns['investment_terms'] > 50:
            patterns['analysis_depth'] = 'deep'
        elif patterns['numerical_data'] < 20:
            patterns['analysis_depth'] = 'light'
        
        return patterns
    
    def _analyze_metadata(self, metadatas: List[Dict]) -> Dict:
        """ë©”íƒ€ë°ì´í„° ë¶„ì„"""
        insights = {
            'avg_video_length': 0,
            'upload_frequency': 'unknown',
            'popular_topics': [],
            'recent_trends': []
        }
        
        # ë¹„ë””ì˜¤ ê¸¸ì´ í‰ê· 
        durations = [m.get('duration_seconds', 0) for m in metadatas if m.get('duration_seconds')]
        if durations:
            insights['avg_video_length'] = sum(durations) / len(durations)
        
        # ì¸ê¸° í† í”½
        all_topics = []
        for m in metadatas:
            if m.get('topic'):
                all_topics.extend(m['topic'])
        
        topic_counts = Counter(all_topics)
        insights['popular_topics'] = [topic for topic, _ in topic_counts.most_common(5)]
        
        return insights
    
    def _analyze_tone(self, documents: List[str]) -> Dict:
        """í†¤ & ìŠ¤íƒ€ì¼ ë¶„ì„"""
        tone_indicators = {
            'formal': ['ìŠµë‹ˆë‹¤', 'ë©ë‹ˆë‹¤', 'ìˆìŠµë‹ˆë‹¤', 'ê²ƒì…ë‹ˆë‹¤'],
            'casual': ['í•´ìš”', 'ì´ì—ìš”', 'ê±°ì˜ˆìš”', 'ë„¤ìš”'],
            'expert': ['ë¶„ì„', 'ë°ì´í„°', 'ì§€í‘œ', 'ì „ë¬¸ì '],
            'practical': ['ì‹¤ì œ', 'ì§ì ‘', 'ê²½í—˜', 'íŒ', 'ë°©ë²•']
        }
        
        tone_scores = {tone: 0 for tone in tone_indicators.keys()}
        
        for doc in documents:
            for tone, indicators in tone_indicators.items():
                tone_scores[tone] += sum(doc.count(indicator) for indicator in indicators)
        
        # ì£¼ìš” í†¤ ê²°ì •
        primary_tone = max(tone_scores, key=tone_scores.get)
        
        return {
            'primary_tone': primary_tone,
            'tone_scores': tone_scores,
            'style_description': self._generate_style_description(primary_tone, tone_scores)
        }
    
    def _generate_style_description(self, primary_tone: str, tone_scores: Dict) -> str:
        """ìŠ¤íƒ€ì¼ ì„¤ëª… ìƒì„±"""
        style_map = {
            'formal': 'ì •ì¤‘í•˜ê³  ì „ë¬¸ì ì¸ ì–´íˆ¬',
            'casual': 'ì¹œê·¼í•˜ê³  í¸ì•ˆí•œ ëŒ€í™”ì²´',
            'expert': 'ë¶„ì„ì ì´ê³  ë°ì´í„° ì¤‘ì‹¬ì ì¸ ìŠ¤íƒ€ì¼',
            'practical': 'ì‹¤ìš©ì ì´ê³  ê²½í—˜ ì¤‘ì‹¬ì ì¸ ì ‘ê·¼'
        }
        
        return style_map.get(primary_tone, 'ê· í˜•ì¡íŒ ìŠ¤íƒ€ì¼')
    
    def generate_auto_prompt(self, channel_analysis: Dict) -> Dict:
        """ì±„ë„ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        if not channel_analysis:
            return self._get_default_prompt()
        
        channel_name = channel_analysis['channel_name']
        keywords = list(channel_analysis.get('keywords', {}).keys())[:10]
        patterns = channel_analysis.get('content_patterns', {})
        tone_analysis = channel_analysis.get('tone_analysis', {})
        
        # í˜ë¥´ì†Œë‚˜ ìƒì„±
        persona = self._generate_persona(patterns, tone_analysis)
        
        # ì „ë¬¸ ë¶„ì•¼ ê²°ì •
        expertise = self._determine_expertise(keywords, patterns)
        
        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_prompt = f"""ë‹¹ì‹ ì€ {channel_name} ì±„ë„ì„ ëŒ€í‘œí•˜ëŠ” {expertise} ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì´ ì±„ë„ì˜ íŠ¹ì§•:
- ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(keywords[:5])}
- ì½˜í…ì¸  ìŠ¤íƒ€ì¼: {tone_analysis.get('style_description', 'ì „ë¬¸ì ')}
- ë¶„ì„ ê¹Šì´: {patterns.get('analysis_depth', 'medium')}

ë‹¹ì‹ ì˜ ì—­í• ì€ ì´ ì±„ë„ì˜ ì˜ìƒ ë‚´ìš©ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì‚¬ìš©ìì—ê²Œ ì •í™•í•˜ê³  ì‹¤ìš©ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤."""

        # ë‹µë³€ ê·œì¹™ ìƒì„±
        rules = self._generate_rules(patterns, tone_analysis)
        
        # ì¶œë ¥ í˜•ì‹ ê²°ì •
        output_format = self._determine_output_format(patterns)
        
        return {
            "version": 1,
            "channel_name": channel_name,
            "created_at": datetime.now().isoformat(),
            "auto_generated": True,
            "persona": persona,
            "tone": tone_analysis.get('style_description', 'ì „ë¬¸ì ì´ê³  ì‹¤ìš©ì ì¸ ìŠ¤íƒ€ì¼'),
            "system_prompt": system_prompt,
            "rules": rules,
            "output_format": output_format,
            "expertise_keywords": keywords[:10],
            "analysis_metadata": {
                "total_videos": channel_analysis.get('total_videos', 0),
                "analysis_timestamp": channel_analysis.get('analysis_timestamp')
            }
        }
    
    def _generate_persona(self, patterns: Dict, tone_analysis: Dict) -> str:
        """íŒ¨í„´ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ í˜ë¥´ì†Œë‚˜ ìƒì„±"""
        base_persona = "ì „ë¬¸ ì»¨í…ì¸  ë¶„ì„ê°€"
        
        if patterns.get('investment_terms', 0) > 30:
            base_persona = "íˆ¬ì ì „ë¬¸ê°€"
        
        if patterns.get('experience_sharing', 0) > 20:
            base_persona += "ì´ë©° ì‹¤ì „ ê²½í—˜ì´ í’ë¶€í•œ ì»¨ì„¤í„´íŠ¸"
        
        if patterns.get('analysis_depth') == 'deep':
            base_persona += "ì´ë©° ë°ì´í„° ê¸°ë°˜ ë¶„ì„ì„ ì¤‘ì‹œí•˜ëŠ” ì „ë¬¸ê°€"
        
        return base_persona
    
    def _determine_expertise(self, keywords: List[str], patterns: Dict) -> str:
        """í‚¤ì›Œë“œì™€ íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ ì „ë¬¸ ë¶„ì•¼ ê²°ì •"""
        if any(keyword in ['ë¶€ë™ì‚°', 'íˆ¬ì', 'ë§¤ë§¤', 'ì„ëŒ€'] for keyword in keywords):
            return "ë¶€ë™ì‚° íˆ¬ì"
        elif any(keyword in ['ì£¼ì‹', 'í€ë“œ', 'ìì‚°'] for keyword in keywords):
            return "ìì‚° ê´€ë¦¬"
        elif any(keyword in ['ì—¬í–‰', 'ë§›ì§‘', 'ë¬¸í™”'] for keyword in keywords):
            return "ë¼ì´í”„ìŠ¤íƒ€ì¼"
        else:
            return "ì¢…í•© ì •ë³´"
    
    def _generate_rules(self, patterns: Dict, tone_analysis: Dict) -> List[str]:
        """íŒ¨í„´ì— ë”°ë¥¸ ë‹µë³€ ê·œì¹™ ìƒì„±"""
        rules = [
            "ë°˜ë“œì‹œ ì´ ì±„ë„ì˜ ì •ë³´ë§Œ í™œìš©í•˜ì—¬ ë‹µë³€",
            "ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡ ê¸ˆì§€, 'ì •ë³´ ë¶€ì¡±' ëª…ì‹œ"
        ]
        
        if patterns.get('numerical_data', 0) > 50:
            rules.append("êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë°ì´í„°ë¥¼ í¬í•¨í•˜ì—¬ ë‹µë³€")
        
        if patterns.get('experience_sharing', 0) > 15:
            rules.append("ì‹¤ì œ ê²½í—˜ê³¼ ì‚¬ë¡€ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…")
        
        if tone_analysis.get('primary_tone') == 'practical':
            rules.append("ì‹¤í–‰ ê°€ëŠ¥í•œ êµ¬ì²´ì  ë‹¨ê³„ ì œì‹œ")
        
        rules.append("ë‹µë³€ êµ¬ì¡°: í•µì‹¬ ìš”ì•½ â†’ ê·¼ê±° â†’ ì‹¤í–‰ ë‹¨ê³„")
        
        return rules
    
    def _determine_output_format(self, patterns: Dict) -> Dict:
        """íŒ¨í„´ì— ë”°ë¥¸ ì¶œë ¥ í˜•ì‹ ê²°ì •"""
        if patterns.get('analysis_depth') == 'deep':
            return {
                "structure": "ğŸš€ í•µì‹¬ ìš”ì•½ â†’ ğŸ“Š ë°ì´í„° ë¶„ì„ â†’ ğŸ“š ê·¼ê±°/ì¶œì²˜ â†’ ğŸ“ ì‹¤í–‰ ë‹¨ê³„ â†’ ğŸ’¡ í•œì¤„ ìš”ì•½",
                "max_bullets": 7,
                "include_video_links": True
            }
        elif patterns.get('experience_sharing', 0) > 20:
            return {
                "structure": "ğŸš€ í•µì‹¬ ìš”ì•½ â†’ ğŸ’¼ ì‹¤ì œ ê²½í—˜ â†’ ğŸ“š ê·¼ê±°/ì¶œì²˜ â†’ ğŸ“ ì‹¤í–‰ ê°€ì´ë“œ â†’ ğŸ’¡ í•œì¤„ ìš”ì•½",
                "max_bullets": 5,
                "include_video_links": True
            }
        else:
            return {
                "structure": "ğŸš€ í•µì‹¬ ìš”ì•½ â†’ ğŸ“š ê·¼ê±°/ì¶œì²˜ â†’ ğŸ“ ì‹¤í–‰ ë‹¨ê³„ â†’ ğŸ’¡ í•œì¤„ ìš”ì•½",
                "max_bullets": 5,
                "include_video_links": True
            }
    
    def _sanitize_name(self, name: str) -> str:
        """ì±„ë„ëª… ì •ë¦¬"""
        return re.sub(r'[^\wê°€-í£]', '_', name)[:50]
    
    def _get_default_prompt(self) -> Dict:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        return {
            "persona": "YouTube ë¹„ë””ì˜¤ ë‚´ìš© ì „ë¬¸ ë¶„ì„ê°€",
            "tone": "ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ìŠ¤íƒ€ì¼",
            "system_prompt": "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë¹„ë””ì˜¤ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.",
            "rules": ["ë¹„ë””ì˜¤ ë‚´ìš© ê¸°ë°˜ ë‹µë³€", "ì •í™•í•œ ì •ë³´ ì œê³µ", "ì¹œì ˆí•œ í†¤ ìœ ì§€"],
            "output_format": {
                "structure": "ë‹µë³€ â†’ ê·¼ê±° â†’ ìš”ì•½",
                "max_bullets": 3,
                "include_video_links": False
            }
        }
```

#### 2.2 ì±„ë„ë³„ í”„ë¡¬í”„íŠ¸ ë¡œë” (`vault/90_indices/prompt_manager.py`)
```python
import json
from pathlib import Path
from typing import Dict, Optional

class PromptManager:
    def __init__(self, prompts_dir: Path = None, chroma_path: Path = None):
        self.prompts_dir = prompts_dir or Path(__file__).parent / "prompts"
        self.prompts_dir.mkdir(exist_ok=True)
        self.analyzer = ChannelAnalyzer(chroma_path or Path(__file__).parent / "chroma")
    
    def get_channel_prompt(self, channel_name: str) -> Dict:
        """ì±„ë„ë³„ í™œì„± í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
        channel_dir = self.prompts_dir / channel_name
        if not channel_dir.exists():
            return self._get_default_prompt()
        
        # í™œì„± ë²„ì „ í™•ì¸
        active_file = channel_dir / "active.txt"
        if active_file.exists():
            version = int(active_file.read_text().strip())
        else:
            version = 1
        
        # í”„ë¡¬í”„íŠ¸ íŒŒì¼ ë¡œë“œ
        prompt_file = channel_dir / f"prompt_v{version}.json"
        if prompt_file.exists():
            return json.loads(prompt_file.read_text(encoding='utf-8'))
        
        return self._get_default_prompt()
    
    def save_channel_prompt(self, channel_name: str, prompt_data: Dict) -> int:
        """ìƒˆ í”„ë¡¬í”„íŠ¸ ë²„ì „ ì €ì¥"""
        channel_dir = self.prompts_dir / channel_name
        channel_dir.mkdir(exist_ok=True)
        
        # ìƒˆ ë²„ì „ ë²ˆí˜¸ ê³„ì‚°
        existing_versions = [
            int(f.stem.split('_v')[1]) 
            for f in channel_dir.glob("prompt_v*.json")
        ]
        new_version = max(existing_versions, default=0) + 1
        
        # í”„ë¡¬í”„íŠ¸ ì €ì¥
        prompt_data['version'] = new_version
        prompt_data['channel_name'] = channel_name
        prompt_data['created_at'] = datetime.now().isoformat()
        
        prompt_file = channel_dir / f"prompt_v{new_version}.json"
        prompt_file.write_text(
            json.dumps(prompt_data, ensure_ascii=False, indent=2),
            encoding='utf-8'
        )
        
        # í™œì„± ë²„ì „ ì—…ë°ì´íŠ¸
        active_file = channel_dir / "active.txt"
        active_file.write_text(str(new_version))
        
        return new_version
    
    def auto_generate_channel_prompt(self, channel_name: str) -> int:
        """ì±„ë„ ë²¡í„° ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìë™ìœ¼ë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        print(f"ğŸ” {channel_name} ì±„ë„ ë²¡í„° ë°ì´í„° ë¶„ì„ ì¤‘...")
        
        # 1. ì±„ë„ ë²¡í„° ë°ì´í„° ë¶„ì„
        channel_analysis = self.analyzer.analyze_channel_content(channel_name)
        if not channel_analysis:
            print(f"âŒ {channel_name} ì±„ë„ì˜ ë²¡í„° ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return 0
        
        print(f"ğŸ“Š ë¶„ì„ ì™„ë£Œ: {channel_analysis['total_videos']}ê°œ ì˜ìƒ ë¶„ì„")
        print(f"ğŸ”‘ ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(list(channel_analysis['keywords'].keys())[:5])}")
        
        # 2. ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±
        auto_prompt = self.analyzer.generate_auto_prompt(channel_analysis)
        
        # 3. í”„ë¡¬í”„íŠ¸ ì €ì¥
        new_version = self.save_channel_prompt(channel_name, auto_prompt)
        
        print(f"âœ… {channel_name} ì±„ë„ ìë™ í”„ë¡¬í”„íŠ¸ v{new_version} ìƒì„± ì™„ë£Œ!")
        print(f"ğŸ“ í˜ë¥´ì†Œë‚˜: {auto_prompt['persona']}")
        print(f"ğŸ¯ ì „ë¬¸ë¶„ì•¼: {auto_prompt.get('expertise_keywords', [])[:3]}")
        
        return new_version
    
    def get_channel_analysis(self, channel_name: str) -> Dict:
        """ì±„ë„ ë²¡í„° ë°ì´í„° ë¶„ì„ ê²°ê³¼ ë°˜í™˜"""
        return self.analyzer.analyze_channel_content(channel_name)
    
    def list_available_channels_for_analysis(self) -> List[str]:
        """ë¶„ì„ ê°€ëŠ¥í•œ ì±„ë„ ëª©ë¡ ë°˜í™˜"""
        try:
            collections = self.analyzer.client.list_collections()
            channels = []
            
            for collection in collections:
                if collection.name.startswith("channel_"):
                    try:
                        data = collection.get()
                        if data['metadatas'] and len(data['metadatas']) > 0:
                            channel_name = data['metadatas'][0].get('channel', 'Unknown')
                            if channel_name != 'Unknown':
                                channels.append(channel_name)
                    except Exception:
                        continue
            
            return sorted(list(set(channels)))
        except Exception as e:
            print(f"âš ï¸ ì±„ë„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def batch_generate_prompts(self) -> Dict[str, int]:
        """ëª¨ë“  ì±„ë„ì— ëŒ€í•´ ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        channels = self.list_available_channels_for_analysis()
        results = {}
        
        print(f"ğŸš€ {len(channels)}ê°œ ì±„ë„ì— ëŒ€í•´ ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘...")
        
        for channel in channels:
            try:
                version = self.auto_generate_channel_prompt(channel)
                results[channel] = version
                print(f"  âœ… {channel}: v{version}")
            except Exception as e:
                print(f"  âŒ {channel}: ì‹¤íŒ¨ - {e}")
                results[channel] = 0
        
        print(f"ğŸ‰ ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ: {len([v for v in results.values() if v > 0])}ê°œ ì„±ê³µ")
        return results
    
    def _get_default_prompt(self) -> Dict:
        """ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
        return {
            "persona": "YouTube ë¹„ë””ì˜¤ ë‚´ìš© ì „ë¬¸ ë¶„ì„ê°€",
            "tone": "ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ìŠ¤íƒ€ì¼",
            "system_prompt": "ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ëŒ€í•´ ë¹„ë””ì˜¤ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”.",
            "rules": ["ë¹„ë””ì˜¤ ë‚´ìš© ê¸°ë°˜ ë‹µë³€", "ì •í™•í•œ ì •ë³´ ì œê³µ", "ì¹œì ˆí•œ í†¤ ìœ ì§€"],
            "output_format": {
                "structure": "ë‹µë³€ â†’ ê·¼ê±° â†’ ìš”ì•½",
                "max_bullets": 3,
                "include_video_links": false
            }
        }
```

#### 2.3 Multi-Stage Retrieval ê°•í™” (`vault/90_indices/rag.py` ìˆ˜ì •)
```python
class AdvancedChannelRAG(ChannelRAG):
    def __init__(self):
        super().__init__()
        self.prompt_manager = PromptManager()
    
    def enhanced_search(self, query: str, channel_name: str):
        """ë‹¤ë‹¨ê³„ ê²€ìƒ‰ ì‹œìŠ¤í…œ"""
        all_results = []
        
        # 1ë‹¨ê³„: ì›ë³¸ ì§ˆë¬¸
        results_1 = self.channel_search_basic(query, channel_name, n_results=3)
        if results_1:
            all_results.extend(self._format_results(results_1, "ì›ë³¸ì§ˆë¬¸", channel_name))
        
        # 2ë‹¨ê³„: ì±„ë„ íŠ¹í™” HyDE
        channel_prompt = self.prompt_manager.get_channel_prompt(channel_name)
        hyde_doc = self.generate_channel_specific_hyde(query, channel_name, channel_prompt)
        if hyde_doc:
            results_2 = self.channel_search_basic(hyde_doc, channel_name, n_results=3)
            if results_2:
                all_results.extend(self._format_results(results_2, "ì±„ë„íŠ¹í™”HyDE", channel_name))
        
        # 3ë‹¨ê³„: Query Decomposition
        sub_queries = self.decompose_query(query, channel_name, channel_prompt)
        for i, sub_query in enumerate(sub_queries):
            results_3 = self.channel_search_basic(sub_query, channel_name, n_results=2)
            if results_3:
                all_results.extend(self._format_results(results_3, f"ë¶„í•´ì§ˆë¬¸{i+1}", channel_name))
        
        # ì¤‘ë³µ ì œê±° ë° LLM Re-ranking
        unique_results = self._deduplicate_results(all_results)
        if len(unique_results) > 5:
            filtered_results = self._llm_rerank_with_channel_context(
                query, unique_results[:8], channel_name, channel_prompt
            )
        else:
            filtered_results = unique_results
        
        return filtered_results[:5]
    
    def generate_channel_specific_hyde(self, query: str, channel_name: str, channel_prompt: Dict) -> str:
        """ì±„ë„ íŠ¹í™” HyDE ë¬¸ì„œ ìƒì„±"""
        try:
            persona = channel_prompt.get('persona', 'ì „ë¬¸ê°€')
            tone = channel_prompt.get('tone', 'ì „ë¬¸ì ì¸ ìŠ¤íƒ€ì¼')
            
            prompt = f"""ë‹¹ì‹ ì€ {channel_name} ì±„ë„ì˜ {persona}ì…ë‹ˆë‹¤. 
{tone}ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ì™„ë²½í•œ ë‹µë³€ì´ ë‹´ê¸´ 150í† í° ë‚´ì™¸ì˜ ê°€ìƒ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ì§ˆë¬¸: {query}

ì´ ì±„ë„ì˜ ê´€ì ì—ì„œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì§€ì—­ëª…, ì „ëµì´ í¬í•¨ëœ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=150,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
        except Exception as e:
            print(f"âš ï¸ ì±„ë„ íŠ¹í™” HyDE ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def generate_answer_with_channel_prompt(self, query: str, search_results: list, channel_name: str):
        """ì±„ë„ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ í™œìš©í•œ ë‹µë³€ ìƒì„±"""
        if not search_results:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. {channel_name} ì±„ë„ì—ì„œ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì±„ë„ë³„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        channel_prompt = self.prompt_manager.get_channel_prompt(channel_name)
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_parts = []
        for i, result in enumerate(search_results):
            title = result['title']
            content_preview = result['content'][:600]
            context_parts.append(f"[ì˜ìƒ {i+1}] {title}\n{content_preview}")
        
        context = "\n\n".join(context_parts)
        
        # ì±„ë„ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = channel_prompt.get('system_prompt', '').replace('{{channel_name}}', channel_name)
        rules = "\n".join([f"- {rule}" for rule in channel_prompt.get('rules', [])])
        output_format = channel_prompt.get('output_format', {})
        structure = output_format.get('structure', 'ë‹µë³€ â†’ ê·¼ê±° â†’ ìš”ì•½')
        
        final_prompt = f"""{system_prompt}

## ë‹µë³€ ê·œì¹™
{rules}

## ë‹µë³€ êµ¬ì¡°
{structure}

## ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ({channel_name} ì±„ë„)
{context}

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

ìœ„ ê·œì¹™ê³¼ êµ¬ì¡°ì— ë”°ë¼ {channel_name} ì±„ë„ì˜ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        try:
            response = self.client.chat.completions.create(
                model="deepseek-chat",
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": final_prompt}
                ],
                max_tokens=800,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"
```

### 3. í´ë¦­í˜• ì¸í„°ë™í‹°ë¸Œ UI ê°œë°œ

#### 3.1 ì±„ë„ ì„ íƒ UI (React ì»´í¬ë„ŒíŠ¸)
```typescript
// app/src/components/ChannelSelector.tsx
interface ChannelInfo {
  name: string;
  video_count: number;
  description?: string;
  last_updated?: string;
}

interface ChannelSelectorProps {
  onChannelSelect: (channel: string) => void;
  selectedChannel?: string;
}

const ChannelSelector: React.FC<ChannelSelectorProps> = ({ onChannelSelect, selectedChannel }) => {
  const [channels, setChannels] = useState<ChannelInfo[]>([]);
  const [loading, setLoading] = useState(true);

  useEffect(() => {
    loadChannels();
  }, []);

  const loadChannels = async () => {
    try {
      const result = await invoke<ChannelInfo[]>('get_available_channels_for_ai');
      setChannels(result);
    } catch (err) {
      console.error('ì±„ë„ ëª©ë¡ ë¡œë“œ ì‹¤íŒ¨:', err);
    } finally {
      setLoading(false);
    }
  };

  if (loading) return <div className="channel-loading">ì±„ë„ ëª©ë¡ ë¡œë”© ì¤‘...</div>;

  return (
    <div className="channel-selector">
      <h3 className="channel-selector-title">ğŸ¯ ì§ˆë¬¸í•  ì±„ë„ ì„ íƒ</h3>
      <div className="channel-grid">
        {channels.map(channel => (
          <div 
            key={channel.name} 
            className={`channel-card ${selectedChannel === channel.name ? 'selected' : ''}`}
            onClick={() => onChannelSelect(channel.name)}
          >
            <div className="channel-name">{channel.name}</div>
            <div className="channel-stats">{channel.video_count}ê°œ ì˜ìƒ</div>
            {channel.description && (
              <div className="channel-description">{channel.description}</div>
            )}
            {channel.last_updated && (
              <div className="channel-updated">ìµœê·¼ ì—…ë°ì´íŠ¸: {channel.last_updated}</div>
            )}
          </div>
        ))}
      </div>
    </div>
  );
};
```

#### 3.2 AI ë‹µë³€ ì»´í¬ë„ŒíŠ¸ ê°œì„ 
```typescript
// app/src/components/AIAnswer.tsx
interface VideoSource {
  video_id: string;
  title: string;
  timestamp?: number;
  relevance_score: number;
  excerpt: string;
}

interface AIResponse {
  answer: string;
  sources: VideoSource[];
  channel_used: string;
  response_time: number;
}

const AIAnswerComponent: React.FC<{ response: AIResponse }> = ({ response }) => {
  const openVideoAtTimestamp = (videoId: string, timestamp?: number) => {
    const url = `https://youtube.com/watch?v=${videoId}${timestamp ? `&t=${timestamp}s` : ''}`;
    window.open(url, '_blank');
  };

  const formatTimestamp = (seconds?: number) => {
    if (!seconds) return '';
    const minutes = Math.floor(seconds / 60);
    const remainingSeconds = seconds % 60;
    return `${minutes}:${remainingSeconds.toString().padStart(2, '0')}`;
  };

  return (
    <div className="ai-response">
      <div className="response-header">
        <span className="channel-badge">ğŸ“º {response.channel_used}</span>
        <span className="response-time">â±ï¸ {response.response_time.toFixed(1)}ì´ˆ</span>
      </div>
      
      <div className="answer-content">
        <ReactMarkdown>{response.answer}</ReactMarkdown>
      </div>
      
      {response.sources.length > 0 && (
        <div className="sources-section">
          <h4 className="sources-title">ğŸ“š ì°¸ê³  ì˜ìƒ</h4>
          <div className="sources-list">
            {response.sources.map((source, i) => (
              <div 
                key={i} 
                className="source-item"
                onClick={() => openVideoAtTimestamp(source.video_id, source.timestamp)}
              >
                <div className="source-main">
                  <span className="source-title">{source.title}</span>
                  <span className="source-relevance">{(source.relevance_score * 100).toFixed(1)}% ê´€ë ¨</span>
                </div>
                <div className="source-details">
                  {source.timestamp && (
                    <span className="source-timestamp">ğŸ• {formatTimestamp(source.timestamp)}</span>
                  )}
                  <span className="source-excerpt">{source.excerpt.slice(0, 100)}...</span>
                </div>
              </div>
            ))}
          </div>
        </div>
      )}
    </div>
  );
};
```

### 4. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ

#### 4.1 í”„ë¡¬í”„íŠ¸ í¸ì§‘ UI (ìƒˆ íƒ­ ì¶”ê°€)
```typescript
// app/src/components/PromptManager.tsx
const PromptManagerTab: React.FC = () => {
  const [selectedChannel, setSelectedChannel] = useState<string>('');
  const [currentPrompt, setCurrentPrompt] = useState<any>(null);
  const [promptVersions, setPromptVersions] = useState<any[]>([]);
  const [isEditing, setIsEditing] = useState(false);

  const loadChannelPrompt = async (channelName: string) => {
    try {
      const prompt = await invoke<any>('get_channel_prompt', { channelName });
      const versions = await invoke<any[]>('get_prompt_versions', { channelName });
      setCurrentPrompt(prompt);
      setPromptVersions(versions);
      setSelectedChannel(channelName);
    } catch (err) {
      console.error('í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨:', err);
    }
  };

  const savePrompt = async () => {
    if (!selectedChannel || !currentPrompt) return;
    
    try {
      const newVersion = await invoke<number>('save_channel_prompt', {
        channelName: selectedChannel,
        promptData: currentPrompt
      });
      alert(`ìƒˆ ë²„ì „ v${newVersion}ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.`);
      loadChannelPrompt(selectedChannel); // ìƒˆë¡œê³ ì¹¨
    } catch (err) {
      alert(`ì €ì¥ ì‹¤íŒ¨: ${err}`);
    }
  };

  return (
    <div className="prompt-management">
      <div className="prompt-header">
        <h2 className="tab-title">ğŸ“ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬</h2>
        <ChannelSelector onChannelSelect={loadChannelPrompt} selectedChannel={selectedChannel} />
      </div>

      {currentPrompt && (
        <div className="prompt-editor-container">
          <div className="prompt-editor">
            <h3>âœï¸ í”„ë¡¬í”„íŠ¸ í¸ì§‘</h3>
            
            <div className="form-group">
              <label>í˜ë¥´ì†Œë‚˜:</label>
              <input
                type="text"
                value={currentPrompt.persona || ''}
                onChange={(e) => setCurrentPrompt({...currentPrompt, persona: e.target.value})}
                placeholder="ì˜ˆ: 10ë…„ì°¨ ë¶€ë™ì‚° íˆ¬ì ì „ë¬¸ê°€"
              />
            </div>

            <div className="form-group">
              <label>í†¤ & ìŠ¤íƒ€ì¼:</label>
              <input
                type="text"
                value={currentPrompt.tone || ''}
                onChange={(e) => setCurrentPrompt({...currentPrompt, tone: e.target.value})}
                placeholder="ì˜ˆ: ì¹œê·¼í•˜ì§€ë§Œ ì „ë¬¸ì ì¸ ìŠ¤íƒ€ì¼"
              />
            </div>

            <div className="form-group">
              <label>ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸:</label>
              <textarea
                rows={8}
                value={currentPrompt.system_prompt || ''}
                onChange={(e) => setCurrentPrompt({...currentPrompt, system_prompt: e.target.value})}
                placeholder="AIì˜ ì—­í• ê³¼ í–‰ë™ ë°©ì‹ì„ ì •ì˜í•˜ì„¸ìš”..."
              />
            </div>

            <div className="form-group">
              <label>ë‹µë³€ ê·œì¹™:</label>
              <textarea
                rows={4}
                value={currentPrompt.rules?.join('\n') || ''}
                onChange={(e) => setCurrentPrompt({
                  ...currentPrompt, 
                  rules: e.target.value.split('\n').filter(r => r.trim())
                })}
                placeholder="ê° ì¤„ì— í•˜ë‚˜ì”© ê·œì¹™ì„ ì…ë ¥í•˜ì„¸ìš”..."
              />
            </div>

            <div className="prompt-actions">
              <button onClick={savePrompt} className="save-button">
                ğŸ’¾ ìƒˆ ë²„ì „ ì €ì¥
              </button>
              <button onClick={() => setIsEditing(!isEditing)} className="edit-button">
                {isEditing ? 'ğŸ“– ë¯¸ë¦¬ë³´ê¸°' : 'âœï¸ í¸ì§‘ ëª¨ë“œ'}
              </button>
            </div>
          </div>

          <div className="prompt-versions">
            <h3>ğŸ“š ë²„ì „ íˆìŠ¤í† ë¦¬</h3>
            <div className="versions-list">
              {promptVersions.map(version => (
                <div key={version.version} className="version-item">
                  <div className="version-header">
                    <span className="version-number">v{version.version}</span>
                    <span className="version-date">{new Date(version.created_at).toLocaleDateString()}</span>
                  </div>
                  <div className="version-preview">
                    {version.persona.slice(0, 50)}...
                  </div>
                  <button 
                    onClick={() => setCurrentPrompt(version)}
                    className="restore-button"
                  >
                    ğŸ”„ ì´ ë²„ì „ìœ¼ë¡œ ë³µì›
                  </button>
                </div>
              ))}
            </div>
          </div>
        </div>
      )}
    </div>
  );
};
```

### 5. ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„± CLI ë„êµ¬

#### 5.1 CLI ëª…ë ¹ì–´ ì¶”ê°€ (`vault/90_indices/auto_prompt.py`)
```python
#!/usr/bin/env python3
"""
ì±„ë„ë³„ ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„± CLI ë„êµ¬
"""
import sys
from pathlib import Path
from prompt_manager import PromptManager

def main():
    if len(sys.argv) < 2:
        print("ğŸ¤– Y-Data House ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸°")
        print("\nğŸ“‹ ì‚¬ìš©ë²•:")
        print("  python auto_prompt.py list                    # ë¶„ì„ ê°€ëŠ¥í•œ ì±„ë„ ëª©ë¡")
        print("  python auto_prompt.py analyze <ì±„ë„ëª…>        # íŠ¹ì • ì±„ë„ ë¶„ì„")
        print("  python auto_prompt.py generate <ì±„ë„ëª…>       # íŠ¹ì • ì±„ë„ í”„ë¡¬í”„íŠ¸ ìƒì„±")
        print("  python auto_prompt.py batch                   # ëª¨ë“  ì±„ë„ í”„ë¡¬í”„íŠ¸ ìƒì„±")
        return
    
    command = sys.argv[1]
    prompt_manager = PromptManager()
    
    if command == "list":
        # ë¶„ì„ ê°€ëŠ¥í•œ ì±„ë„ ëª©ë¡
        channels = prompt_manager.list_available_channels_for_analysis()
        if channels:
            print(f"ğŸ“º ë¶„ì„ ê°€ëŠ¥í•œ ì±„ë„ ({len(channels)}ê°œ):")
            for i, channel in enumerate(channels, 1):
                print(f"  {i}. {channel}")
        else:
            print("ë¶„ì„ ê°€ëŠ¥í•œ ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤. ë¨¼ì € ë²¡í„° ì„ë² ë”©ì„ ìƒì„±í•˜ì„¸ìš”.")
    
    elif command == "analyze":
        if len(sys.argv) < 3:
            print("âŒ ì±„ë„ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print("ì‚¬ìš©ë²•: python auto_prompt.py analyze <ì±„ë„ëª…>")
            return
        
        channel_name = sys.argv[2]
        analysis = prompt_manager.get_channel_analysis(channel_name)
        
        if analysis:
            print(f"ğŸ“Š {channel_name} ì±„ë„ ë¶„ì„ ê²°ê³¼:")
            print(f"  ğŸ“¹ ì´ ì˜ìƒ ìˆ˜: {analysis['total_videos']}")
            print(f"  ğŸ”‘ ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(list(analysis['keywords'].keys())[:10])}")
            print(f"  ğŸ­ ì£¼ìš” í†¤: {analysis['tone_analysis']['primary_tone']}")
            print(f"  ğŸ“ˆ ë¶„ì„ ê¹Šì´: {analysis['content_patterns']['analysis_depth']}")
            print(f"  ğŸ’¼ íˆ¬ì ìš©ì–´ ë¹ˆë„: {analysis['content_patterns']['investment_terms']}")
            print(f"  ğŸ“ ì§€ì—­ ì–¸ê¸‰ ë¹ˆë„: {analysis['content_patterns']['location_mentions']}")
        else:
            print(f"âŒ {channel_name} ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    elif command == "generate":
        if len(sys.argv) < 3:
            print("âŒ ì±„ë„ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print("ì‚¬ìš©ë²•: python auto_prompt.py generate <ì±„ë„ëª…>")
            return
        
        channel_name = sys.argv[2]
        version = prompt_manager.auto_generate_channel_prompt(channel_name)
        
        if version > 0:
            print(f"âœ… {channel_name} ì±„ë„ ìë™ í”„ë¡¬í”„íŠ¸ v{version} ìƒì„± ì™„ë£Œ!")
        else:
            print(f"âŒ {channel_name} ì±„ë„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨")
    
    elif command == "batch":
        # ëª¨ë“  ì±„ë„ ì¼ê´„ ìƒì„±
        results = prompt_manager.batch_generate_prompts()
        
        success_count = len([v for v in results.values() if v > 0])
        total_count = len(results)
        
        print(f"\nğŸ‰ ì¼ê´„ ìƒì„± ì™„ë£Œ: {success_count}/{total_count} ì„±ê³µ")
        
        if success_count < total_count:
            failed_channels = [ch for ch, v in results.items() if v == 0]
            print(f"âŒ ì‹¤íŒ¨í•œ ì±„ë„: {', '.join(failed_channels)}")
    
    else:
        print(f"âŒ ì•Œ ìˆ˜ ì—†ëŠ” ëª…ë ¹ì–´: {command}")
        print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´: list, analyze, generate, batch")

if __name__ == "__main__":
    main()
```

### 6. Rust ë°±ì—”ë“œ API í™•ì¥

#### 6.1 ìƒˆë¡œìš´ Tauri ëª…ë ¹ì–´ ì¶”ê°€ (`app/src-tauri/src/main.rs`)
```rust
// ì±„ë„ë³„ AI ì§ˆë¬¸ (ì±„ë„ ì„ íƒ í¬í•¨)
#[command]
async fn ask_ai_with_channel(query: String, channel_name: String) -> Result<String, String> {
    let project_root = get_project_root();
    let rag_script = project_root.join("vault").join("90_indices").join("rag.py");
    
    if !rag_script.exists() {
        return Err("RAG ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤".to_string());
    }
    
    let venv_python = project_root.join("venv").join("bin").join("python");
    let output = Command::new(&venv_python)
        .args(&[rag_script.to_str().unwrap(), &query, &channel_name])
        .current_dir(&project_root)
        .env("PYTHONUNBUFFERED", "1")
        .output()
        .map_err(|e| e.to_string())?;
    
    if output.status.success() {
        Ok(String::from_utf8_lossy(&output.stdout).to_string())
    } else {
        let stderr = String::from_utf8_lossy(&output.stderr);
        Err(format!("AI ì§ˆë¬¸ ì‹¤íŒ¨: {}", stderr))
    }
}

// AIìš© ì±„ë„ ëª©ë¡ ì¡°íšŒ
#[command]
async fn get_available_channels_for_ai() -> Result<Vec<ChannelInfo>, String> {
    let project_root = get_project_root();
    let chroma_path = project_root.join("vault").join("90_indices").join("chroma");
    
    if !chroma_path.exists() {
        return Ok(vec![]);
    }
    
    // Python ìŠ¤í¬ë¦½íŠ¸ë¡œ ì±„ë„ ëª©ë¡ ì¡°íšŒ
    let rag_script = project_root.join("vault").join("90_indices").join("rag.py");
    let venv_python = project_root.join("venv").join("bin").join("python");
    
    let output = Command::new(&venv_python)
        .args(&[rag_script.to_str().unwrap(), "channels"])
        .current_dir(&project_root)
        .output()
        .map_err(|e| e.to_string())?;
    
    if output.status.success() {
        let stdout = String::from_utf8_lossy(&output.stdout);
        // íŒŒì‹± ë¡œì§ êµ¬í˜„ í•„ìš”
        Ok(parse_channel_list(&stdout))
    } else {
        Err("ì±„ë„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨".to_string())
    }
}

// ì±„ë„ë³„ í”„ë¡¬í”„íŠ¸ ì¡°íšŒ
#[command]
async fn get_channel_prompt(channel_name: String) -> Result<String, String> {
    let project_root = get_project_root();
    let prompts_dir = project_root.join("vault").join("90_indices").join("prompts");
    let channel_dir = prompts_dir.join(&channel_name);
    
    if !channel_dir.exists() {
        return Ok("{}".to_string()); // ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë°˜í™˜
    }
    
    // í™œì„± ë²„ì „ í™•ì¸
    let active_file = channel_dir.join("active.txt");
    let version = if active_file.exists() {
        std::fs::read_to_string(&active_file)
            .map_err(|e| e.to_string())?
            .trim()
            .parse::<u32>()
            .unwrap_or(1)
    } else {
        1
    };
    
    // í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì½ê¸°
    let prompt_file = channel_dir.join(format!("prompt_v{}.json", version));
    if prompt_file.exists() {
        std::fs::read_to_string(&prompt_file).map_err(|e| e.to_string())
    } else {
        Ok("{}".to_string())
    }
}

// ì±„ë„ë³„ ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±
#[command]
async fn auto_generate_channel_prompt(channel_name: String) -> Result<u32, String> {
    let project_root = get_project_root();
    let auto_prompt_script = project_root.join("vault").join("90_indices").join("auto_prompt.py");
    
    if !auto_prompt_script.exists() {
        return Err("ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„± ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤".to_string());
    }
    
    let venv_python = project_root.join("venv").join("bin").join("python");
    let output = Command::new(&venv_python)
        .args(&[auto_prompt_script.to_str().unwrap(), "generate", &channel_name])
        .current_dir(&project_root)
        .output()
        .map_err(|e| e.to_string())?;
    
    if output.status.success() {
        let stdout = String::from_utf8_lossy(&output.stdout);
        // ë²„ì „ ë²ˆí˜¸ ì¶”ì¶œ (ì˜ˆ: "v3 ìƒì„± ì™„ë£Œ" -> 3)
        if let Some(version_match) = stdout.find("v") {
            if let Some(space_pos) = stdout[version_match..].find(" ") {
                let version_str = &stdout[version_match + 1..version_match + space_pos];
                if let Ok(version) = version_str.parse::<u32>() {
                    return Ok(version);
                }
            }
        }
        Ok(1) // ê¸°ë³¸ê°’
    } else {
        let stderr = String::from_utf8_lossy(&output.stderr);
        Err(format!("ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {}", stderr))
    }
}

// ì±„ë„ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
#[command]
async fn get_channel_analysis(channel_name: String) -> Result<String, String> {
    let project_root = get_project_root();
    let auto_prompt_script = project_root.join("vault").join("90_indices").join("auto_prompt.py");
    
    let venv_python = project_root.join("venv").join("bin").join("python");
    let output = Command::new(&venv_python)
        .args(&[auto_prompt_script.to_str().unwrap(), "analyze", &channel_name])
        .current_dir(&project_root)
        .output()
        .map_err(|e| e.to_string())?;
    
    if output.status.success() {
        Ok(String::from_utf8_lossy(&output.stdout).to_string())
    } else {
        let stderr = String::from_utf8_lossy(&output.stderr);
        Err(format!("ì±„ë„ ë¶„ì„ ì‹¤íŒ¨: {}", stderr))
    }
}

// ëª¨ë“  ì±„ë„ ìë™ í”„ë¡¬í”„íŠ¸ ì¼ê´„ ìƒì„±
#[command]
async fn batch_generate_prompts() -> Result<String, String> {
    let project_root = get_project_root();
    let auto_prompt_script = project_root.join("vault").join("90_indices").join("auto_prompt.py");
    
    let venv_python = project_root.join("venv").join("bin").join("python");
    let output = Command::new(&venv_python)
        .args(&[auto_prompt_script.to_str().unwrap(), "batch"])
        .current_dir(&project_root)
        .output()
        .map_err(|e| e.to_string())?;
    
    if output.status.success() {
        Ok(String::from_utf8_lossy(&output.stdout).to_string())
    } else {
        let stderr = String::from_utf8_lossy(&output.stderr);
        Err(format!("ì¼ê´„ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {}", stderr))
    }
}

// ì±„ë„ë³„ í”„ë¡¬í”„íŠ¸ ì €ì¥
#[command]
async fn save_channel_prompt(channel_name: String, prompt_data: String) -> Result<u32, String> {
    let project_root = get_project_root();
    let prompts_dir = project_root.join("vault").join("90_indices").join("prompts");
    let channel_dir = prompts_dir.join(&channel_name);
    
    // ë””ë ‰í† ë¦¬ ìƒì„±
    std::fs::create_dir_all(&channel_dir).map_err(|e| e.to_string())?;
    
    // ê¸°ì¡´ ë²„ì „ í™•ì¸
    let existing_versions: Vec<u32> = std::fs::read_dir(&channel_dir)
        .map_err(|e| e.to_string())?
        .filter_map(|entry| {
            let entry = entry.ok()?;
            let filename = entry.file_name().to_string_lossy().to_string();
            if filename.starts_with("prompt_v") && filename.ends_with(".json") {
                let version_str = filename.strip_prefix("prompt_v")?.strip_suffix(".json")?;
                version_str.parse().ok()
            } else {
                None
            }
        })
        .collect();
    
    let new_version = existing_versions.iter().max().unwrap_or(&0) + 1;
    
    // ìƒˆ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì €ì¥
    let prompt_file = channel_dir.join(format!("prompt_v{}.json", new_version));
    std::fs::write(&prompt_file, &prompt_data).map_err(|e| e.to_string())?;
    
    // í™œì„± ë²„ì „ ì—…ë°ì´íŠ¸
    let active_file = channel_dir.join("active.txt");
    std::fs::write(&active_file, new_version.to_string()).map_err(|e| e.to_string())?;
    
    Ok(new_version)
}
```

## ğŸ—ï¸ êµ¬í˜„ ë¡œë“œë§µ

### Phase 1: ê¸°ë°˜ ì‹œìŠ¤í…œ êµ¬ì¶• (1ì£¼)
1. **ì±„ë„ë³„ ë²¡í„° ë¶„ì„ ì‹œìŠ¤í…œ**
   - `vault/90_indices/channel_analyzer.py` êµ¬í˜„
   - ë²¡í„° ë°ì´í„°ì—ì„œ í‚¤ì›Œë“œ, í†¤, íŒ¨í„´ ìë™ ì¶”ì¶œ
   - ì±„ë„ íŠ¹ì„± ê¸°ë°˜ í˜ë¥´ì†Œë‚˜ ìë™ ìƒì„±

2. **íŒŒì¼ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ**
   - `vault/90_indices/prompt_manager.py` ìƒì„±
   - ì±„ë„ë³„ í”„ë¡¬í”„íŠ¸ CRUD ê¸°ëŠ¥
   - ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„± ê¸°ëŠ¥
   - ë²„ì „ ê´€ë¦¬ ì‹œìŠ¤í…œ

3. **ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„± CLI**
   - `vault/90_indices/auto_prompt.py` êµ¬í˜„
   - ì±„ë„ ë¶„ì„ ë° í”„ë¡¬í”„íŠ¸ ìë™ ìƒì„±
   - ì¼ê´„ ì²˜ë¦¬ ê¸°ëŠ¥

4. **ì±„ë„ ì„ íƒ UI ê°œë°œ**
   - React ì»´í¬ë„ŒíŠ¸ ì¶”ê°€
   - Tauri ë°±ì—”ë“œ API í™•ì¥

### Phase 2: ê³ ë„í™” RAG êµ¬í˜„ (1-2ì£¼)
1. **Multi-Stage Retrieval**
   - ì±„ë„ íŠ¹í™” HyDE êµ¬í˜„
   - Query Decomposition êµ¬í˜„
   - LLM Re-ranking ê°•í™”

2. **í”„ë¡¬í”„íŠ¸ ì‹œìŠ¤í…œ í†µí•©**
   - ì±„ë„ë³„ ë§ì¶¤ ë‹µë³€ ìƒì„±
   - ë™ì  í”„ë¡¬í”„íŠ¸ ë¡œë”©

### Phase 3: ì¸í„°ë™í‹°ë¸Œ UI (1ì£¼)
1. **í´ë¦­í˜• ì˜ìƒ ë§í¬**
   - YouTube íƒ€ì„ìŠ¤íƒ¬í”„ ë§í¬
   - ë¯¸ë¦¬ë³´ê¸° ì¹´ë“œ
   - ê´€ë ¨ë„ ì ìˆ˜ í‘œì‹œ

2. **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ UI**
   - í¸ì§‘ê¸° êµ¬í˜„
   - ë²„ì „ íˆìŠ¤í† ë¦¬ í‘œì‹œ

## ğŸ¯ ì„±ê³µ ê¸°ì¤€

### âœ… ê¸°ëŠ¥ì  ìš”êµ¬ì‚¬í•­
1. **ì±„ë„ë³„ ë§ì¶¤ ë‹µë³€**: ê° ì±„ë„ì˜ íŠ¹ì„±ì„ ë°˜ì˜í•œ ì „ë¬¸ì  ë‹µë³€ ì œê³µ
2. **ì¸í„°ë™í‹°ë¸Œ ì†ŒìŠ¤**: í´ë¦­ìœ¼ë¡œ YouTube ì›ë³¸ ì˜ìƒ ì¦‰ì‹œ ì ‘ê·¼
3. **í”„ë¡¬í”„íŠ¸ ê´€ë¦¬**: ì‹¤ì‹œê°„ í¸ì§‘, ë²„ì „ ê´€ë¦¬ ê°€ëŠ¥
4. **ì„±ëŠ¥**: ì§ˆë¬¸ â†’ ë‹µë³€ 5ì´ˆ ì´ë‚´

### ğŸ“Š í’ˆì§ˆ ì§€í‘œ
1. **ì •í™•ë„**: ì±„ë„ë³„ íŠ¹ì„±ì´ ë°˜ì˜ëœ ì „ë¬¸ì  ë‹µë³€
2. **ì†ë„**: í‰ê·  ì‘ë‹µ ì‹œê°„ 3ì´ˆ ì´í•˜
3. **ì‚¬ìš©ì„±**: ì±„ë„ ì „í™˜ ë° ì§ˆë¬¸ ì…ë ¥ ì›í´ë¦­
4. **ìœ ì§€ë³´ìˆ˜ì„±**: ìƒˆ ì±„ë„ ì¶”ê°€ ë° í”„ë¡¬í”„íŠ¸ í¸ì§‘ ìš©ì´

## ğŸ”§ ê¸°ìˆ  ìŠ¤íƒ

### ë°±ì—”ë“œ í™•ì¥
- **íŒŒì¼ ì‹œìŠ¤í…œ**: JSON ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
- **Python**: RAG íŒŒì´í”„ë¼ì¸ ê³ ë„í™”
- **Rust/Tauri**: API í™•ì¥ ë° íŒŒì¼ ê´€ë¦¬

### í”„ë¡ íŠ¸ì—”ë“œ ê°œì„ 
- **React**: ìƒˆë¡œìš´ ì»´í¬ë„ŒíŠ¸ ë° ìƒíƒœ ê´€ë¦¬
- **TypeScript**: íƒ€ì… ì•ˆì „ì„± ê°•í™”
- **CSS**: ì¸í„°ë™í‹°ë¸Œ UI ë””ìì¸

### AI/ML
- **DeepSeek**: Chain-of-Thought ë° ì±„ë„ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸
- **ChromaDB**: ë²¡í„° ê²€ìƒ‰ ìµœì í™”
- **í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§**: ì±„ë„ë³„ íŠ¹ì„± ë°˜ì˜

---

**ê°œë°œ ìš°ì„ ìˆœìœ„**: 
1. ì±„ë„ë³„ ë²¡í„° ë¶„ì„ ì‹œìŠ¤í…œ êµ¬í˜„
2. ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„± ê¸°ëŠ¥ ê°œë°œ
3. ì±„ë„ ì„ íƒ UI êµ¬í˜„
4. íŒŒì¼ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ê´€ë¦¬ ì‹œìŠ¤í…œ
5. ì±„ë„ë³„ ë§ì¶¤ ë‹µë³€ ìƒì„±
6. í´ë¦­í˜• ì˜ìƒ ë§í¬ ê¸°ëŠ¥
7. í”„ë¡¬í”„íŠ¸ í¸ì§‘ UI

## ğŸš€ ì‚¬ìš© ì‹œë‚˜ë¦¬ì˜¤

### 1. ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±
```bash
# 1. ë²¡í„° ì„ë² ë”© ìƒì„± (ê¸°ì¡´)
make embed

# 2. ëª¨ë“  ì±„ë„ ìë™ í”„ë¡¬í”„íŠ¸ ìƒì„±
python vault/90_indices/auto_prompt.py batch

# 3. íŠ¹ì • ì±„ë„ ë¶„ì„
python vault/90_indices/auto_prompt.py analyze takaki_takehana

# 4. íŠ¹ì • ì±„ë„ í”„ë¡¬í”„íŠ¸ ìƒì„±
python vault/90_indices/auto_prompt.py generate takaki_takehana
```

### 2. **ì™„ì „ ìë™í™”ëœ** AI ì§ˆë¬¸ ì›Œí¬í”Œë¡œìš°
1. **ì±„ë„ ì„ íƒ** â†’ `takaki_takehana` ì„ íƒ
2. **ìë™ ë¡œë“œ** â†’ ë²¡í„° ë¶„ì„ìœ¼ë¡œ ìƒì„±ëœ ì „ë¬¸ê°€ í”„ë¡¬í”„íŠ¸ ìë™ ì ìš©
3. **ì§ˆë¬¸ ì…ë ¥** â†’ "ë„ì¿„ ì›ë£¸ íˆ¬ì ìˆ˜ìµë¥ ì€?"
4. **ì „ë¬¸ê°€ ë‹µë³€** â†’ "10ë…„ì°¨ ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ì ì „ë¬¸ê°€" í˜ë¥´ì†Œë‚˜ë¡œ ë‹µë³€
5. **ì†ŒìŠ¤ í™•ì¸** â†’ YouTube ì˜ìƒ ì›í´ë¦­ ì ‘ê·¼

#### ğŸ” **ìë™ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ**
```
ë‹¹ì‹ ì€ takaki_takehana ì±„ë„ì„ ëŒ€í‘œí•˜ëŠ” ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ì ì „ë¬¸ AIì…ë‹ˆë‹¤.

ì´ ì±„ë„ì˜ íŠ¹ì§•:
- ì£¼ìš” í‚¤ì›Œë“œ: ë¶€ë™ì‚°, íˆ¬ì, ë„ì¿„, ìˆ˜ìµë¥ , ì„ëŒ€
- ì½˜í…ì¸  ìŠ¤íƒ€ì¼: ì‹¤ìš©ì ì´ê³  ê²½í—˜ ì¤‘ì‹¬ì ì¸ ì ‘ê·¼
- ë¶„ì„ ê¹Šì´: deep (êµ¬ì²´ì  ìˆ˜ì¹˜ì™€ ë°ì´í„° ì¤‘ì‹œ)

ë‹µë³€ ê·œì¹™:
- êµ¬ì²´ì ì¸ ìˆ˜ì¹˜ì™€ ë°ì´í„°ë¥¼ í¬í•¨í•˜ì—¬ ë‹µë³€
- ì‹¤ì œ ê²½í—˜ê³¼ ì‚¬ë¡€ë¥¼ ì¤‘ì‹¬ìœ¼ë¡œ ì„¤ëª…
- ë‹µë³€ êµ¬ì¡°: ğŸš€ í•µì‹¬ ìš”ì•½ â†’ ğŸ“Š ë°ì´í„° ë¶„ì„ â†’ ğŸ“š ê·¼ê±°/ì¶œì²˜ â†’ ğŸ“ ì‹¤í–‰ ë‹¨ê³„
```

### 3. í”„ë¡¬í”„íŠ¸ ê´€ë¦¬
1. **ìë™ ìƒì„±** â†’ ë²¡í„° ë°ì´í„° ë¶„ì„ìœ¼ë¡œ ì´ˆê¸° í”„ë¡¬í”„íŠ¸ ìƒì„±
2. **ìˆ˜ë™ í¸ì§‘** â†’ ì›¹ UIì—ì„œ í”„ë¡¬í”„íŠ¸ ì„¸ë¶€ ì¡°ì •
3. **ë²„ì „ ê´€ë¦¬** â†’ ë³€ê²½ ì´ë ¥ ì¶”ì  ë° ë¡¤ë°± ê°€ëŠ¥
4. **ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§** â†’ ë‹µë³€ í’ˆì§ˆì— ë”°ë¥¸ í”„ë¡¬í”„íŠ¸ ê°œì„ 
