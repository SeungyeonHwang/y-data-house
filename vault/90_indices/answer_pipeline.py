#!/usr/bin/env python3
"""
Prompt-Light ë‹µë³€ íŒŒì´í”„ë¼ì¸
ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ + Self-Refine (1íšŒ) + ReAct + JSON Schema

ì¡°ì–¸ ê¸°ë°˜ ìµœì í™”:
- ì±„ë„ë³„ 1-2ì¤„ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©
- Self-Refine 1íšŒë¡œ ì œí•œí•´ í† í° í­ì¦ ë°©ì§€  
- JSON Schema ê°•ì œë¡œ íŒŒì„œ ì˜¤ë¥˜ ê°ì†Œ
- ReActëŠ” ì¶”ê°€ ê²€ìƒ‰ í•„ìš”ì‹œì—ë§Œ
"""

import os
import time
import json
from typing import List, Dict, Optional, Any
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
from schemas import (
    AnswerRequest, AnswerResponse, AnswerConfig, ChannelPrompt,
    SearchResult, AnswerStyle
)
from prompt_manager import PromptManager

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class AnswerPipeline:
    """Prompt-Light ë‹µë³€ ìƒì„± íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, model: str = "deepseek-chat", prompts_dir: Path = None):
        """ì´ˆê¸°í™”"""
        self.model = model
        
        # DeepSeek í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            api_key = os.getenv('DEEPSEEK_API_KEY')
            if not api_key:
                raise ValueError("DEEPSEEK_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
                
            self.client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com/v1"
            )
            print(f"âœ… DeepSeek API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {model})")
        except Exception as e:
            raise ValueError(f"âŒ DeepSeek API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” (ì±„ë„ë³„ ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ìš©)
        try:
            self.prompt_manager = PromptManager(prompts_dir) if prompts_dir else None
            if self.prompt_manager:
                print(f"âœ… PromptManager ë¡œë“œë¨")
        except Exception as e:
            print(f"âš ï¸ PromptManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.prompt_manager = None
        
        # ê¸°ë³¸ JSON ìŠ¤í‚¤ë§ˆ í…œí”Œë¦¿
        self.default_schema = {
            "answer": "string - ë©”ì¸ ë‹µë³€ ë‚´ìš©",
            "key_points": ["string array - í•µì‹¬ í¬ì¸íŠ¸ë“¤"],
            "sources": ["string array - ì‚¬ìš©ëœ ì˜ìƒ IDë“¤"],
            "confidence": "number - ë‹µë³€ ì‹ ë¢°ë„ (0-1)",
            "summary": "string - í•œ ì¤„ ìš”ì•½"
        }
        
        # ì ì‘í˜• Temperatureìš© ì§ˆë¬¸ ë¶„ë¥˜ íŒ¨í„´
        self.factual_patterns = [
            r'\b(ì–¸ì œ|ëª‡|ì–¼ë§ˆ|ì–´ë””|ëˆ„ê°€|ë¬´ì—‡|ì–´ëŠ|ëª‡ê°œ|ëª‡ëª…)\b',  # 5W1H ì§ˆë¬¸
            r'\b(ê°€ê²©|ë¹„ìš©|ìš”ê¸ˆ|ìˆ˜ì¹˜|í†µê³„|ë‚ ì§œ|ì‹œê°„|ì£¼ì†Œ|ìœ„ì¹˜)\b',  # êµ¬ì²´ì  ìˆ˜ì¹˜/ìœ„ì¹˜
            r'\b(ì •ì˜|ì˜ë¯¸|ëœ»|ê°œë…|ìš©ì–´)\b',                      # ì •ì˜ ê´€ë ¨
            r'\b(ì‚¬ì‹¤|í™•ì¸|ë§ë‚˜|ì§„ì§œ|ì •ë§)\b',                    # ì‚¬ì‹¤ í™•ì¸
        ]
        
        self.analytical_patterns = [
            r'\b(ì™œ|ì´ìœ |ì›ì¸|ë°°ê²½|ê·¼ê±°|ê¹Œë‹­)\b',                 # ì¸ê³¼ê´€ê³„
            r'\b(ì–´ë–»ê²Œ|ë°©ë²•|ë°©ì‹|ê³¼ì •|ì ˆì°¨|ë‹¨ê³„)\b',              # ë°©ë²•/ì ˆì°¨
            r'\b(ë¹„êµ|ì°¨ì´|ì¥ë‹¨ì |vs|ëŒ€ë¹„|ì–´ë–¤.*ì¢‹)\b',           # ë¹„êµë¶„ì„
            r'\b(ì „ëµ|ê³„íš|ë°©í–¥|ë°©ì¹¨|ì •ì±…)\b',                    # ì „ëµì  ì‚¬ê³ 
            r'\b(í‰ê°€|ë¶„ì„|ê²€í† |ê³ ë ¤|íŒë‹¨)\b',                    # ë¶„ì„ì  ì‚¬ê³ 
            r'\b(ë¯¸ë˜|ì „ë§|ì˜ˆì¸¡|ì˜ˆìƒ|ì•ìœ¼ë¡œ)\b',                  # ì˜ˆì¸¡/ì „ë§
            r'\b(ì¶”ì²œ|ê¶Œì¥|ì œì•ˆ|ì¶”ì²œ.*ë°©ë²•)\b',                   # ì¶”ì²œ/ì œì•ˆ
        ]
        
        print("ğŸ’¬ Answer Pipeline ì´ˆê¸°í™” ì™„ë£Œ (ì ì‘í˜• Temperature ì§€ì›)")
    
    def _classify_question_type(self, query: str) -> str:
        """ì§ˆë¬¸ ìœ í˜• ë¶„ë¥˜ - ì‚¬ì‹¤í˜• vs ë¶„ì„í˜• (ì „ë¬¸ê°€ ì¡°ì–¸ ê¸°ë°˜)"""
        import re
        
        query_lower = query.lower()
        
        # ì‚¬ì‹¤í˜• íŒ¨í„´ ì ìˆ˜ ê³„ì‚°
        factual_score = 0
        for pattern in self.factual_patterns:
            if re.search(pattern, query_lower):
                factual_score += 1
        
        # ë¶„ì„í˜• íŒ¨í„´ ì ìˆ˜ ê³„ì‚°
        analytical_score = 0
        for pattern in self.analytical_patterns:
            if re.search(pattern, query_lower):
                analytical_score += 1
        
        # ê¸¸ì´ ê¸°ë°˜ ì¶”ê°€ ì ìˆ˜ (ì§§ì€ ì§ˆë¬¸ = ì‚¬ì‹¤í˜• ê²½í–¥)
        if len(query) <= 20:
            factual_score += 0.5
        elif len(query) >= 50:
            analytical_score += 0.5
        
        # ì§ˆë¬¸ ë³µì¡ë„ (ë³µìˆ˜ ì§ˆë¬¸ = ë¶„ì„í˜•)
        if query.count('?') > 1 or query.count('ï¼Ÿ') > 1:
            analytical_score += 1
        
        # ê²°ê³¼ íŒì •
        if factual_score > analytical_score:
            return "factual"
        elif analytical_score > factual_score:
            return "analytical"
        else:
            # ë™ì ì¸ ê²½ìš° ì§ˆë¬¸ ê¸¸ì´ì™€ êµ¬ì¡°ë¡œ íŒë‹¨
            if len(query) <= 30 and ('ë¬´ì—‡' in query or 'ì–¸ì œ' in query or 'ì–´ë””' in query):
                return "factual"
            else:
                return "analytical"
    
    def _get_adaptive_temperature(self, query: str, config: AnswerConfig) -> float:
        """ì ì‘í˜• Temperature ê³„ì‚° (ì „ë¬¸ê°€ ì¡°ì–¸: ì‚¬ì‹¤í˜• 0.4, ë¶„ì„í˜• 0.65)"""
        if not config.enable_adaptive_temperature:
            return config.temperature
        
        question_type = self._classify_question_type(query)
        
        if question_type == "factual":
            temperature = config.factual_temperature
            print(f"ğŸ¯ ì‚¬ì‹¤í˜• ì§ˆë¬¸ ê°ì§€ â†’ Temperature: {temperature}")
        else:
            temperature = config.analytical_temperature
            print(f"ğŸ§  ë¶„ì„í˜• ì§ˆë¬¸ ê°ì§€ â†’ Temperature: {temperature}")
        
        return temperature
    
    def _load_channel_prompt(self, channel_name: str) -> ChannelPrompt:
        """ì±„ë„ë³„ ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
        if self.prompt_manager:
            try:
                prompt_data = self.prompt_manager.get_channel_prompt(channel_name)
                
                # ê²½ëŸ‰í™”: í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ
                return ChannelPrompt(
                    channel_name=channel_name,
                    persona=prompt_data.get('persona', f'{channel_name} ì±„ë„ ì „ë¬¸ê°€')[:100],  # 1-2ì¤„ë¡œ ì œí•œ
                    tone=prompt_data.get('tone', 'ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ìŠ¤íƒ€ì¼')[:50],
                    expertise_keywords=prompt_data.get('expertise_keywords', [])[:5],  # ìƒìœ„ 5ê°œë§Œ
                    system_prompt=prompt_data.get('system_prompt', 
                        f'ë‹¹ì‹ ì€ {channel_name} ì±„ë„ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” AIì…ë‹ˆë‹¤.')[:200]  # ê°„ê²°í•˜ê²Œ
                )
            except Exception as e:
                print(f"âš ï¸ ì±„ë„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸
        return ChannelPrompt(
            channel_name=channel_name,
            persona=f'{channel_name} ì±„ë„ ì „ë¬¸ ë¶„ì„ê°€',
            tone='ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ìŠ¤íƒ€ì¼',
            expertise_keywords=[],
            system_prompt=f'ë‹¹ì‹ ì€ {channel_name} ì±„ë„ì˜ ì˜ìƒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.'
        )
    
    def _build_context(self, search_result: SearchResult, max_context_length: int = 2000) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¡œë¶€í„° ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ì˜ìƒ ì—°ê´€ì„± ì •ë³´ ê°•í™”)"""
        if not search_result.documents:
            return "ê²€ìƒ‰ëœ ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤."
        
        context_parts = []
        for i, doc in enumerate(search_result.documents[:6]):  # ì „ë¬¸ê°€ ì¡°ì–¸: top-6 chunk Ã— ìµœëŒ€ 800 tokê°€ LLM-window ìµœì 
            # ì˜ìƒ ë©”íƒ€ë°ì´í„° ì¶”ì¶œ (ì•ˆì „í•˜ê²Œ)
            metadata = doc.metadata if hasattr(doc, 'metadata') and doc.metadata else {}
            upload_date = metadata.get('upload_date', 'ë‚ ì§œ ë¯¸ìƒ')
            duration = metadata.get('duration', 'ì‹œê°„ ë¯¸ìƒ')
            chunk_index = metadata.get('chunk_index', 'N/A')
            
            # ì˜ìƒ ì—°ê´€ì„± ì •ë³´ ê°•í™”
            context_part = f"""
ğŸ“º **ì˜ìƒ {i+1}** [{doc.video_id}]
ğŸ“ **ì œëª©**: {doc.title}
ğŸ“… **ì—…ë¡œë“œ**: {upload_date}
â±ï¸ **ì˜ìƒ ê¸¸ì´**: {duration}
ğŸ” **ì—°ê´€ì„± ì ìˆ˜**: {doc.similarity:.3f} (ë§¤ìš° ë†’ìŒ: 0.8+, ë†’ìŒ: 0.6+, ë³´í†µ: 0.4+)
ğŸ“ **ì²­í¬ ìœ„ì¹˜**: {chunk_index}ë²ˆì§¸ êµ¬ê°„
ğŸ“– **ê´€ë ¨ ë‚´ìš©**: {doc.content[:400]}...
ğŸ¯ **ì´ ì˜ìƒì˜ ê°€ì¹˜**: {'í•µì‹¬ ë‹µë³€ ì œê³µ' if doc.similarity > 0.7 else 'ë³´ì¡° ì •ë³´ ì œê³µ' if doc.similarity > 0.5 else 'ì°¸ê³  ìë£Œ'}
---"""
            context_parts.append(context_part)
        
        context = "\n".join(context_parts)
        
        if len(context) > max_context_length:
            context = context[:max_context_length] + "\n...(ë‚´ìš© ìƒëµ)"
        
        return context
    
    def _get_json_schema_instruction(self, config: AnswerConfig) -> str:
        """JSON ìŠ¤í‚¤ë§ˆ ì§€ì‹œì‚¬í•­ ìƒì„± (ëª…í™•í•˜ê³  ê°•ì œì )"""
        
        # ìŠ¤íƒ€ì¼ë³„ ì˜ˆì‹œ (ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ ì¤‘ì‹¬)
        if config.style == AnswerStyle.BULLET_POINTS:
            format_example = """
{
  "answer": "## ğŸ¯ í•µì‹¬ ë‹µë³€\\n\\nâ€¢ **ì˜ìƒ ê¸°ë°˜ ì •ë³´**: êµ¬ì²´ì ì¸ ì„¤ëª… ë‚´ìš© [video_id_1]\\nâ€¢ **ì¶”ê°€ ì „ë¬¸ ì§€ì‹**: ì˜ìƒì—ì„œ ë‹¤ë£¨ì§€ ì•Šì•˜ì§€ë§Œ ê´€ë ¨ëœ ìœ ìš©í•œ ì •ë³´\\nâ€¢ **ì‹¤ì „ ì¡°ì–¸**: ì¢…í•©ì ì¸ ê°€ì´ë“œ ë° ì£¼ì˜ì‚¬í•­ [video_id_2]\\n\\n## ğŸ“š ì •ë³´ ì¶œì²˜ êµ¬ë¶„\\n- ğŸ¬ ì˜ìƒ ì •ë³´: [video_id] í‘œì‹œ\\n- ğŸ§  ì „ë¬¸ ì§€ì‹: ì¼ë°˜ì ìœ¼ë¡œ ì•Œë ¤ì§„ ì •ë³´",
  "key_points": [
    "ì˜ìƒì—ì„œ í™•ì¸ëœ í•µì‹¬ í¬ì¸íŠ¸",
    "ì¶”ê°€ë¡œ ì•Œì•„ë‘ë©´ ì¢‹ì€ ê´€ë ¨ ì •ë³´", 
    "ì‹¤ìš©ì ì¸ ì¡°ì–¸ ë° ì£¼ì˜ì‚¬í•­"
  ],
  "video_connections": [
    {
      "video_id": "20231201_investment_guide",
      "title": "ë¶€ë™ì‚° íˆ¬ì ê°€ì´ë“œ",
      "relevance_score": 0.92,
      "connection_reason": "ì§ˆë¬¸ì˜ í•µì‹¬ ì£¼ì œì¸ íˆ¬ì ì „ëµì„ ì§ì ‘ì ìœ¼ë¡œ ë‹¤ë£¨ê³  ìˆìŒ",
      "key_content": "ë„ì¿„ ì•„íŒŒíŠ¸ íˆ¬ì ìˆ˜ìµë¥  ë¶„ì„ ë° ì‹¤ì „ íŒ",
      "usage_in_answer": "ì²« ë²ˆì§¸ í¬ì¸íŠ¸ì˜ ê·¼ê±° ìë£Œë¡œ í™œìš©"
    }
  ],
  "additional_insights": "ì˜ìƒì—ì„œ ì§ì ‘ ë‹¤ë£¨ì§€ ì•Šì•˜ì§€ë§Œ ì§ˆë¬¸ í•´ê²°ì— ë„ì›€ë˜ëŠ” ë³´ì™„ ì •ë³´ë“¤",
  "sources": [
    {"video_id": "20231201_investment_guide", "relevance": "íˆ¬ì ì „ëµ ì„¤ëª…"},
    {"video_id": "20231215_market_analysis", "relevance": "ì‹œì¥ ë¶„ì„ ë‚´ìš©"}
  ],
  "confidence": 0.85,
  "summary": "ì˜ìƒ ì •ë³´ì™€ ì „ë¬¸ ì§€ì‹ì„ ì¢…í•©í•œ ì™„ì „í•œ ë‹µë³€"
}"""
        elif config.style == AnswerStyle.DETAILED_EXPLANATION:
            format_example = """
{
  "answer": "## ğŸ“‹ ìƒì„¸ ë¶„ì„\\n\\n**ì˜ìƒ ê¸°ë°˜ ë¶„ì„**: ìì„¸í•œ ì„¤ëª…... [video_id_1]\\n\\n**ë³´ì™„ ì •ë³´**: ì˜ìƒì—ì„œ ë‹¤ë£¨ì§€ ì•Šì€ ê´€ë ¨ ì „ë¬¸ ì§€ì‹\\n\\n**ì¢…í•© ê²°ë¡ **: ì™„ì „í•œ ë¶„ì„ ê²°ê³¼ [video_id_2]",
  "key_points": ["ì˜ìƒ í™•ì¸ ìš”ì ", "ì¶”ê°€ ì „ë¬¸ ì§€ì‹", "ì‹¤ìš©ì  ê²°ë¡ "],
  "video_connections": [
    {
      "video_id": "actual_video_id",
      "title": "ì‹¤ì œ ì˜ìƒ ì œëª©",
      "relevance_score": 0.88,
      "connection_reason": "ìƒì„¸ ë¶„ì„ì˜ ê·¼ê±°ê°€ ë˜ëŠ” í•µì‹¬ ë‚´ìš© í¬í•¨",
      "key_content": "ì˜ìƒì—ì„œ ë‹¤ë£¬ êµ¬ì²´ì  ë‚´ìš©",
      "usage_in_answer": "ìƒì„¸ ë¶„ì„ ì„¹ì…˜ì˜ ì£¼ìš” ê·¼ê±°ë¡œ í™œìš©"
    }
  ],
  "additional_insights": "ì˜ìƒì— ì—†ì§€ë§Œ ë¶„ì„ì— í•„ìš”í•œ ë³´ì™„ ì •ë³´",
  "sources": [{"video_id": "actual_video_id", "relevance": "ê´€ë ¨ì„± ì„¤ëª…"}],
  "confidence": 0.80,
  "summary": "ì˜ìƒê³¼ ì „ë¬¸ì§€ì‹ì„ ì¢…í•©í•œ ì™„ì „í•œ ë¶„ì„"
}"""
        else:  # SUMMARY
            format_example = """
{
  "answer": "## ğŸ“ ìš”ì•½\\n\\nğŸ¬ **ì˜ìƒ ìš”ì•½**: í•µì‹¬ ë‚´ìš© ì •ë¦¬... [video_id_1]\\nğŸ§  **ì¶”ê°€ ì •ë³´**: ë³´ì™„ì ì¸ ì „ë¬¸ ì§€ì‹\\nğŸ’¡ **ê²°ë¡ **: ì¢…í•©ì ì¸ ìš”ì•½",
  "key_points": ["ì˜ìƒ í•µì‹¬ ìš”ì ", "ë³´ì™„ ì •ë³´", "ìµœì¢… ê²°ë¡ "],
  "video_connections": [
    {
      "video_id": "actual_video_id",
      "title": "ì‹¤ì œ ì˜ìƒ ì œëª©",
      "relevance_score": 0.85,
      "connection_reason": "ìš”ì•½ì˜ í•µì‹¬ ê·¼ê±°ê°€ ë˜ëŠ” ë‚´ìš©",
      "key_content": "ì˜ìƒì˜ ì£¼ìš” í¬ì¸íŠ¸",
      "usage_in_answer": "ìš”ì•½ ë‚´ìš©ì˜ ì§ì ‘ì  ê·¼ê±°"
    }
  ],
  "additional_insights": "ì˜ìƒ ì™¸ ìœ ìš©í•œ ê´€ë ¨ ì •ë³´",
  "sources": [{"video_id": "actual_video_id", "relevance": "ê´€ë ¨ì„±"}],
  "confidence": 0.75,
  "summary": "ì™„ì „í•˜ê³  ìœ ìš©í•œ ìš”ì•½"
}"""
        
        return f"""
## âš ï¸ ì‘ë‹µ í˜•ì‹ (JSON í•„ìˆ˜)

**ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:**

```json
{format_example.strip()}
```

## ğŸ“‹ í•„ìˆ˜ ìš”êµ¬ì‚¬í•­:

1. **JSON í˜•ì‹ í•„ìˆ˜**: ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ ì˜¤ì§ JSONë§Œ ì¶œë ¥
2. **ì‹¤ì œ video_id ì‚¬ìš©**: [video_id_1] í˜•íƒœë¡œ ì‹¤ì œ ì˜ìƒ ID í‘œì‹œ
3. **video_connections ë°°ì—´**: ê° ì˜ìƒê³¼ ì§ˆë¬¸ì˜ ì—°ê´€ì„±ì„ ìƒì„¸íˆ ì„¤ëª…
4. **additional_insights í•„ë“œ**: ì˜ìƒì— ì—†ì§€ë§Œ ìœ ìš©í•œ ë³´ì™„ ì •ë³´ ì œê³µ
5. **sources ë°°ì—´**: ê° ì¶œì²˜ì˜ video_idì™€ relevance ëª…ì‹œ
6. **confidence**: 0.0~1.0 ì‚¬ì´ì˜ ì •í™•í•œ ìˆ˜ì¹˜
7. **í•œê¸€ ì‚¬ìš©**: ëª¨ë“  ë‚´ìš©ì€ í•œê¸€ë¡œ ì‘ì„±

## ğŸ¯ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ ì‘ì„± ë°©ë²•:
- **ì˜ìƒ ìš°ì„ **: ê°€ëŠ¥í•œ í•œ ì˜ìƒ ë‚´ìš©ì„ ì£¼ìš” ê·¼ê±°ë¡œ í™œìš©
- **ì ê·¹ì  ë³´ì™„**: ì˜ìƒì— ì—†ëŠ” ë‚´ìš©ë„ ì§ˆë¬¸ í•´ê²°ì— ë„ì›€ëœë‹¤ë©´ ì ê·¹ í¬í•¨
- **ì¶œì²˜ êµ¬ë¶„**: ì˜ìƒ ì •ë³´(ğŸ¬)ì™€ ì¼ë°˜ ì „ë¬¸ì§€ì‹(ğŸ§ )ì„ ëª…í™•íˆ êµ¬ë¶„
- **ì™„ì „í•œ ë‹µë³€**: ì§ˆë¬¸ìê°€ ë§Œì¡±í•  ìˆ˜ ìˆëŠ” ì™„ì „í•˜ê³  ìœ ìš©í•œ ì •ë³´ ì œê³µ
- **ì‹¤ìš©ì„± ì¤‘ì‹¬**: ì´ë¡ ë³´ë‹¤ëŠ” ì‹¤ì œ ë„ì›€ì´ ë˜ëŠ” êµ¬ì²´ì  ì •ë³´ ìš°ì„ 
- **ê´€ë ¨ì„± í™•ì¥**: ì§ˆë¬¸ê³¼ ê°„ì ‘ì ìœ¼ë¡œë¼ë„ ê´€ë ¨ëœ ìœ ìš©í•œ ì •ë³´ í¬í•¨
"""
    
    def _extract_json_from_response(self, response_text: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ (ê°•í™”ëœ íŒŒì‹±)"""
        try:
            # JSON ì½”ë“œë¸”ë¡ ì°¾ê¸°
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(1)
            else:
                # ì½”ë“œë¸”ë¡ ì—†ìœ¼ë©´ ì§ì ‘ JSON ì°¾ê¸°
                json_match = re.search(r'(\{.*\})', response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # JSON íŒŒì‹± ì‹œë„
            try:
                parsed_json = json.loads(json_str)
            except json.JSONDecodeError as e:
                print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                # ë¶ˆì™„ì „í•œ JSON ë³µêµ¬ ì‹œë„
                parsed_json = self._repair_incomplete_json(json_str, response_text)
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦ ë° íƒ€ì… ì•ˆì „ì„± ë³´ì¥
            required_fields = ['answer', 'confidence', 'sources']
            for field in required_fields:
                if field not in parsed_json:
                    if field == 'answer':
                        parsed_json[field] = response_text[:500] + "..." if len(response_text) > 500 else response_text
                    elif field == 'confidence':
                        parsed_json[field] = 0.5
                    elif field == 'sources':
                        parsed_json[field] = []
            
            # íƒ€ì… ì•ˆì „ì„± í™•ë³´
            if not isinstance(parsed_json.get('answer'), str):
                parsed_json['answer'] = str(parsed_json.get('answer', ''))
            
            if not isinstance(parsed_json.get('confidence'), (int, float)):
                try:
                    parsed_json['confidence'] = float(parsed_json.get('confidence', 0.5))
                except (ValueError, TypeError):
                    parsed_json['confidence'] = 0.5
            
            if not isinstance(parsed_json.get('sources'), list):
                parsed_json['sources'] = []
            
            return parsed_json
            
        except Exception as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # ì•ˆì „í•œ fallback ì‘ë‹µ
            clean_text = response_text.replace('\n', ' ').strip()
            return {
                "answer": clean_text[:1000] + "..." if len(clean_text) > 1000 else clean_text,
                "key_points": [],
                "sources": [],
                "confidence": 0.3,
                "summary": "JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ì‘ë‹µ"
            }
    
    def _repair_incomplete_json(self, json_str: str, full_response: str) -> Dict[str, Any]:
        """ë¶ˆì™„ì „í•œ JSON ë³µêµ¬ ì‹œë„"""
        try:
            # ê¸°ë³¸ êµ¬ì¡° ì¶”ì¶œ
            result = {}
            
            # answer í•„ë“œ ì¶”ì¶œ
            answer_match = re.search(r'"answer":\s*"([^"]*(?:\\.[^"]*)*)"', json_str, re.DOTALL)
            if answer_match:
                result['answer'] = answer_match.group(1).replace('\\"', '"').replace('\\n', '\n')
            else:
                # answer í•„ë“œê°€ ì—†ìœ¼ë©´ ì „ì²´ ì‘ë‹µì—ì„œ ì¶”ì¶œ
                result['answer'] = full_response[:800]
            
            # key_points ì¶”ì¶œ
            key_points_match = re.search(r'"key_points":\s*\[(.*?)\]', json_str, re.DOTALL)
            if key_points_match:
                points_str = key_points_match.group(1)
                # ê°œë³„ í¬ì¸íŠ¸ ì¶”ì¶œ
                points = re.findall(r'"([^"]*(?:\\.[^"]*)*)"', points_str)
                result['key_points'] = [p.replace('\\"', '"') for p in points]
            else:
                result['key_points'] = []
            
            # sources ì¶”ì¶œ (ê°„ë‹¨í•œ í˜•íƒœ)
            sources_match = re.search(r'"sources":\s*\[(.*?)\]', json_str, re.DOTALL)
            if sources_match:
                result['sources'] = []
                # video_id íŒ¨í„´ ì°¾ê¸°
                video_ids = re.findall(r'"video_id":\s*"([^"]*)"', sources_match.group(1))
                for vid in video_ids:
                    result['sources'].append({"video_id": vid, "relevance": "ë³µêµ¬ëœ ì •ë³´"})
            else:
                result['sources'] = []
            
            # confidence ì¶”ì¶œ
            conf_match = re.search(r'"confidence":\s*([0-9.]+)', json_str)
            if conf_match:
                try:
                    result['confidence'] = float(conf_match.group(1))
                except:
                    result['confidence'] = 0.5
            else:
                result['confidence'] = 0.5
            
            print(f"ğŸ”§ JSON ë³µêµ¬ ì„±ê³µ: {len(result)} í•„ë“œ")
            return result
            
        except Exception as e:
            print(f"âš ï¸ JSON ë³µêµ¬ ì‹¤íŒ¨: {e}")
            return {
                "answer": full_response[:800],
                "key_points": [],
                "sources": [],
                "confidence": 0.3,
                "summary": "JSON ë³µêµ¬ ì‹¤íŒ¨"
            }
    
    def _should_use_react(self, query: str, search_result: SearchResult) -> bool:
        """ReAct íŒ¨í„´ ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì‹ ë¢°ë„ê°€ ë‚®ì„ ë•Œë§Œ
        if len(search_result.documents) < 2:
            return True
        
        avg_similarity = sum(doc.similarity for doc in search_result.documents) / len(search_result.documents)
        if avg_similarity < 0.4:
            return True
        
        # ë³µì¡í•œ ì¿¼ë¦¬ íŒ¨í„´ (ìµœì‹  ì •ë³´, ë¹„êµ, ì˜ˆì¸¡ ë“±)
        react_patterns = [
            r'\b(ìµœì‹ |ìµœê·¼|í˜„ì¬|ì§€ê¸ˆ|ì˜¤ëŠ˜)\b',
            r'\b(ë¹„êµ|ì°¨ì´|vs|ëŒ€ë¹„)\b', 
            r'\b(ì˜ˆì¸¡|ì „ë§|ë¯¸ë˜|ê³„íš)\b',
            r'\b(ì¶”ì²œ|ì œì•ˆ|ì¡°ì–¸)\b'
        ]
        
        import re
        for pattern in react_patterns:
            if re.search(pattern, query.lower()):
                return True
        
        return False
    
    def _apply_react_pattern(self, query: str, initial_context: str, channel_name: str) -> str:
        """ReAct íŒ¨í„´ ì ìš© (ì¶”ê°€ ì •ë³´ í•„ìš”ì‹œ)"""
        try:
            react_prompt = f"""ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í˜„ì¬ ì •ë³´ë¡œ ì§ˆë¬¸ì— ì™„ì „íˆ ë‹µí•  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

## í˜„ì¬ ì§ˆë¬¸
{query}

## í˜„ì¬ ê°€ì§„ ì •ë³´
{initial_context[:500]}...

## íŒë‹¨ ê³¼ì • (ReAct)
Thought: í˜„ì¬ ì •ë³´ë¡œ ì§ˆë¬¸ì— ì¶©ë¶„íˆ ë‹µí•  ìˆ˜ ìˆëŠ”ê°€?
Action: [SUFFICIENT] ë˜ëŠ” [NEED_MORE_INFO: í•„ìš”í•œ ì •ë³´ ìœ í˜•]
Observation: ì •ë³´ ì¶©ì¡±ë„ í‰ê°€
Final Answer: ë‹¤ìŒ ë‹¨ê³„ ê²°ì •

ê°„ë‹¨íˆ íŒë‹¨ ê²°ê³¼ë§Œ ì‘ë‹µí•˜ì„¸ìš”: "SUFFICIENT" ë˜ëŠ” "NEED_MORE_INFO: ..."
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ ì •ë³´ í‰ê°€ìì…ë‹ˆë‹¤."},
                    {"role": "user", "content": react_prompt}
                ],
                max_tokens=100,
                temperature=0.3
            )
            
            result = response.choices[0].message.content.strip()
            print(f"ğŸ”§ ReAct íŒë‹¨: {result}")
            
            if "NEED_MORE_INFO" in result:
                return f"í˜„ì¬ ì •ë³´ë¡œëŠ” ë¶€ì¡±í•©ë‹ˆë‹¤. {result}"
            else:
                return "í˜„ì¬ ì •ë³´ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤."
                
        except Exception as e:
            print(f"âš ï¸ ReAct íŒ¨í„´ ì‹¤íŒ¨: {e}")
            return "í˜„ì¬ ì •ë³´ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤."
    
    def _generate_initial_answer(self, request: AnswerRequest) -> str:
        """ì´ˆê¸° ë‹µë³€ ìƒì„± (ì ì‘í˜• Temperature ì ìš©)"""
        # ì±„ë„ë³„ ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        channel_prompt = request.channel_prompt or self._load_channel_prompt(request.search_result.channel_name)
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± (ë¹„ë””ì˜¤ ID í¬í•¨)
        context = self._build_context(request.search_result)
        
        # ê²€ìƒ‰ëœ ë¹„ë””ì˜¤ ID ëª©ë¡ ìƒì„±
        video_ids = [doc.video_id for doc in request.search_result.documents]
        video_list = ", ".join(video_ids) if video_ids else "ì—†ìŒ"
        
        # JSON ìŠ¤í‚¤ë§ˆ ì§€ì‹œì‚¬í•­
        json_instruction = self._get_json_schema_instruction(request.config)
        
        # ì ì‘í˜• Temperature ê³„ì‚° (ì „ë¬¸ê°€ ì¡°ì–¸ ë°˜ì˜)
        adaptive_temp = self._get_adaptive_temperature(request.original_query, request.config)
        
        # ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ ì¤‘ì‹¬ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_message = f"{channel_prompt.system_prompt} {channel_prompt.tone}ìœ¼ë¡œ ë‹µë³€í•˜ë˜, ì˜ìƒì— ì—†ëŠ” ë‚´ìš©ì´ë¼ë„ ì§ˆë¬¸ í•´ê²°ì— ë„ì›€ì´ ëœë‹¤ë©´ ì ê·¹ì ìœ¼ë¡œ í¬í•¨í•˜ì—¬ ì™„ì „í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”."
        
        user_prompt = f"""## ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ({request.search_result.channel_name} ì±„ë„)
{context}

## ì‚¬ìš© ê°€ëŠ¥í•œ ë¹„ë””ì˜¤ ID ëª©ë¡
{video_list}

## ì‚¬ìš©ì ì§ˆë¬¸
{request.original_query}

## ğŸ¯ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ ì œê³µ ì§€ì‹œì‚¬í•­
- **ì˜ìƒ ìš°ì„  í™œìš©**: {request.search_result.channel_name} ì±„ë„ì˜ ì˜ìƒ ë‚´ìš©ì„ ì£¼ìš” ê·¼ê±°ë¡œ í™œìš©
- **ì˜ìƒë³„ ì—°ê´€ì„± ëª…ì‹œ**: ê° ì˜ìƒì´ ì§ˆë¬¸ê³¼ ì–´ë–»ê²Œ ì—°ê²°ë˜ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…
- **ë³´ì™„ ì •ë³´ ì œê³µ**: ì˜ìƒì—ì„œ ì§ì ‘ ë‹¤ë£¨ì§€ ì•Šì§€ë§Œ ì§ˆë¬¸ê³¼ ê´€ë ¨ëœ ìœ ìš©í•œ ì •ë³´ë„ í¬í•¨
- **video_connections í¬í•¨**: ì˜ìƒê³¼ ì§ˆë¬¸ì˜ ì—°ê´€ì„± ì ìˆ˜ì™€ êµ¬ì²´ì  ê·¼ê±° í¬í•¨
- **ì ê·¹ì  ë‹µë³€**: ì˜ìƒ ì •ë³´ + ì±„ë„ íŠ¹ì„± + ì¼ë°˜ì  ì „ë¬¸ ì§€ì‹ì„ ì¢…í•©í•˜ì—¬ ìµœëŒ€í•œ ë„ì›€ë˜ëŠ” ë‹µë³€ ì œê³µ
- **ì •ë³´ êµ¬ë¶„**: ì˜ìƒ ê¸°ë°˜ ì •ë³´ì™€ ì¶”ê°€ ì „ë¬¸ ì§€ì‹ì„ ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ í‘œì‹œ
- **ìŠ¤íƒ€ì¼**: {request.config.style.value} í˜•ì‹ìœ¼ë¡œ ì‘ì„±
- **ì¶œì²˜ í‘œì‹œ**: [video_id] í˜•íƒœë¡œ ì˜ìƒ ID ëª…ì‹œì  í‘œì‹œ

{json_instruction}

**í•µì‹¬**: ì‚¬ìš©ìì—ê²Œ ìµœëŒ€í•œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”. 
ì˜ìƒ ë‚´ìš©ì„ ì£¼ìš” ê·¼ê±°ë¡œ í•˜ë˜, ì§ˆë¬¸ í•´ê²°ì— í•„ìš”í•œ ì¶”ê°€ ì •ë³´ë„ ì ê·¹ì ìœ¼ë¡œ í¬í•¨í•˜ì—¬ ì™„ì „í•œ ë‹µë³€ì„ ë§Œë“œì„¸ìš”.
ì •ë³´ì˜ ì¶œì²˜(ì˜ìƒ vs ì¼ë°˜ ì§€ì‹)ëŠ” ëª…í™•íˆ êµ¬ë¶„í•˜ì—¬ í‘œì‹œí•˜ì„¸ìš”."""
        
        try:
            start_time = time.time()
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=request.config.max_tokens,
                temperature=adaptive_temp  # ì ì‘í˜• Temperature ì ìš©
            )
            
            generation_time = (time.time() - start_time) * 1000
            initial_answer = response.choices[0].message.content.strip()
            
            print(f"ğŸ“ ì´ˆê¸° ë‹µë³€ ìƒì„± ì™„ë£Œ ({generation_time:.1f}ms, temp={adaptive_temp})")
            return initial_answer
            
        except Exception as e:
            print(f"âŒ ì´ˆê¸° ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return json.dumps({
                "answer": f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
                "key_points": [],
                "sources": [],
                "confidence": 0.0,
                "summary": "ì˜¤ë¥˜ ë°œìƒ"
            }, ensure_ascii=False)
    
    def _apply_self_refine(self, initial_answer: str, query: str, channel_name: str) -> str:
        """Self-Refine 1íšŒ ì ìš© (í† í° í­ì¦ ë°©ì§€)"""
        try:
            # ì´ˆê¸° ë‹µë³€ì—ì„œ JSON ì¶”ì¶œ
            initial_json = self._extract_json_from_response(initial_answer)
            
            if initial_json.get('confidence', 0) > 0.8:
                print("ğŸ¯ ì´ˆê¸° ë‹µë³€ ì‹ ë¢°ë„ ë†’ìŒ, Self-Refine ìƒëµ")
                return initial_answer
            
            refine_prompt = f"""ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ ë‹µë³€ í’ˆì§ˆ ê²€í† ìì…ë‹ˆë‹¤.

## ì›ë³¸ ì§ˆë¬¸
{query}

## ì´ˆê¸° ë‹µë³€ (JSON)
{json.dumps(initial_json, ensure_ascii=False, indent=2)}

## ê°œì„  ì§€ì‹œì‚¬í•­
1. ë‹µë³€ì˜ ì •í™•ì„±ê³¼ ì™„ì„±ë„ë¥¼ ê²€í† 
2. ëˆ„ë½ëœ ì¤‘ìš” ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸  
3. ì¶œì²˜ í‘œì‹œê°€ ì ì ˆí•œì§€ ì ê²€
4. ì‹ ë¢°ë„ë¥¼ ì¬í‰ê°€

ê°œì„ ëœ ë‹µë³€ì„ ë™ì¼í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. 20% ì´ìƒ í’ˆì§ˆ ê°œì„ ì„ ëª©í‘œë¡œ í•˜ë˜, ê¸°ì¡´ ë‹µë³€ì´ ì´ë¯¸ ìš°ìˆ˜í•˜ë‹¤ë©´ ìœ ì§€í•˜ì„¸ìš”."""

            start_time = time.time()
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ ë‹µë³€ ê²€í† ìì…ë‹ˆë‹¤."},
                    {"role": "user", "content": refine_prompt}
                ],
                max_tokens=800,
                temperature=0.5
            )
            
            refine_time = (time.time() - start_time) * 1000
            refined_answer = response.choices[0].message.content.strip()
            
            print(f"âœ¨ Self-Refine ì™„ë£Œ ({refine_time:.1f}ms)")
            return refined_answer
            
        except Exception as e:
            print(f"âš ï¸ Self-Refine ì‹¤íŒ¨: {e}")
            return initial_answer
    
    def generate_answer(self, request: AnswerRequest) -> AnswerResponse:
        """ë©”ì¸ ë‹µë³€ ìƒì„± íŒŒì´í”„ë¼ì¸"""
        start_time = time.time()
        
        print(f"ğŸ’¬ ë‹µë³€ ìƒì„± ì‹œì‘: {request.query_id}")
        
        # 0. ReAct íŒ¨í„´ ì ìš© ì—¬ë¶€ íŒë‹¨
        react_steps = []
        if request.config.enable_react:
            context_preview = self._build_context(request.search_result, 500)
            if self._should_use_react(request.original_query, request.search_result):
                react_result = self._apply_react_pattern(request.original_query, context_preview, request.search_result.channel_name)
                react_steps.append(react_result)
        
        # 1. ì´ˆê¸° ë‹µë³€ ìƒì„±
        initial_answer = self._generate_initial_answer(request)
        
        # 2. Self-Refine ì ìš© (1íšŒ ì œí•œ)
        final_answer = initial_answer
        self_refined = False
        
        if request.config.enable_self_refine:
            refined_answer = self._apply_self_refine(initial_answer, request.original_query, request.search_result.channel_name)
            if refined_answer != initial_answer:
                final_answer = refined_answer
                self_refined = True
        
        # 3. JSON íŒŒì‹± ë° ê²€ì¦
        answer_json = self._extract_json_from_response(final_answer)
        
        # 4. ì‚¬ìš©ëœ ì†ŒìŠ¤ ì¶”ì¶œ (ì•ˆì „í•˜ê²Œ)
        sources_used = []
        try:
            for doc in request.search_result.documents:
                # ì•ˆì „í•œ í•„ë“œ ê°’ ê²€ì‚¬
                for field in ['answer', 'key_points']:
                    field_value = answer_json.get(field, '')
                    
                    # ë‹¤ì–‘í•œ íƒ€ì…ì„ ì•ˆì „í•˜ê²Œ ë¬¸ìì—´ë¡œ ë³€í™˜
                    if isinstance(field_value, list):
                        field_str = ' '.join(str(item) for item in field_value)
                    elif isinstance(field_value, str):
                        field_str = field_value
                    else:
                        field_str = str(field_value) if field_value else ''
                    
                    if doc.video_id in field_str:
                        sources_used.append(doc.video_id)
                        break  # ì´ë¯¸ ì°¾ì•˜ìœ¼ë¯€ë¡œ ë‹¤ìŒ ë¬¸ì„œë¡œ
        except Exception as e:
            print(f"âš ï¸ ì†ŒìŠ¤ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        
        # ì†ŒìŠ¤ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê²€ìƒ‰ëœ ì˜ìƒë“¤ í¬í•¨ (ì „ë¬¸ê°€ ì¡°ì–¸: 4-5ê°œ ìµœì )
        if not sources_used:
            sources_used = [doc.video_id for doc in request.search_result.documents[:5]]  # Choice Overload ë°©ì§€
        
        generation_time = (time.time() - start_time) * 1000
        
        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì • (ì•ˆì „í•œ ê³„ì‚°)
        try:
            # ì›ë³¸ ì¿¼ë¦¬ í† í° ìˆ˜ ê³„ì‚°
            query_tokens = len(request.original_query.split()) * 1.3 if isinstance(request.original_query, str) else 10
            
            # ë‹µë³€ í† í° ìˆ˜ ê³„ì‚° (ì•ˆì „í•˜ê²Œ)
            answer_text = answer_json.get('answer', '')
            if isinstance(answer_text, list):
                # ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
                answer_text = ' '.join(str(item) for item in answer_text)
            elif not isinstance(answer_text, str):
                # ë¬¸ìì—´ì´ ì•„ë‹Œ ê²½ìš° ë¬¸ìì—´ë¡œ ë³€í™˜
                answer_text = str(answer_text)
            
            completion_tokens = len(answer_text.split()) * 1.3 if answer_text else 5
            
            token_usage = {
                "prompt_tokens": int(query_tokens),
                "completion_tokens": int(completion_tokens),
                "total_tokens": int(query_tokens + completion_tokens)
            }
        except Exception as e:
            print(f"âš ï¸ í† í° ê³„ì‚° ì˜¤ë¥˜: {e}, ê¸°ë³¸ê°’ ì‚¬ìš©")
            token_usage = {
                "prompt_tokens": 50,
                "completion_tokens": 100,
                "total_tokens": 150
            }
        
        print(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ ({generation_time:.1f}ms)")
        
        return AnswerResponse(
            query_id=request.query_id,
            answer=answer_json.get('answer', 'ë‹µë³€ ìƒì„± ì‹¤íŒ¨'),
            confidence=float(answer_json.get('confidence', 0.5)),
            sources_used=sources_used,
            generation_time_ms=generation_time,
            self_refined=self_refined,
            react_steps=react_steps,
            token_usage=token_usage
        ) 