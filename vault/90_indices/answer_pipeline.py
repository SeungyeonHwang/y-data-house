#!/usr/bin/env python3
"""
Prompt-Light ë‹µë³€ íŒŒì´í”„ë¼ì¸
ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ + Self-Refine (1íšŒ) + ReAct + JSON Schema

ì¡°ì–¸ ê¸°ë°˜ ìµœì í™”:
- ì±„ë„ë³„ 1-2ì¤„ í”„ë¡¬í”„íŠ¸ë§Œ ì‚¬ìš©
- Self-Refine 1íšŒë¡œ ì œí•œí•´ í† í° í­ì¦ ë°©ì§€  
- JSON Schema ê°•ì œë¡œ íŒŒì„œ ì˜¤ë¥˜ ê°ì†Œ
- ReActëŠ” ì¶”ê°€ ê²€ìƒ‰ í•„ìš”ì‹œì—ë§Œ
"""

import os
import time
import json
from typing import List, Dict, Optional, Any
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI
from schemas import (
    AnswerRequest, AnswerResponse, AnswerConfig, ChannelPrompt,
    SearchResult, AnswerStyle
)
from prompt_manager import PromptManager

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class AnswerPipeline:
    """Prompt-Light ë‹µë³€ ìƒì„± íŒŒì´í”„ë¼ì¸"""
    
    def __init__(self, model: str = "deepseek-chat", prompts_dir: Path = None):
        """ì´ˆê¸°í™”"""
        self.model = model
        
        # DeepSeek í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            api_key = os.getenv('DEEPSEEK_API_KEY')
            if not api_key:
                raise ValueError("DEEPSEEK_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
                
            self.client = OpenAI(
                api_key=api_key,
                base_url="https://api.deepseek.com/v1"
            )
            print(f"âœ… DeepSeek API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {model})")
        except Exception as e:
            raise ValueError(f"âŒ DeepSeek API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” (ì±„ë„ë³„ ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ìš©)
        try:
            self.prompt_manager = PromptManager(prompts_dir) if prompts_dir else None
            if self.prompt_manager:
                print(f"âœ… PromptManager ë¡œë“œë¨")
        except Exception as e:
            print(f"âš ï¸ PromptManager ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.prompt_manager = None
        
        # ê¸°ë³¸ JSON ìŠ¤í‚¤ë§ˆ í…œí”Œë¦¿
        self.default_schema = {
            "answer": "string - ë©”ì¸ ë‹µë³€ ë‚´ìš©",
            "key_points": ["string array - í•µì‹¬ í¬ì¸íŠ¸ë“¤"],
            "sources": ["string array - ì‚¬ìš©ëœ ì˜ìƒ IDë“¤"],
            "confidence": "number - ë‹µë³€ ì‹ ë¢°ë„ (0-1)",
            "summary": "string - í•œ ì¤„ ìš”ì•½"
        }
        
        print("ğŸ’¬ Answer Pipeline ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _load_channel_prompt(self, channel_name: str) -> ChannelPrompt:
        """ì±„ë„ë³„ ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ ë¡œë“œ"""
        if self.prompt_manager:
            try:
                prompt_data = self.prompt_manager.get_channel_prompt(channel_name)
                
                # ê²½ëŸ‰í™”: í•µì‹¬ ì •ë³´ë§Œ ì¶”ì¶œ
                return ChannelPrompt(
                    channel_name=channel_name,
                    persona=prompt_data.get('persona', f'{channel_name} ì±„ë„ ì „ë¬¸ê°€')[:100],  # 1-2ì¤„ë¡œ ì œí•œ
                    tone=prompt_data.get('tone', 'ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ìŠ¤íƒ€ì¼')[:50],
                    expertise_keywords=prompt_data.get('expertise_keywords', [])[:5],  # ìƒìœ„ 5ê°œë§Œ
                    system_prompt=prompt_data.get('system_prompt', 
                        f'ë‹¹ì‹ ì€ {channel_name} ì±„ë„ì˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” AIì…ë‹ˆë‹¤.')[:200]  # ê°„ê²°í•˜ê²Œ
                )
            except Exception as e:
                print(f"âš ï¸ ì±„ë„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        # ê¸°ë³¸ ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸
        return ChannelPrompt(
            channel_name=channel_name,
            persona=f'{channel_name} ì±„ë„ ì „ë¬¸ ë¶„ì„ê°€',
            tone='ì¹œê·¼í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ìŠ¤íƒ€ì¼',
            expertise_keywords=[],
            system_prompt=f'ë‹¹ì‹ ì€ {channel_name} ì±„ë„ì˜ ì˜ìƒ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.'
        )
    
    def _build_context(self, search_result: SearchResult, max_context_length: int = 2000) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ êµ¬ì„± (í† í° íš¨ìœ¨ì„± ê³ ë ¤)"""
        context_parts = []
        current_length = 0
        
        for i, doc in enumerate(search_result.documents):
            # ì˜ìƒ ì •ë³´ í—¤ë” (ê°„ê²°)
            header = f"[ì˜ìƒ {i+1}] {doc.title}"
            
            # ë‚´ìš© ìš”ì•½ (í† í° ì ˆì•½)
            content_preview = doc.content[:400] + "..." if len(doc.content) > 400 else doc.content
            
            part = f"{header}\n{content_preview}"
            part_length = len(part)
            
            if current_length + part_length > max_context_length:
                break
                
            context_parts.append(part)
            current_length += part_length
        
        return "\n\n".join(context_parts)
    
    def _get_json_schema_instruction(self, config: AnswerConfig) -> str:
        """JSON ìŠ¤í‚¤ë§ˆ ì§€ì‹œì‚¬í•­ ìƒì„±"""
        schema_fields = []
        
        if config.style == AnswerStyle.BULLET_POINTS:
            schema_fields = [
                f"answer: ìµœëŒ€ {config.max_bullets}ê°œ bullet pointë¡œ êµ¬ì„±ëœ ë©”ì¸ ë‹µë³€",
                "key_points: í•µì‹¬ í¬ì¸íŠ¸ ë°°ì—´ (3-5ê°œ)",
                "sources: ì‚¬ìš©ëœ ì˜ìƒ ID ë°°ì—´",
                f"confidence: ë‹µë³€ ì‹ ë¢°ë„ (0.0-1.0)",
                "summary: í•œ ì¤„ í•µì‹¬ ìš”ì•½"
            ]
        elif config.style == AnswerStyle.STRUCTURED:
            schema_fields = [
                "answer: êµ¬ì¡°í™”ëœ ë‹µë³€ (í—¤ë”©ê³¼ ì„¹ì…˜ í¬í•¨)",
                "key_points: ê° ì„¹ì…˜ë³„ í•µì‹¬ í¬ì¸íŠ¸",
                "sources: ì‚¬ìš©ëœ ì˜ìƒ ID ë°°ì—´", 
                "confidence: ë‹µë³€ ì‹ ë¢°ë„ (0.0-1.0)",
                "summary: ì „ì²´ ë‚´ìš© ìš”ì•½"
            ]
        else:
            schema_fields = [
                "answer: ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™”í˜• ë‹µë³€",
                "key_points: í•µì‹¬ ë‚´ìš© ìš”ì•½",
                "sources: ì‚¬ìš©ëœ ì˜ìƒ ID ë°°ì—´",
                "confidence: ë‹µë³€ ì‹ ë¢°ë„ (0.0-1.0)", 
                "summary: í•œ ì¤„ ìš”ì•½"
            ]
        
        return f"""

## ğŸ“ ì¶œë ¥ í˜•ì‹ (JSON)
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”:
```json
{{
  {chr(10).join([f'  "{field.split(":")[0]}": {field.split(":", 1)[1].strip()}' for field in schema_fields])}
}}
```

JSON ì™¸ì˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ëŠ” ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”."""
    
    def _extract_json_from_response(self, response_text: str) -> Dict[str, Any]:
        """LLM ì‘ë‹µì—ì„œ JSON ì¶”ì¶œ"""
        try:
            # JSON ì½”ë“œë¸”ë¡ ì°¾ê¸°
            import re
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', response_text, re.DOTALL)
            
            if json_match:
                json_str = json_match.group(1)
            else:
                # ì½”ë“œë¸”ë¡ ì—†ìœ¼ë©´ ì§ì ‘ JSON ì°¾ê¸°
                json_match = re.search(r'(\{.*\})', response_text, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # JSON íŒŒì‹±
            parsed_json = json.loads(json_str)
            
            # í•„ìˆ˜ í•„ë“œ ê²€ì¦
            required_fields = ['answer', 'confidence', 'sources']
            for field in required_fields:
                if field not in parsed_json:
                    raise ValueError(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
            
            return parsed_json
            
        except Exception as e:
            print(f"âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
            # Fallback: ê¸°ë³¸ êµ¬ì¡°ë¡œ ì‘ë‹µ
            return {
                "answer": response_text,
                "key_points": [],
                "sources": [],
                "confidence": 0.5,
                "summary": "JSON íŒŒì‹± ì‹¤íŒ¨ë¡œ ì¸í•œ ê¸°ë³¸ ì‘ë‹µ"
            }
    
    def _should_use_react(self, query: str, search_result: SearchResult) -> bool:
        """ReAct íŒ¨í„´ ì‚¬ìš© ì—¬ë¶€ ê²°ì •"""
        # ê²€ìƒ‰ ê²°ê³¼ê°€ ë¶€ì¡±í•˜ê±°ë‚˜ ì‹ ë¢°ë„ê°€ ë‚®ì„ ë•Œë§Œ
        if len(search_result.documents) < 2:
            return True
        
        avg_similarity = sum(doc.similarity for doc in search_result.documents) / len(search_result.documents)
        if avg_similarity < 0.4:
            return True
        
        # ë³µì¡í•œ ì¿¼ë¦¬ íŒ¨í„´ (ìµœì‹  ì •ë³´, ë¹„êµ, ì˜ˆì¸¡ ë“±)
        react_patterns = [
            r'\b(ìµœì‹ |ìµœê·¼|í˜„ì¬|ì§€ê¸ˆ|ì˜¤ëŠ˜)\b',
            r'\b(ë¹„êµ|ì°¨ì´|vs|ëŒ€ë¹„)\b', 
            r'\b(ì˜ˆì¸¡|ì „ë§|ë¯¸ë˜|ê³„íš)\b',
            r'\b(ì¶”ì²œ|ì œì•ˆ|ì¡°ì–¸)\b'
        ]
        
        import re
        for pattern in react_patterns:
            if re.search(pattern, query.lower()):
                return True
        
        return False
    
    def _apply_react_pattern(self, query: str, initial_context: str, channel_name: str) -> str:
        """ReAct íŒ¨í„´ ì ìš© (ì¶”ê°€ ì •ë³´ í•„ìš”ì‹œ)"""
        try:
            react_prompt = f"""ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í˜„ì¬ ì •ë³´ë¡œ ì§ˆë¬¸ì— ì™„ì „íˆ ë‹µí•  ìˆ˜ ìˆëŠ”ì§€ íŒë‹¨í•˜ì„¸ìš”.

## í˜„ì¬ ì§ˆë¬¸
{query}

## í˜„ì¬ ê°€ì§„ ì •ë³´
{initial_context[:500]}...

## íŒë‹¨ ê³¼ì • (ReAct)
Thought: í˜„ì¬ ì •ë³´ë¡œ ì§ˆë¬¸ì— ì¶©ë¶„íˆ ë‹µí•  ìˆ˜ ìˆëŠ”ê°€?
Action: [SUFFICIENT] ë˜ëŠ” [NEED_MORE_INFO: í•„ìš”í•œ ì •ë³´ ìœ í˜•]
Observation: ì •ë³´ ì¶©ì¡±ë„ í‰ê°€
Final Answer: ë‹¤ìŒ ë‹¨ê³„ ê²°ì •

ê°„ë‹¨íˆ íŒë‹¨ ê²°ê³¼ë§Œ ì‘ë‹µí•˜ì„¸ìš”: "SUFFICIENT" ë˜ëŠ” "NEED_MORE_INFO: ..."
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ ì •ë³´ í‰ê°€ìì…ë‹ˆë‹¤."},
                    {"role": "user", "content": react_prompt}
                ],
                max_tokens=100,
                temperature=0.3
            )
            
            result = response.choices[0].message.content.strip()
            print(f"ğŸ”§ ReAct íŒë‹¨: {result}")
            
            if "NEED_MORE_INFO" in result:
                return f"í˜„ì¬ ì •ë³´ë¡œëŠ” ë¶€ì¡±í•©ë‹ˆë‹¤. {result}"
            else:
                return "í˜„ì¬ ì •ë³´ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤."
                
        except Exception as e:
            print(f"âš ï¸ ReAct íŒ¨í„´ ì‹¤íŒ¨: {e}")
            return "í˜„ì¬ ì •ë³´ë¡œ ì¶©ë¶„í•©ë‹ˆë‹¤."
    
    def _generate_initial_answer(self, request: AnswerRequest) -> str:
        """ì´ˆê¸° ë‹µë³€ ìƒì„±"""
        # ì±„ë„ë³„ ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        channel_prompt = request.channel_prompt or self._load_channel_prompt(request.search_result.channel_name)
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context = self._build_context(request.search_result)
        
        # JSON ìŠ¤í‚¤ë§ˆ ì§€ì‹œì‚¬í•­
        json_instruction = self._get_json_schema_instruction(request.config)
        
        # ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_message = f"{channel_prompt.system_prompt} {channel_prompt.tone}ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”."
        
        user_prompt = f"""## ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ({request.search_result.channel_name} ì±„ë„)
{context}

## ì‚¬ìš©ì ì§ˆë¬¸
{request.original_query}

## ë‹µë³€ ìš”êµ¬ì‚¬í•­
- {request.search_result.channel_name} ì±„ë„ì˜ ì •ë³´ë§Œ í™œìš©
- {request.config.style.value} ìŠ¤íƒ€ì¼ë¡œ ì‘ì„±
- ì¶œì²˜ë¥¼ ëª…í™•íˆ í‘œì‹œ ([ì˜ìƒ 1], [ì˜ìƒ 2] ë“±)
- ëª¨ë¥´ëŠ” ë‚´ìš©ì€ ì¶”ì¸¡í•˜ì§€ ë§ê³  "ì •ë³´ ë¶€ì¡±" ëª…ì‹œ

{json_instruction}"""
        
        try:
            start_time = time.time()
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": system_message},
                    {"role": "user", "content": user_prompt}
                ],
                max_tokens=request.config.max_tokens,
                temperature=request.config.temperature
            )
            
            generation_time = (time.time() - start_time) * 1000
            initial_answer = response.choices[0].message.content.strip()
            
            print(f"ğŸ“ ì´ˆê¸° ë‹µë³€ ìƒì„± ì™„ë£Œ ({generation_time:.1f}ms)")
            return initial_answer
            
        except Exception as e:
            print(f"âŒ ì´ˆê¸° ë‹µë³€ ìƒì„± ì‹¤íŒ¨: {e}")
            return json.dumps({
                "answer": f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}",
                "key_points": [],
                "sources": [],
                "confidence": 0.0,
                "summary": "ì˜¤ë¥˜ ë°œìƒ"
            }, ensure_ascii=False)
    
    def _apply_self_refine(self, initial_answer: str, query: str, channel_name: str) -> str:
        """Self-Refine 1íšŒ ì ìš© (í† í° í­ì¦ ë°©ì§€)"""
        try:
            # ì´ˆê¸° ë‹µë³€ì—ì„œ JSON ì¶”ì¶œ
            initial_json = self._extract_json_from_response(initial_answer)
            
            if initial_json.get('confidence', 0) > 0.8:
                print("ğŸ¯ ì´ˆê¸° ë‹µë³€ ì‹ ë¢°ë„ ë†’ìŒ, Self-Refine ìƒëµ")
                return initial_answer
            
            refine_prompt = f"""ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ ë‹µë³€ í’ˆì§ˆ ê²€í† ìì…ë‹ˆë‹¤.

## ì›ë³¸ ì§ˆë¬¸
{query}

## ì´ˆê¸° ë‹µë³€ (JSON)
{json.dumps(initial_json, ensure_ascii=False, indent=2)}

## ê°œì„  ì§€ì‹œì‚¬í•­
1. ë‹µë³€ì˜ ì •í™•ì„±ê³¼ ì™„ì„±ë„ë¥¼ ê²€í† 
2. ëˆ„ë½ëœ ì¤‘ìš” ì •ë³´ê°€ ìˆëŠ”ì§€ í™•ì¸  
3. ì¶œì²˜ í‘œì‹œê°€ ì ì ˆí•œì§€ ì ê²€
4. ì‹ ë¢°ë„ë¥¼ ì¬í‰ê°€

ê°œì„ ëœ ë‹µë³€ì„ ë™ì¼í•œ JSON í˜•ì‹ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. 20% ì´ìƒ í’ˆì§ˆ ê°œì„ ì„ ëª©í‘œë¡œ í•˜ë˜, ê¸°ì¡´ ë‹µë³€ì´ ì´ë¯¸ ìš°ìˆ˜í•˜ë‹¤ë©´ ìœ ì§€í•˜ì„¸ìš”."""

            start_time = time.time()
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ ë‹µë³€ ê²€í† ìì…ë‹ˆë‹¤."},
                    {"role": "user", "content": refine_prompt}
                ],
                max_tokens=800,
                temperature=0.5
            )
            
            refine_time = (time.time() - start_time) * 1000
            refined_answer = response.choices[0].message.content.strip()
            
            print(f"âœ¨ Self-Refine ì™„ë£Œ ({refine_time:.1f}ms)")
            return refined_answer
            
        except Exception as e:
            print(f"âš ï¸ Self-Refine ì‹¤íŒ¨: {e}")
            return initial_answer
    
    def generate_answer(self, request: AnswerRequest) -> AnswerResponse:
        """ë©”ì¸ ë‹µë³€ ìƒì„± íŒŒì´í”„ë¼ì¸"""
        start_time = time.time()
        
        print(f"ğŸ’¬ ë‹µë³€ ìƒì„± ì‹œì‘: {request.query_id}")
        
        # 0. ReAct íŒ¨í„´ ì ìš© ì—¬ë¶€ íŒë‹¨
        react_steps = []
        if request.config.enable_react:
            context_preview = self._build_context(request.search_result, 500)
            if self._should_use_react(request.original_query, request.search_result):
                react_result = self._apply_react_pattern(request.original_query, context_preview, request.search_result.channel_name)
                react_steps.append(react_result)
        
        # 1. ì´ˆê¸° ë‹µë³€ ìƒì„±
        initial_answer = self._generate_initial_answer(request)
        
        # 2. Self-Refine ì ìš© (1íšŒ ì œí•œ)
        final_answer = initial_answer
        self_refined = False
        
        if request.config.enable_self_refine:
            refined_answer = self._apply_self_refine(initial_answer, request.original_query, request.search_result.channel_name)
            if refined_answer != initial_answer:
                final_answer = refined_answer
                self_refined = True
        
        # 3. JSON íŒŒì‹± ë° ê²€ì¦
        answer_json = self._extract_json_from_response(final_answer)
        
        # 4. ì‚¬ìš©ëœ ì†ŒìŠ¤ ì¶”ì¶œ
        sources_used = []
        for doc in request.search_result.documents:
            if any(doc.video_id in str(answer_json.get(field, '')) for field in ['answer', 'key_points']):
                sources_used.append(doc.video_id)
        
        # ì†ŒìŠ¤ê°€ ë¹„ì–´ìˆìœ¼ë©´ ê²€ìƒ‰ëœ ì˜ìƒë“¤ í¬í•¨
        if not sources_used:
            sources_used = [doc.video_id for doc in request.search_result.documents[:3]]
        
        generation_time = (time.time() - start_time) * 1000
        
        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì • (ê°„ë‹¨í•œ ê³„ì‚°)
        token_usage = {
            "prompt_tokens": len(request.original_query.split()) * 1.3,  # ê·¼ì‚¬ì¹˜
            "completion_tokens": len(answer_json.get('answer', '').split()) * 1.3,
            "total_tokens": 0
        }
        token_usage["total_tokens"] = token_usage["prompt_tokens"] + token_usage["completion_tokens"]
        
        print(f"âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ ({generation_time:.1f}ms)")
        
        return AnswerResponse(
            query_id=request.query_id,
            answer=answer_json.get('answer', 'ë‹µë³€ ìƒì„± ì‹¤íŒ¨'),
            confidence=float(answer_json.get('confidence', 0.5)),
            sources_used=sources_used,
            generation_time_ms=generation_time,
            self_refined=self_refined,
            react_steps=react_steps,
            token_usage=token_usage
        ) 