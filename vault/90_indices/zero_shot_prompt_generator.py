#!/usr/bin/env python3
"""
ì œë¡œìƒ· í”„ë¡¬í”„íŠ¸ ìë™ ìƒì„± ì‹œìŠ¤í…œ - Y-Data-House
AIê°€ ì±„ë„ ì •ë³´ë¥¼ ë¶„ì„í•´ì„œ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ ìë™ ìƒì„±
"""

import json
import os
from pathlib import Path
from typing import Dict, List, Optional
from datetime import datetime
import re
from dotenv import load_dotenv
from openai import OpenAI
import chromadb
from chromadb.config import Settings as ChromaSettings

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

class ZeroShotPromptGenerator:
    """ì œë¡œìƒ· ë°©ì‹ í”„ë¡¬í”„íŠ¸ ìë™ ìƒì„±ê¸°"""
    
    def __init__(self, chroma_path: Path = None, model: str = "gpt-4"):
        """ì´ˆê¸°í™”"""
        self.chroma_path = chroma_path or Path(__file__).parent / "chroma"
        self.model = model
        
        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (DeepSeek í˜¸í™˜)
        api_key = os.getenv("DEEPSEEK_API_KEY") or os.getenv("OPENAI_API_KEY")
        base_url = os.getenv("DEEPSEEK_BASE_URL", "https://api.deepseek.com")
        
        if not api_key:
            raise ValueError("âŒ DEEPSEEK_API_KEY ë˜ëŠ” OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤")
        
        self.client = OpenAI(
            api_key=api_key,
            base_url=base_url if "deepseek" in model else None
        )
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.chroma_client = chromadb.PersistentClient(
                path=str(self.chroma_path),
                settings=ChromaSettings(anonymized_telemetry=False)
            )
            print(f"âœ… ChromaDB ì—°ê²°ë¨: {self.chroma_path}")
        except Exception as e:
            raise ValueError(f"âŒ ChromaDB ë¡œë“œ ì‹¤íŒ¨: {e}")
        
        print(f"ğŸ¤– ì œë¡œìƒ· í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {model})")
    
    def _find_collection_by_channel_name(self, channel_name: str):
        """ì±„ë„ëª…ìœ¼ë¡œ ì‹¤ì œ ì»¬ë ‰ì…˜ ì°¾ê¸° (channel_analyzerì™€ ë™ì¼í•œ ë¡œì§)"""
        try:
            collections = self.chroma_client.list_collections()
            
            for collection in collections:
                if collection.name.startswith("channel_"):
                    # ì»¬ë ‰ì…˜ì—ì„œ ìƒ˜í”Œ ë°ì´í„° ê°€ì ¸ì™€ì„œ ì±„ë„ëª… í™•ì¸
                    try:
                        sample = collection.get(limit=1, include=['metadatas'])
                        if sample['metadatas'] and sample['metadatas'][0]:
                            metadata_channel = sample['metadatas'][0].get('channel', '')
                            if metadata_channel == channel_name:
                                return collection
                    except:
                        continue
            
            print(f"ğŸ“‹ ì‚¬ìš© ê°€ëŠ¥í•œ ì»¬ë ‰ì…˜ë“¤:")
            for collection in collections:
                if collection.name.startswith("channel_"):
                    try:
                        sample = collection.get(limit=1, include=['metadatas'])
                        if sample['metadatas'] and sample['metadatas'][0]:
                            metadata_channel = sample['metadatas'][0].get('channel', 'ì•Œ ìˆ˜ ì—†ìŒ')
                            print(f"  - {collection.name} â†’ {metadata_channel}")
                    except:
                        print(f"  - {collection.name} â†’ ë©”íƒ€ë°ì´í„° í™•ì¸ ë¶ˆê°€")
            
            return None
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None
    
    def get_channel_summary(self, channel_name: str) -> Dict:
        """ì±„ë„ì˜ ìš”ì•½ ì •ë³´ ì¶”ì¶œ"""
        try:
            # ì˜¬ë°”ë¥¸ ì»¬ë ‰ì…˜ ì°¾ê¸° (channel_analyzerì™€ ë™ì¼í•œ ë¡œì§ ì‚¬ìš©)
            target_collection = self._find_collection_by_channel_name(channel_name)
            
            if not target_collection:
                print(f"âŒ {channel_name} ì±„ë„ì˜ ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                return {}
            
            # ì „ì²´ ë¬¸ì„œ ì¡°íšŒ
            results = target_collection.get()
            documents = results['documents']
            metadatas = results['metadatas'] if results['metadatas'] else []
            
            if not documents:
                print(f"âŒ {channel_name} ì±„ë„ì— ë¬¸ì„œê°€ ì—†ìŠµë‹ˆë‹¤")
                return {}
            
            # ì±„ë„ ìš”ì•½ ì •ë³´ êµ¬ì„±
            summary = {
                'channel_name': channel_name,
                'total_documents': len(documents),
                'sample_documents': documents[:5],  # ì²« 5ê°œ ë¬¸ì„œ ìƒ˜í”Œ
                'video_titles': [],
                'content_keywords': self._extract_keywords_simple(documents),
                'content_length_stats': self._analyze_content_length(documents),
                'metadata_insights': self._analyze_metadata_simple(metadatas)
            }
            
            # ë¹„ë””ì˜¤ ì œëª© ì¶”ì¶œ
            for metadata in metadatas[:10]:  # ì²« 10ê°œë§Œ
                if isinstance(metadata, dict) and 'title' in metadata:
                    summary['video_titles'].append(metadata['title'])
            
            return summary
            
        except Exception as e:
            print(f"âŒ ì±„ë„ ìš”ì•½ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return {}
    
    def _extract_keywords_simple(self, documents: List[str]) -> List[str]:
        """ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ"""
        all_text = ' '.join(documents)
        
        # í•œê¸€/ì˜ì–´/ìˆ«ìë§Œ ìœ ì§€
        cleaned = re.sub(r'[^\wê°€-í£\s]', ' ', all_text)
        words = cleaned.split()
        
        # ë‹¨ì–´ ë¹ˆë„ ê³„ì‚° (ê¸¸ì´ 2 ì´ìƒ)
        word_count = {}
        for word in words:
            if len(word) >= 2:
                word_count[word] = word_count.get(word, 0) + 1
        
        # ìƒìœ„ 20ê°œ í‚¤ì›Œë“œ ë°˜í™˜
        sorted_words = sorted(word_count.items(), key=lambda x: x[1], reverse=True)
        return [word for word, count in sorted_words[:20]]
    
    def _analyze_content_length(self, documents: List[str]) -> Dict:
        """ì½˜í…ì¸  ê¸¸ì´ ë¶„ì„"""
        lengths = [len(doc) for doc in documents]
        return {
            'avg_length': sum(lengths) / len(lengths) if lengths else 0,
            'max_length': max(lengths) if lengths else 0,
            'min_length': min(lengths) if lengths else 0
        }
    
    def _analyze_metadata_simple(self, metadatas: List[Dict]) -> Dict:
        """ë©”íƒ€ë°ì´í„° ê°„ë‹¨ ë¶„ì„"""
        insights = {
            'video_count': len(metadatas),
            'has_timestamps': False,
            'has_descriptions': False
        }
        
        for metadata in metadatas:
            if isinstance(metadata, dict):
                if 'timestamp' in metadata or 'upload_date' in metadata:
                    insights['has_timestamps'] = True
                if 'description' in metadata:
                    insights['has_descriptions'] = True
        
        return insights
    
    def generate_prompt_with_ai(self, channel_summary: Dict) -> Dict:
        """AIë¥¼ í™œìš©í•œ ì œë¡œìƒ· í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        if not channel_summary:
            return self._get_fallback_prompt()
        
        # ë©”íƒ€ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        meta_prompt = self._build_meta_prompt(channel_summary)
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {
                        "role": "system", 
                        "content": "ë‹¹ì‹ ì€ YouTube ì±„ë„ë³„ ë§ì¶¤ AI í”„ë¡¬í”„íŠ¸ ì„¤ê³„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì±„ë„ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì í™”ëœ í”„ë¡¬í”„íŠ¸ë¥¼ JSON í˜•íƒœë¡œ ìƒì„±í•´ì£¼ì„¸ìš”."
                    },
                    {
                        "role": "user", 
                        "content": meta_prompt
                    }
                ],
                max_tokens=1500,
                temperature=0.3  # ì¼ê´€ì„±ì„ ìœ„í•´ ë‚®ì€ ì˜¨ë„
            )
            
            # JSON íŒŒì‹±
            ai_response = response.choices[0].message.content.strip()
            prompt_data = self._parse_ai_response(ai_response, channel_summary)
            
            return prompt_data
            
        except Exception as e:
            print(f"âŒ AI í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return self._get_fallback_prompt(channel_summary.get('channel_name', 'unknown'))
    
    def _build_meta_prompt(self, channel_summary: Dict) -> str:
        """Prompt-Light ë©”íƒ€ í”„ë¡¬í”„íŠ¸ ìƒì„± (Search-First ì•„í‚¤í…ì²˜ ë°˜ì˜)"""
        channel_name = channel_summary.get('channel_name', 'Unknown')
        total_docs = channel_summary.get('total_documents', 0)
        keywords = ', '.join(channel_summary.get('content_keywords', [])[:8])  # 8ê°œë¡œ ì œí•œ
        video_titles = channel_summary.get('video_titles', [])[:3]  # 3ê°œë¡œ ì œí•œ
        
        # ê°„ë‹¨í•œ ì½˜í…ì¸  ë¯¸ë¦¬ë³´ê¸° (1ê°œë§Œ)
        content_preview = ""
        if channel_summary.get('sample_documents'):
            sample = channel_summary['sample_documents'][0]
            preview = sample[:200] + "..." if len(sample) > 200 else sample
            content_preview = f"ëŒ€í‘œ ì½˜í…ì¸ : {preview}"
        
        meta_prompt = f"""
Y-Data-House RAG v7.0 "Search-First & Prompt-Light" ì•„í‚¤í…ì²˜ìš© ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

## ğŸ“Š ì±„ë„ ì •ë³´
- ì±„ë„: {channel_name}
- ë¬¸ì„œ: {total_docs}ê°œ
- í‚¤ì›Œë“œ: {keywords}
- ëŒ€í‘œ ì˜ìƒ: {', '.join(video_titles)}
{content_preview}

## ğŸ¯ ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ ì² í•™
"Search-First & Prompt-Light" - ê²€ìƒ‰ í’ˆì§ˆì„ 'í•˜ë“œ'í•˜ê²Œ ì˜¬ë¦¬ê³ , í”„ë¡¬í”„íŠ¸ëŠ” 'ì‹¬í”Œ+ê²€ì¦'ìœ¼ë¡œ ìœ ì§€
âœ… 4ë‹¨ê³„ ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸ì´ ì´ë¯¸ ê³ í’ˆì§ˆ ê²€ìƒ‰ ìˆ˜í–‰
âœ… í”„ë¡¬í”„íŠ¸ëŠ” ê²½ëŸ‰í™”í•˜ì—¬ í† í° íš¨ìœ¨ì„± ê·¹ëŒ€í™”
âœ… ê°„ë‹¨í•œ ì§€ì¹¨ìœ¼ë¡œ ë¹ ë¥¸ ì‘ë‹µ (<500ms ëª©í‘œ)

## ğŸ“ ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ ìš”êµ¬ì‚¬í•­
ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œ **ê°„ë‹¨í•˜ê³  í•µì‹¬ì ì¸** í”„ë¡¬í”„íŠ¸ë§Œ ìƒì„±:

```json
{{
  "persona": "ì±„ë„ ì „ë¬¸ê°€ (1-2ì¤„, 100ì ì´ë‚´)",
  "tone": "ë‹µë³€ ìŠ¤íƒ€ì¼ (1ì¤„, 50ì ì´ë‚´)", 
  "system_prompt": "AI ì—­í•  ê°„ë‹¨ ì„¤ëª… (150ì ì´ë‚´)",
  "expertise_keywords": ["í•µì‹¬ í‚¤ì›Œë“œ 5ê°œ ì´í•˜"],
  "target_audience": "ì£¼ìš” ì‚¬ìš©ìì¸µ (50ì ì´ë‚´)"
}}
```

## âš¡ ì¤‘ìš” ì œì•½ì‚¬í•­
1. **ê·¹ë„ë¡œ ê°„ê²°**: persona(100ì), tone(50ì), system_prompt(150ì) ì œí•œ
2. **ê²€ìƒ‰ ì˜ì¡´**: "ì±„ë„ ì˜ìƒì„ ë°”íƒ•ìœ¼ë¡œ" ì •ë„ë¡œë§Œ ì–¸ê¸‰ (ê²€ìƒ‰ì€ ì´ë¯¸ ê³ ë„í™”ë¨)
3. **ë³µì¡í•œ ê·œì¹™ ê¸ˆì§€**: ê¸°ì¡´ì˜ ë³µì¡í•œ output_format, self_refine ì„¤ì • ë¶ˆí•„ìš”
4. **í‚¤ì›Œë“œ ì¤‘ì‹¬**: expertise_keywords 5ê°œ ì´í•˜ë¡œ í•µì‹¬ë§Œ
5. **ì‹¤ìš©ì„± ìš°ì„ **: ì‚¬ìš©ìê°€ ë°”ë¡œ ì´í•´í•  ìˆ˜ ìˆëŠ” ë‹¨ìˆœí•œ ì„¤ëª…

## ì˜ˆì‹œ (ì°¸ê³ ìš©)
```json
{{
  "persona": "ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ì ì „ë¬¸ ì»¨ì„¤í„´íŠ¸",
  "tone": "ì¹œê·¼í•˜ê³  ë°ì´í„° ê¸°ë°˜", 
  "system_prompt": "ì±„ë„ ì˜ìƒì„ ë°”íƒ•ìœ¼ë¡œ ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ìì— ëŒ€í•œ ì‹¤ìš©ì  ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.",
  "expertise_keywords": ["ë„ì¿„ ì•„íŒŒíŠ¸", "íˆ¬ì ìˆ˜ìµë¥ ", "ì§€ì—­ ë¶„ì„", "êµ¬ë§¤ ì „ëµ"],
  "target_audience": "ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ì ê´€ì‹¬ì"
}}
```

**{channel_name} ì±„ë„ì— ìµœì í™”ëœ ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ JSONì„ ìƒì„±í•´ì£¼ì„¸ìš”:**
"""
        
        return meta_prompt.strip()
    
    def _parse_ai_response(self, ai_response: str, channel_summary: Dict) -> Dict:
        """AI ì‘ë‹µ íŒŒì‹± ë° ê²€ì¦ (Prompt-Light ë²„ì „)"""
        try:
            # JSON ë¶€ë¶„ë§Œ ì¶”ì¶œ
            json_match = re.search(r'```json\s*(\{.*?\})\s*```', ai_response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
            else:
                # JSON ì½”ë“œë¸”ë¡ì´ ì—†ìœ¼ë©´ ì „ì²´ì—ì„œ JSON ì°¾ê¸°
                json_match = re.search(r'(\{.*\})', ai_response, re.DOTALL)
                if json_match:
                    json_str = json_match.group(1)
                else:
                    raise ValueError("JSON í˜•ì‹ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            
            # JSON íŒŒì‹±
            prompt_data = json.loads(json_str)
            
            # ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ í•„ë“œ ê¸¸ì´ ì œí•œ ì ìš©
            if 'persona' in prompt_data:
                prompt_data['persona'] = prompt_data['persona'][:100]  # 100ì ì œí•œ
            if 'tone' in prompt_data:
                prompt_data['tone'] = prompt_data['tone'][:50]       # 50ì ì œí•œ
            if 'system_prompt' in prompt_data:
                prompt_data['system_prompt'] = prompt_data['system_prompt'][:200]  # 150ì â†’ 200ì ì—¬ìœ 
            if 'target_audience' in prompt_data:
                prompt_data['target_audience'] = prompt_data['target_audience'][:50]  # 50ì ì œí•œ
            if 'expertise_keywords' in prompt_data and isinstance(prompt_data['expertise_keywords'], list):
                prompt_data['expertise_keywords'] = prompt_data['expertise_keywords'][:5]  # 5ê°œ ì œí•œ
            
            # ê¸°ë³¸ ë©”íƒ€ë°ì´í„° ì¶”ê°€ (Prompt-Light ë©”íƒ€ë°ì´í„°)
            prompt_data.update({
                "version": 1,
                "channel_name": channel_summary.get('channel_name', 'unknown'),
                "created_at": datetime.now().isoformat(),
                "auto_generated": True,
                "generation_method": "prompt_light_ai",  # ìƒˆë¡œìš´ ë°©ì‹ì„ì„ ëª…ì‹œ
                "model_used": self.model,
                "source_documents": channel_summary.get('total_documents', 0),
                "architecture": "search_first_prompt_light"  # ì•„í‚¤í…ì²˜ ë²„ì „ ëª…ì‹œ
            })
            
            # í•„ìˆ˜ ê²½ëŸ‰ í•„ë“œ ê²€ì¦ ë° ê¸°ë³¸ê°’ ì„¤ì •
            light_required_fields = {
                'persona': f'{channel_summary.get("channel_name", "unknown")} ì±„ë„ ì „ë¬¸ê°€',
                'tone': 'ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ìŠ¤íƒ€ì¼',
                'system_prompt': f'ì±„ë„ ì˜ìƒì„ ë°”íƒ•ìœ¼ë¡œ {channel_summary.get("channel_name", "ì •ë³´")}ì— ëŒ€í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.',
                'expertise_keywords': [],
                'target_audience': 'ê´€ì‹¬ ìˆëŠ” ì¼ë°˜ ì‚¬ìš©ì'
            }
            
            for field, default_value in light_required_fields.items():
                if field not in prompt_data:
                    print(f"âš ï¸ í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}, ê¸°ë³¸ê°’ ì„¤ì •")
                    prompt_data[field] = default_value
            
            # ê¸°ì¡´ ë³µì¡í•œ í•„ë“œë“¤ ì œê±° (ìƒˆ ì•„í‚¤í…ì²˜ì—ì„œ ë¶ˆí•„ìš”)
            deprecated_fields = [
                'rules', 'output_format', 'tooling', 'self_refine', 
                'response_schema', 'quality_metrics', 'unique_value'
            ]
            for field in deprecated_fields:
                if field in prompt_data:
                    del prompt_data[field]
            
            print(f"âœ… Prompt-Light í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")
            print(f"   í˜ë¥´ì†Œë‚˜: {prompt_data['persona'][:50]}...")
            print(f"   í‚¤ì›Œë“œ: {len(prompt_data.get('expertise_keywords', []))}ê°œ")
            
            return prompt_data
            
        except Exception as e:
            print(f"âŒ AI ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            print(f"ì›ë³¸ ì‘ë‹µ: {ai_response[:300]}...")
            return self._get_fallback_prompt(channel_summary.get('channel_name', 'unknown'))
    
    def _get_default_field_value(self, field: str) -> str:
        """ëˆ„ë½ëœ í•„ë“œì˜ ê¸°ë³¸ê°’ ë°˜í™˜ (Prompt-Light ë²„ì „)"""
        defaults = {
            'persona': 'YouTube ì±„ë„ ì „ë¬¸ ë¶„ì„ê°€',
            'tone': 'ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ìŠ¤íƒ€ì¼',
            'system_prompt': 'ì±„ë„ ì˜ìƒì„ ë°”íƒ•ìœ¼ë¡œ ì •í™•í•˜ê³  ìœ ìš©í•œ ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.',
            'target_audience': 'ê´€ì‹¬ ìˆëŠ” ì¼ë°˜ ì‚¬ìš©ì'
        }
        return defaults.get(field, '')
    
    def _get_fallback_prompt(self, channel_name: str = "unknown") -> Dict:
        """AI ìƒì„± ì‹¤íŒ¨ ì‹œ ê²½ëŸ‰ í´ë°± í”„ë¡¬í”„íŠ¸"""
        return {
            "version": 1,
            "channel_name": channel_name,
            "created_at": datetime.now().isoformat(),
            "auto_generated": True,
            "generation_method": "prompt_light_fallback",
            "architecture": "search_first_prompt_light",
            "persona": f"{channel_name} ì±„ë„ ì „ë¬¸ ë¶„ì„ê°€",
            "tone": "ì¹œê·¼í•˜ê³  ì „ë¬¸ì ì¸ ìŠ¤íƒ€ì¼",
            "system_prompt": f"ì±„ë„ ì˜ìƒì„ ë°”íƒ•ìœ¼ë¡œ {channel_name}ì— ëŒ€í•œ ì‹¤ìš©ì  ì¡°ì–¸ì„ ì œê³µí•©ë‹ˆë‹¤.",
            "expertise_keywords": [],
            "target_audience": f"{channel_name} ê´€ì‹¬ì"
        }
    
    def generate_channel_prompt(self, channel_name: str) -> Dict:
        """ì±„ë„ë³„ ì œë¡œìƒ· í”„ë¡¬í”„íŠ¸ ìƒì„± (ë©”ì¸ í•¨ìˆ˜)"""
        print(f"ğŸ” {channel_name} ì±„ë„ ì •ë³´ ìˆ˜ì§‘ ì¤‘...")
        
        # 1. ì±„ë„ ìš”ì•½ ì •ë³´ ìˆ˜ì§‘
        channel_summary = self.get_channel_summary(channel_name)
        if not channel_summary:
            print(f"âŒ {channel_name} ì±„ë„ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
            return {}
        
        print(f"ğŸ“Š ì±„ë„ ë¶„ì„ ì™„ë£Œ: {channel_summary['total_documents']}ê°œ ë¬¸ì„œ")
        print(f"ğŸ”‘ ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(channel_summary['content_keywords'][:5])}")
        
        # 2. AIë¡œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        print(f"ğŸ¤– AI í”„ë¡¬í”„íŠ¸ ìƒì„± ì¤‘... (ëª¨ë¸: {self.model})")
        prompt_data = self.generate_prompt_with_ai(channel_summary)
        
        if prompt_data:
            print(f"âœ… {channel_name} ì œë¡œìƒ· í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ!")
            print(f"ğŸ“ í˜ë¥´ì†Œë‚˜: {prompt_data.get('persona', 'N/A')}")
            print(f"ğŸ¯ ì „ë¬¸ë¶„ì•¼: {', '.join(prompt_data.get('expertise_keywords', [])[:3])}")
            return prompt_data
        else:
            print(f"âŒ {channel_name} í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹¤íŒ¨")
            return {}


def main():
    """í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
    try:
        # ì œë¡œìƒ· ìƒì„±ê¸° ì´ˆê¸°í™”
        generator = ZeroShotPromptGenerator(model="deepseek-chat")
        
        # ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ í™•ì¸
        collections = generator.chroma_client.list_collections()
        if not collections:
            print("âŒ ë¶„ì„ ê°€ëŠ¥í•œ ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤")
            print("ğŸ’¡ ë¨¼ì € 'python embed.py'ë¡œ ë²¡í„° ì„ë² ë”©ì„ ìƒì„±í•˜ì„¸ìš”")
            return
        
        channel_names = [c.name for c in collections]
        print(f"ğŸ“º ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ({len(channel_names)}ê°œ):")
        for i, name in enumerate(channel_names, 1):
            print(f"  {i}. {name}")
        
        # ì²« ë²ˆì§¸ ì±„ë„ë¡œ í…ŒìŠ¤íŠ¸
        if channel_names:
            test_channel = channel_names[0]
            print(f"\nğŸ§ª {test_channel} ì œë¡œìƒ· í”„ë¡¬í”„íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸...")
            
            prompt_data = generator.generate_channel_prompt(test_channel)
            
            if prompt_data:
                print(f"\nğŸ“‹ ìƒì„±ëœ í”„ë¡¬í”„íŠ¸ ë¯¸ë¦¬ë³´ê¸°:")
                print(f"  í˜ë¥´ì†Œë‚˜: {prompt_data.get('persona', 'N/A')}")
                print(f"  í†¤: {prompt_data.get('tone', 'N/A')}")
                print(f"  ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸: {prompt_data.get('system_prompt', 'N/A')[:100]}...")
                print(f"  ê·œì¹™ ìˆ˜: {len(prompt_data.get('rules', []))}")
                print(f"  ìƒì„± ë°©ë²•: {prompt_data.get('generation_method', 'N/A')}")
            
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")


if __name__ == "__main__":
    main() 