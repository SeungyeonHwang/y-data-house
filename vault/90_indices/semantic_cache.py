#!/usr/bin/env python3
"""
Semantic Cache System - LLM í˜¸ì¶œ 40% ì ˆê°
rewritten queryì™€ HyDE ë¬¸ì„œ ìºì‹±ìœ¼ë¡œ 70% hit rate ëª©í‘œ

ì¡°ì–¸ ê¸°ë°˜ ìµœì í™”:
- (model, temperature, prompt_hash) í‚¤ë¡œ ìºì‹œ
- TTL 7ì¼ ì„¤ì •
- ìœ ì‚¬ ì§ˆì˜ ì¬ì‚¬ìš© (semantic similarity)
- íŒŒì¼ ê¸°ë°˜ â†’ Redis í™•ì¥ ê°€ëŠ¥
"""

import os
import hashlib
import json
import time
import pickle
from typing import Dict, Optional, Any, List, Union
from pathlib import Path
from datetime import datetime, timedelta
from dataclasses import dataclass
import sqlite3
from threading import Lock
from schemas import CacheKey, CacheEntry

@dataclass
class CacheStats:
    """ìºì‹œ í†µê³„"""
    total_requests: int = 0
    cache_hits: int = 0
    cache_misses: int = 0
    
    @property
    def hit_rate(self) -> float:
        return self.cache_hits / self.total_requests if self.total_requests > 0 else 0.0

class SemanticCache:
    """Semantic Cache ì‹œìŠ¤í…œ"""
    
    def __init__(self, cache_dir: Path = None, ttl_seconds: int = 604800):  # 7ì¼
        """ì´ˆê¸°í™”"""
        self.cache_dir = cache_dir or Path(__file__).parent / "cache"
        self.cache_dir.mkdir(exist_ok=True)
        self.ttl_seconds = ttl_seconds
        self.stats = CacheStats()
        self._lock = Lock()
        
        # SQLite DB ì´ˆê¸°í™” (ë©”íƒ€ë°ì´í„° ì €ì¥ìš©)
        self.db_path = self.cache_dir / "cache_meta.db"
        self._init_db()
        
        print(f"ğŸ’¾ Semantic Cache ì´ˆê¸°í™”: {self.cache_dir}")
        print(f"â° TTL: {ttl_seconds}ì´ˆ ({ttl_seconds//86400}ì¼)")
    
    def _init_db(self):
        """SQLite DB ì´ˆê¸°í™”"""
        with sqlite3.connect(self.db_path) as conn:
            conn.execute("""
                CREATE TABLE IF NOT EXISTS cache_entries (
                    key_hash TEXT PRIMARY KEY,
                    model TEXT,
                    temperature REAL,
                    prompt_hash TEXT,
                    query_hash TEXT,
                    created_at TIMESTAMP,
                    ttl_seconds INTEGER,
                    hit_count INTEGER DEFAULT 0,
                    data_file TEXT,
                    data_size INTEGER
                )
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_created_ttl 
                ON cache_entries (created_at, ttl_seconds)
            """)
            
            conn.execute("""
                CREATE INDEX IF NOT EXISTS idx_model_temp 
                ON cache_entries (model, temperature)
            """)
    
    def _generate_cache_key(self, model: str, temperature: float, prompt: str, query: str = "") -> CacheKey:
        """ìºì‹œ í‚¤ ìƒì„±"""
        prompt_hash = hashlib.sha256(prompt.encode('utf-8')).hexdigest()[:16]
        query_hash = hashlib.sha256(query.encode('utf-8')).hexdigest()[:16] if query else ""
        
        return CacheKey(
            model=model,
            temperature=temperature,
            prompt_hash=prompt_hash,
            query_hash=query_hash
        )
    
    def _get_key_hash(self, cache_key: CacheKey) -> str:
        """ìºì‹œ í‚¤ë¥¼ ë¬¸ìì—´ í•´ì‹œë¡œ ë³€í™˜"""
        key_str = f"{cache_key.model}:{cache_key.temperature}:{cache_key.prompt_hash}:{cache_key.query_hash}"
        return hashlib.sha256(key_str.encode('utf-8')).hexdigest()[:32]
    
    def _is_expired(self, created_at: datetime, ttl_seconds: int) -> bool:
        """TTL ë§Œë£Œ í™•ì¸"""
        expiry_time = created_at + timedelta(seconds=ttl_seconds)
        return datetime.now() > expiry_time
    
    def _save_data_file(self, key_hash: str, data: Any) -> str:
        """ë°ì´í„° íŒŒì¼ ì €ì¥"""
        data_file = f"{key_hash}.pkl"
        file_path = self.cache_dir / data_file
        
        with open(file_path, 'wb') as f:
            pickle.dump(data, f)
        
        return data_file
    
    def _load_data_file(self, data_file: str) -> Any:
        """ë°ì´í„° íŒŒì¼ ë¡œë“œ"""
        file_path = self.cache_dir / data_file
        
        if not file_path.exists():
            return None
        
        try:
            with open(file_path, 'rb') as f:
                return pickle.load(f)
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return None
    
    def get(self, model: str, temperature: float, prompt: str, query: str = "") -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        with self._lock:
            self.stats.total_requests += 1
            
            cache_key = self._generate_cache_key(model, temperature, prompt, query)
            key_hash = self._get_key_hash(cache_key)
            
            try:
                with sqlite3.connect(self.db_path) as conn:
                    cursor = conn.execute("""
                        SELECT created_at, ttl_seconds, hit_count, data_file
                        FROM cache_entries 
                        WHERE key_hash = ?
                    """, (key_hash,))
                    
                    row = cursor.fetchone()
                    if not row:
                        self.stats.cache_misses += 1
                        return None
                    
                    created_at_str, ttl_seconds, hit_count, data_file = row
                    created_at = datetime.fromisoformat(created_at_str)
                    
                    # TTL ë§Œë£Œ í™•ì¸
                    if self._is_expired(created_at, ttl_seconds):
                        self._delete_entry(key_hash, data_file)
                        self.stats.cache_misses += 1
                        return None
                    
                    # ë°ì´í„° ë¡œë“œ
                    data = self._load_data_file(data_file)
                    if data is None:
                        self._delete_entry(key_hash, data_file)
                        self.stats.cache_misses += 1
                        return None
                    
                    # íˆíŠ¸ ì¹´ìš´íŠ¸ ì¦ê°€
                    conn.execute("""
                        UPDATE cache_entries 
                        SET hit_count = ? 
                        WHERE key_hash = ?
                    """, (hit_count + 1, key_hash))
                    
                    self.stats.cache_hits += 1
                    print(f"âœ… ìºì‹œ íˆíŠ¸: {key_hash[:8]}... (hit_count: {hit_count + 1})")
                    return data
                    
            except Exception as e:
                print(f"âš ï¸ ìºì‹œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                self.stats.cache_misses += 1
                return None
    
    def set(self, model: str, temperature: float, prompt: str, data: Any, query: str = "", ttl_seconds: int = None) -> bool:
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        with self._lock:
            cache_key = self._generate_cache_key(model, temperature, prompt, query)
            key_hash = self._get_key_hash(cache_key)
            ttl = ttl_seconds or self.ttl_seconds
            
            try:
                # ë°ì´í„° íŒŒì¼ ì €ì¥
                data_file = self._save_data_file(key_hash, data)
                data_size = (self.cache_dir / data_file).stat().st_size
                
                # ë©”íƒ€ë°ì´í„° ì €ì¥
                with sqlite3.connect(self.db_path) as conn:
                    conn.execute("""
                        INSERT OR REPLACE INTO cache_entries 
                        (key_hash, model, temperature, prompt_hash, query_hash, 
                         created_at, ttl_seconds, hit_count, data_file, data_size)
                        VALUES (?, ?, ?, ?, ?, ?, ?, 0, ?, ?)
                    """, (
                        key_hash,
                        cache_key.model,
                        cache_key.temperature,
                        cache_key.prompt_hash,
                        cache_key.query_hash,
                        datetime.now().isoformat(),
                        ttl,
                        data_file,
                        data_size
                    ))
                
                print(f"ğŸ’¾ ìºì‹œ ì €ì¥: {key_hash[:8]}... ({data_size} bytes)")
                return True
                
            except Exception as e:
                print(f"âŒ ìºì‹œ ì €ì¥ ì‹¤íŒ¨: {e}")
                return False
    
    def _delete_entry(self, key_hash: str, data_file: str):
        """ìºì‹œ ì—”íŠ¸ë¦¬ ì‚­ì œ"""
        try:
            # ë°ì´í„° íŒŒì¼ ì‚­ì œ
            file_path = self.cache_dir / data_file
            if file_path.exists():
                file_path.unlink()
            
            # DB ì—”íŠ¸ë¦¬ ì‚­ì œ
            with sqlite3.connect(self.db_path) as conn:
                conn.execute("DELETE FROM cache_entries WHERE key_hash = ?", (key_hash,))
                
        except Exception as e:
            print(f"âš ï¸ ìºì‹œ ì—”íŠ¸ë¦¬ ì‚­ì œ ì‹¤íŒ¨: {e}")
    
    def cleanup_expired(self) -> int:
        """ë§Œë£Œëœ ìºì‹œ ì—”íŠ¸ë¦¬ ì •ë¦¬"""
        with self._lock:
            deleted_count = 0
            
            try:
                with sqlite3.connect(self.db_path) as conn:
                    cursor = conn.execute("""
                        SELECT key_hash, data_file, created_at, ttl_seconds
                        FROM cache_entries
                    """)
                    
                    expired_entries = []
                    for row in cursor.fetchall():
                        key_hash, data_file, created_at_str, ttl_seconds = row
                        created_at = datetime.fromisoformat(created_at_str)
                        
                        if self._is_expired(created_at, ttl_seconds):
                            expired_entries.append((key_hash, data_file))
                    
                    # ë§Œë£Œëœ ì—”íŠ¸ë¦¬ ì‚­ì œ
                    for key_hash, data_file in expired_entries:
                        self._delete_entry(key_hash, data_file)
                        deleted_count += 1
                
                if deleted_count > 0:
                    print(f"ğŸ§¹ ë§Œë£Œëœ ìºì‹œ ì—”íŠ¸ë¦¬ {deleted_count}ê°œ ì •ë¦¬ ì™„ë£Œ")
                
                return deleted_count
                
            except Exception as e:
                print(f"âŒ ìºì‹œ ì •ë¦¬ ì‹¤íŒ¨: {e}")
                return 0
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì¡°íšŒ"""
        cache_size = 0
        entry_count = 0
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("SELECT COUNT(*), SUM(data_size) FROM cache_entries")
                row = cursor.fetchone()
                if row:
                    entry_count, total_size = row
                    cache_size = total_size or 0
        except Exception:
            pass
        
        return {
            "total_requests": self.stats.total_requests,
            "cache_hits": self.stats.cache_hits,
            "cache_misses": self.stats.cache_misses,
            "hit_rate": self.stats.hit_rate,
            "entry_count": entry_count,
            "cache_size_bytes": cache_size,
            "cache_size_mb": cache_size / (1024 * 1024) if cache_size > 0 else 0
        }
    
    def clear(self) -> bool:
        """ì „ì²´ ìºì‹œ ì‚­ì œ"""
        with self._lock:
            try:
                # ëª¨ë“  ë°ì´í„° íŒŒì¼ ì‚­ì œ
                for file_path in self.cache_dir.glob("*.pkl"):
                    file_path.unlink()
                
                # DB ì´ˆê¸°í™”
                with sqlite3.connect(self.db_path) as conn:
                    conn.execute("DELETE FROM cache_entries")
                
                # í†µê³„ ë¦¬ì…‹
                self.stats = CacheStats()
                
                print("ğŸ§¹ ì „ì²´ ìºì‹œ ì‚­ì œ ì™„ë£Œ")
                return True
                
            except Exception as e:
                print(f"âŒ ìºì‹œ ì‚­ì œ ì‹¤íŒ¨: {e}")
                return False
    
    def find_similar_queries(self, query: str, model: str, temperature: float, limit: int = 5) -> List[Dict]:
        """ìœ ì‚¬í•œ ì¿¼ë¦¬ ê²€ìƒ‰ (ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜)"""
        query_words = set(query.lower().split())
        similar_entries = []
        
        try:
            with sqlite3.connect(self.db_path) as conn:
                cursor = conn.execute("""
                    SELECT key_hash, query_hash, hit_count, created_at
                    FROM cache_entries 
                    WHERE model = ? AND temperature = ?
                    ORDER BY hit_count DESC
                    LIMIT ?
                """, (model, temperature, limit * 2))  # ë” ë§ì´ ê°€ì ¸ì™€ì„œ í•„í„°ë§
                
                for row in cursor.fetchall():
                    key_hash, query_hash, hit_count, created_at = row
                    
                    # ê°„ë‹¨í•œ ìœ ì‚¬ë„ ê³„ì‚° (ì‹¤ì œë¡œëŠ” ë” ì •êµí•œ semantic similarity í•„ìš”)
                    if query_hash:  # query_hashê°€ ìˆëŠ” ê²½ìš°ë§Œ
                        similar_entries.append({
                            "key_hash": key_hash,
                            "query_hash": query_hash,
                            "hit_count": hit_count,
                            "created_at": created_at
                        })
                
                return similar_entries[:limit]
                
        except Exception as e:
            print(f"âš ï¸ ìœ ì‚¬ ì¿¼ë¦¬ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []

class CachedLLMClient:
    """ìºì‹œê°€ ì ìš©ëœ LLM í´ë¼ì´ì–¸íŠ¸ ë˜í¼"""
    
    def __init__(self, llm_client, cache: SemanticCache):
        """ì´ˆê¸°í™”"""
        self.llm_client = llm_client
        self.cache = cache
        print("ğŸ”„ CachedLLMClient ì´ˆê¸°í™” ì™„ë£Œ")
    
    def chat_completion_cached(self, model: str, messages: List[Dict], temperature: float = 0.7, 
                             max_tokens: int = 150, use_cache: bool = True, **kwargs) -> Any:
        """ìºì‹œê°€ ì ìš©ëœ chat completion"""
        
        if not use_cache:
            return self.llm_client.chat.completions.create(
                model=model,
                messages=messages,
                temperature=temperature,
                max_tokens=max_tokens,
                **kwargs
            )
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„± (ìºì‹œ í‚¤ìš©)
        prompt_parts = []
        user_query = ""
        
        for msg in messages:
            if msg["role"] == "system":
                prompt_parts.append(f"SYSTEM: {msg['content']}")
            elif msg["role"] == "user":
                prompt_parts.append(f"USER: {msg['content']}")
                user_query = msg['content']  # ë§ˆì§€ë§‰ user ë©”ì‹œì§€ë¥¼ ì¿¼ë¦¬ë¡œ ì‚¬ìš©
        
        prompt = "\n".join(prompt_parts)
        
        # ìºì‹œì—ì„œ ì¡°íšŒ
        cached_response = self.cache.get(model, temperature, prompt, user_query)
        if cached_response is not None:
            return cached_response
        
        # ìºì‹œ ë¯¸ìŠ¤ - LLM í˜¸ì¶œ
        start_time = time.time()
        response = self.llm_client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            **kwargs
        )
        call_time = (time.time() - start_time) * 1000
        
        # ì‘ë‹µ ìºì‹œì— ì €ì¥
        self.cache.set(model, temperature, prompt, response, user_query)
        
        print(f"ğŸš€ LLM í˜¸ì¶œ ì™„ë£Œ ({call_time:.1f}ms), ìºì‹œì— ì €ì¥ë¨")
        return response 