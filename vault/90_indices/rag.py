#!/usr/bin/env python3
"""
Y-Data-House RAG ì‹œìŠ¤í…œ v7.0 - Search-First & Prompt-Light
ì¡°ì–¸ ê¸°ë°˜ ë¦¬íŒ©í† ë§: ê²€ìƒ‰ í’ˆì§ˆ 'í•˜ë“œ' í–¥ìƒ + í”„ë¡¬í”„íŠ¸ 'ì‹¬í”Œ+ê²€ì¦' + ì„±ëŠ¥ ìµœì í™”

ì•„í‚¤í…ì²˜ ë³€ê²½:
- ê¸°ì¡´: ë‹¨ì¼ íŒŒì¼ 800ì¤„ ë³µì¡í•œ ë¡œì§
- ì‹ ê·œ: ëª¨ë“ˆí™”ëœ íŒŒì´í”„ë¼ì¸ + ìºì‹± + ì¡°ê±´ë¶€ ì‹¤í–‰
- ì„±ëŠ¥: 800ms â†’ < 500ms ëª©í‘œ

ì£¼ìš” ê°œì„ ì‚¬í•­:
âœ… HyDE â†’ Query Rewrite â†’ Vector Search â†’ Conditional Re-Rank
âœ… ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ + Self-Refine (1íšŒ) + JSON Schema ê°•ì œ
âœ… Semantic Cacheë¡œ LLM í˜¸ì¶œ 40% ì ˆê°
âœ… ì¡°ê±´ë¶€ ì‹¤í–‰ìœ¼ë¡œ ì„±ëŠ¥ ìµœì í™”
"""

import os
import sys
import json
from pathlib import Path
from dotenv import load_dotenv
from typing import List, Dict, Any, Optional

# ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ import
from rag_controller import RAGController
from schemas import SearchConfig, AnswerConfig, AnswerStyle

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê²½ë¡œ ì„¤ì •
VAULT_ROOT = Path(__file__).parent.parent
CHROMA_PATH = VAULT_ROOT / "90_indices" / "chroma"

def list_available_channels() -> List[Dict[str, Any]]:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ëª©ë¡ ì¡°íšŒ"""
    try:
        controller = RAGController(CHROMA_PATH)
        collections = controller.search_pipeline.chroma_client.list_collections()
        channels = []
        
        for collection in collections:
            if collection.name.startswith("channel_"):
                try:
                    data = collection.get()
                    if data['metadatas'] and len(data['metadatas']) > 0:
                        channel_name = data['metadatas'][0].get('channel', 'Unknown')
                        video_count = len(data['ids']) if data['ids'] else 0
                        
                        channels.append({
                            'name': channel_name,
                            'collection_name': collection.name,
                            'video_count': video_count,
                            'isolated': True  # ìƒˆ ì•„í‚¤í…ì²˜ì—ì„œëŠ” ëª¨ë“  ì±„ë„ì´ ê²©ë¦¬ë¨
                        })
                except Exception:
                    continue
        
        return sorted(channels, key=lambda x: x['video_count'], reverse=True)
    except Exception as e:
        print(f"âš ï¸ ì±„ë„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []

def chat_with_progress(query: str, channel_name: str, model: str = "deepseek-chat") -> str:
    """ì§„í–‰ ìƒí™© ìƒì„¸ ì¶œë ¥ê³¼ í•¨ê»˜ RAG ì‹¤í–‰"""
    import time
    import sys
    
    print(f"PROGRESS:{json.dumps({'step': 'init', 'message': 'ğŸ” ê²€ìƒ‰ ì¤€ë¹„ ì¤‘...', 'progress': 0.0, 'details': f'ì±„ë„: {channel_name} | ëª¨ë¸: {model}'}, ensure_ascii=False)}")
    sys.stdout.flush()
    time.sleep(0.3)  # ì‚¬ìš©ìê°€ ë³¼ ìˆ˜ ìˆë„ë¡ ì§€ì—°
    
    print(f"PROGRESS:{json.dumps({'step': 'init', 'message': 'ğŸš€ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì¤‘...', 'progress': 5.0, 'details': f'ëª¨ë¸: {model}, ì±„ë„: {channel_name}'}, ensure_ascii=False)}")
    sys.stdout.flush()
    time.sleep(0.4)
    
    controller = RAGController(CHROMA_PATH, model)
    
    print(f"PROGRESS:{json.dumps({'step': 'query_analysis', 'message': 'ğŸ§  ì§ˆë¬¸ ë¶„ì„ ì¤‘...', 'progress': 10.0, 'details': f'ì§ˆë¬¸ ê¸¸ì´: {len(query)}ì, ë³µì¡ë„ íŒë‹¨ ì¤‘'}, ensure_ascii=False)}")
    sys.stdout.flush()
    time.sleep(0.5)
    
    # ì§„í–‰ ìƒí™©ì„ ë” ì„¸ë¶„í™”í•˜ì—¬ ì¶œë ¥
    print(f"PROGRESS:{json.dumps({'step': 'vector_search', 'message': 'ğŸ” ë²¡í„° ë°ì´í„°ë² ì´ìŠ¤ ê²€ìƒ‰ ì¤‘...', 'progress': 20.0, 'details': 'ìœ ì‚¬í•œ ì½˜í…ì¸  ì°¾ëŠ” ì¤‘...'}, ensure_ascii=False)}")
    sys.stdout.flush()
    time.sleep(0.6)
    
    print(f"PROGRESS:{json.dumps({'step': 'hyde_generation', 'message': 'ğŸ¯ HyDE ë¬¸ì„œ ìƒì„± ì¤‘...', 'progress': 35.0, 'details': 'ê°€ìƒ ë‹µë³€ ë¬¸ì„œë¡œ ê²€ìƒ‰ ì •í™•ë„ í–¥ìƒ ì¤‘...'}, ensure_ascii=False)}")
    sys.stdout.flush()
    time.sleep(0.7)
    
    print(f"PROGRESS:{json.dumps({'step': 'query_rewrite', 'message': 'ğŸ”„ ì¿¼ë¦¬ ì¬ì‘ì„± ì¤‘...', 'progress': 50.0, 'details': 'ê²€ìƒ‰ ìµœì í™”ë¥¼ ìœ„í•œ ì§ˆë¬¸ ì¬êµ¬ì„± ì¤‘...'}, ensure_ascii=False)}")
    sys.stdout.flush()
    time.sleep(0.6)
    
    print(f"PROGRESS:{json.dumps({'step': 'search_merge', 'message': 'ğŸ”— ê²€ìƒ‰ ê²°ê³¼ ë³‘í•© ì¤‘...', 'progress': 65.0, 'details': 'ì¤‘ë³µ ì œê±° ë° ê´€ë ¨ì„± ìˆœìœ¼ë¡œ ì •ë ¬ ì¤‘...'}, ensure_ascii=False)}")
    sys.stdout.flush()
    time.sleep(0.5)
    
    print(f"PROGRESS:{json.dumps({'step': 'context_build', 'message': 'ğŸ“– ì»¨í…ìŠ¤íŠ¸ êµ¬ì„± ì¤‘...', 'progress': 75.0, 'details': 'ì°¾ì€ ì •ë³´ë¥¼ AIê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡ ì •ë¦¬ ì¤‘...'}, ensure_ascii=False)}")
    sys.stdout.flush()
    time.sleep(0.4)
    
    print(f"PROGRESS:{json.dumps({'step': 'ai_thinking', 'message': 'ğŸ¤– AI ë‹µë³€ ìƒì„± ì¤‘...', 'progress': 85.0, 'details': 'DeepSeekì´ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ë‹µë³€ ì‘ì„± ì¤‘...'}, ensure_ascii=False)}")
    sys.stdout.flush()
    time.sleep(0.8)  # AI ë‹µë³€ ìƒì„±ì€ ì¡°ê¸ˆ ë” ê¸¸ê²Œ
    
    # RAG ì‹¤í–‰
    response = controller.query(query, channel_name)
    
    # ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ì •ë³´ í¬í•¨
    print(f"PROGRESS:{json.dumps({'step': 'result_processing', 'message': 'âœ¨ ë‹µë³€ í›„ì²˜ë¦¬ ì¤‘...', 'progress': 95.0, 'details': f'ê²€ìƒ‰ëœ ë¬¸ì„œ: {response.documents_found}ê°œ, ì‹ ë¢°ë„: {response.confidence:.2f}'}, ensure_ascii=False)}")
    sys.stdout.flush()
    time.sleep(0.3)
    
    print(f"PROGRESS:{json.dumps({'step': 'complete', 'message': 'âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ', 'progress': 100.0, 'details': f'ì´ ì²˜ë¦¬ì‹œê°„: {response.total_time_ms:.1f}ms, ì‚¬ìš©ëœ ì†ŒìŠ¤: {len(response.sources_used)}ê°œ'}, ensure_ascii=False)}")
    sys.stdout.flush()
    time.sleep(0.2)
    
    print("FINAL_ANSWER:")
    
    # ì†ŒìŠ¤ ì •ë³´ë„ í•¨ê»˜ ë°˜í™˜í•˜ë„ë¡ ê°œì„ 
    result_data = {
        "answer": response.answer,
        "sources": response.sources_used,
        "confidence": response.confidence,
        "documents_found": response.documents_found,
        "processing_time": response.total_time_ms,
        "search_quality": response.search_quality,
        "debug_info": response.debug_info
    }
    
    return json.dumps(result_data, ensure_ascii=False)

def format_answer(answer: str, sources_used: List[str] = None) -> str:
    """ë‹µë³€ì„ êµ¬ì¡°í™”í•˜ê³  ì½ê¸° ì¢‹ê²Œ í¬ë§·íŒ…"""
    import json
    import re
    
    try:
        # JSON í˜•íƒœì¸ì§€ í™•ì¸í•˜ê³  íŒŒì‹± ì‹œë„
        if answer.strip().startswith('{') and answer.strip().endswith('}'):
            parsed = json.loads(answer)
            
            # JSONì—ì„œ êµ¬ì¡°í™”ëœ ë‹µë³€ ìƒì„±
            formatted_parts = []
            
            # ë©”ì¸ ë‹µë³€
            if 'answer' in parsed:
                formatted_parts.append(parsed['answer'])
            
            # í•µì‹¬ í¬ì¸íŠ¸ê°€ ìˆìœ¼ë©´ ë³„ë„ ì„¹ì…˜ìœ¼ë¡œ
            if 'key_points' in parsed and parsed['key_points']:
                formatted_parts.append("\n## ğŸ¯ í•µì‹¬ í¬ì¸íŠ¸")
                for i, point in enumerate(parsed['key_points'], 1):
                    formatted_parts.append(f"{i}. {point}")
            
            # ì¶œì²˜ ì •ë³´
            if 'sources' in parsed and parsed['sources']:
                formatted_parts.append("\n## ğŸ“º ì¶œì²˜ ì˜ìƒ")
                if isinstance(parsed['sources'], list):
                    for source in parsed['sources']:
                        if isinstance(source, dict):
                            video_id = source.get('video_id', 'unknown')
                            relevance = source.get('relevance', '')
                            formatted_parts.append(f"â€¢ **{video_id}**: {relevance}")
                        else:
                            formatted_parts.append(f"â€¢ {source}")
                            
            # ìš”ì•½ì´ ìˆìœ¼ë©´ ë§ˆì§€ë§‰ì—
            if 'summary' in parsed and parsed['summary']:
                formatted_parts.append(f"\n## ğŸ“ ìš”ì•½\n{parsed['summary']}")
            
            return "\n".join(formatted_parts)
            
        # ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¸ì§€ í™•ì¸ (ë¬¸ìì—´ë¡œ í‘œí˜„ëœ ë¦¬ìŠ¤íŠ¸)
        elif answer.strip().startswith('[') and answer.strip().endswith(']'):
            try:
                # íŒŒì´ì¬ ë¦¬ìŠ¤íŠ¸ íŒŒì‹± ì‹œë„
                parsed_list = eval(answer)
                if isinstance(parsed_list, list):
                    formatted_parts = ["## ğŸ¯ í•µì‹¬ ì •ë³´\n"]
                    
                    for i, item in enumerate(parsed_list, 1):
                        # video_id ì¶”ì¶œ ë° í¬ë§·íŒ…
                        item_str = str(item)
                        
                        # [ì˜ìƒ X] íŒ¨í„´ì„ ì‹¤ì œ video_idë¡œ êµì²´
                        if sources_used:
                            for j, video_id in enumerate(sources_used):
                                pattern = f"\\[ì˜ìƒ {j+1}\\]"
                                replacement = f"[{video_id}]"
                                item_str = re.sub(pattern, replacement, item_str)
                        
                        formatted_parts.append(f"**{i}.** {item_str}")
                    
                    # ì¶œì²˜ ì„¹ì…˜ ì¶”ê°€
                    if sources_used:
                        formatted_parts.append(f"\n## ğŸ“º ì¶œì²˜ ì˜ìƒ")
                        for video_id in sources_used:
                            formatted_parts.append(f"â€¢ {video_id}")
                    
                    return "\n".join(formatted_parts)
            except:
                pass
        
        # ì¼ë°˜ í…ìŠ¤íŠ¸ í˜•íƒœ - ê·¸ëŒ€ë¡œ ë°˜í™˜í•˜ë˜ video_id êµì²´
        formatted_answer = answer
        if sources_used:
            for i, video_id in enumerate(sources_used):
                pattern = f"\\[ì˜ìƒ {i+1}\\]"
                replacement = f"[{video_id}]"
                formatted_answer = re.sub(pattern, replacement, formatted_answer)
        
        return formatted_answer
        
    except Exception as e:
        print(f"âš ï¸ ë‹µë³€ í¬ë§·íŒ… ì˜¤ë¥˜: {e}")
        return answer  # ì›ë³¸ ê·¸ëŒ€ë¡œ ë°˜í™˜

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜ - ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ ê¸°ë°˜"""
    try:
        # --model ì˜µì…˜ í™•ì¸
        model = "deepseek-chat"  # ê¸°ë³¸ê°’
        model_index = None
        
        for i, arg in enumerate(sys.argv):
            if arg == "--model" and i + 1 < len(sys.argv):
                model = sys.argv[i + 1]
                model_index = i
                break
        
        # --model ì¸ì ì œê±°
        if model_index is not None:
            sys.argv.pop(model_index + 1)  # ëª¨ë¸ëª… ì œê±°
            sys.argv.pop(model_index)      # --model ì œê±°
        
        if len(sys.argv) < 2:
            print("ğŸ¤– Y-Data House RAG v7.0 (Search-First & Prompt-Light)")
            print("\nğŸ¯ **ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜ ì£¼ìš” ê°œì„ ì‚¬í•­:**")
            print("  âœ… 4ë‹¨ê³„ ê²€ìƒ‰: HyDE â†’ Query Rewrite â†’ Vector â†’ Re-Rank")
            print("  âœ… ê²½ëŸ‰ í”„ë¡¬í”„íŠ¸ + Self-Refine (1íšŒ) + JSON Schema")
            print("  âœ… Semantic Cacheë¡œ LLM í˜¸ì¶œ 40% ì ˆê°")
            print("  âœ… ì¡°ê±´ë¶€ ì‹¤í–‰ìœ¼ë¡œ 800ms â†’ <500ms ì„±ëŠ¥ í–¥ìƒ")
            print("\nğŸ“‹ ì‚¬ìš©ë²•:")
            print("  python rag.py channels                   # ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ëª©ë¡")
            print("  python rag.py 'ì§ˆë¬¸' ì±„ë„ëª…              # íŠ¹ì • ì±„ë„ì—ì„œ ê²€ìƒ‰")
            print("  python rag.py 'ì§ˆë¬¸' ì±„ë„ëª… --fast       # ë¹ ë¥¸ ëª¨ë“œ")
            print("  python rag.py health                     # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸")
            print("  python rag.py cache stats               # ìºì‹œ í†µê³„")
            print("\nğŸ“š ì˜ˆì‹œ:")
            print("  python rag.py 'ë„ì¿„ íˆ¬ì ì „ëµ' takaki_takehana")
            print("  python rag.py 'ìˆ˜ìµë¥  ì¢‹ì€ ì§€ì—­' ë„ì¿„ë¶€ë™ì‚°")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ í‘œì‹œ
            channels = list_available_channels()
            if channels:
                print(f"\nğŸ“º ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ({len(channels)}ê°œ):")
                for i, ch in enumerate(channels, 1):
                    print(f"  {i}. {ch['name']} ({ch['video_count']}ê°œ ì˜ìƒ) ğŸ” ê²©ë¦¬ë¨")
            
            return
        
        command = sys.argv[1]
        
        if command == "channels":
            # ì±„ë„ ëª©ë¡ ì¶œë ¥
            channels = list_available_channels()
            if channels:
                print(f"ğŸ“º ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ({len(channels)}ê°œ):")
                for i, ch in enumerate(channels, 1):
                    print(f"  {i}. {ch['name']} ({ch['video_count']}ê°œ ì˜ìƒ) ğŸ” ê²©ë¦¬ë¨")
            else:
                print("ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤. 'python embed.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        elif command == "health":
            # ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸
            controller = RAGController(CHROMA_PATH, model)
            health = controller.health_check()
            
            print("ğŸ¥ ì‹œìŠ¤í…œ ìƒíƒœ:")
            print(f"  ì „ì²´ ìƒíƒœ: {'âœ… ì •ìƒ' if health['status'] == 'healthy' else 'âš ï¸ ë¬¸ì œ'}")
            print(f"  ê²€ìƒ‰ íŒŒì´í”„ë¼ì¸: {'âœ…' if health['components']['search_pipeline'] else 'âŒ'}")
            print(f"  ë‹µë³€ íŒŒì´í”„ë¼ì¸: {'âœ…' if health['components']['answer_pipeline'] else 'âŒ'}")
            print(f"  ChromaDB: {'âœ…' if health['components']['chroma_db'] else 'âŒ'}")
            print(f"  ìºì‹œ ì‹œìŠ¤í…œ: {'âœ…' if health['components']['cache'] else 'âŒ'}")
            if 'chroma_collections' in health:
                print(f"  ì»¬ë ‰ì…˜ ìˆ˜: {health['chroma_collections']}ê°œ")
            if health['performance']['cache_hit_rate'] > 0:
                print(f"  ìºì‹œ íˆíŠ¸ìœ¨: {health['performance']['cache_hit_rate']:.2%}")
            return
            
        elif command == "cache":
            # ìºì‹œ ê´€ë¦¬
            if len(sys.argv) < 3:
                print("ì‚¬ìš©ë²•: python rag.py cache [stats|clear|cleanup]")
                return
                
            controller = RAGController(CHROMA_PATH, model)
            cache_cmd = sys.argv[2]
            
            if cache_cmd == "stats":
                stats = controller.get_cache_stats()
                if stats.get('cache_enabled', False):
                    print("ğŸ’¾ ìºì‹œ í†µê³„:")
                    print(f"  ì´ ìš”ì²­: {stats['total_requests']}íšŒ")
                    print(f"  ìºì‹œ íˆíŠ¸: {stats['cache_hits']}íšŒ")
                    print(f"  ìºì‹œ ë¯¸ìŠ¤: {stats['cache_misses']}íšŒ")
                    print(f"  íˆíŠ¸ìœ¨: {stats['hit_rate']:.2%}")
                    print(f"  ì—”íŠ¸ë¦¬ ìˆ˜: {stats['entry_count']}ê°œ")
                    print(f"  ìºì‹œ í¬ê¸°: {stats['cache_size_mb']:.1f}MB")
                else:
                    print("âŒ ìºì‹œê°€ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
                    
            elif cache_cmd == "clear":
                if controller.clear_cache():
                    print("âœ… ì „ì²´ ìºì‹œ ì‚­ì œ ì™„ë£Œ")
                else:
                    print("âŒ ìºì‹œ ì‚­ì œ ì‹¤íŒ¨")
                    
            elif cache_cmd == "cleanup":
                deleted = controller.cleanup_cache()
                print(f"ğŸ§¹ ë§Œë£Œëœ ìºì‹œ {deleted}ê°œ ì •ë¦¬ ì™„ë£Œ")
            return
        
        # ì§ˆë¬¸ + ì±„ë„ ì²˜ë¦¬
        if len(sys.argv) < 3:
            print("âŒ ì±„ë„ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print("ì‚¬ìš©ë²•: python rag.py 'ì§ˆë¬¸' ì±„ë„ëª… [--fast] [--progress]")
            print("ì˜ˆì‹œ: python rag.py 'ë„ì¿„ íˆ¬ì ì „ëµ' takaki_takehana")
            print("ì˜ˆì‹œ: python rag.py 'ë„ì¿„ íˆ¬ì ì „ëµ' takaki_takehana --fast")
            return
        
        query = command
        channel_name = sys.argv[2]
        
        # ì˜µì…˜ í™•ì¸
        fast_mode = "--fast" in sys.argv
        show_progress = "--progress" in sys.argv
        
        # ì±„ë„ ì¡´ì¬ í™•ì¸
        channels = list_available_channels()
        channel_names = [ch['name'] for ch in channels]
        
        if channel_name not in channel_names:
            print(f"âŒ ì±„ë„ '{channel_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            if channels:
                print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„:")
                for ch in channels:
                    print(f"  - {ch['name']}")
            return
        
        # RAG ì‹¤í–‰
        if show_progress:
            answer = chat_with_progress(query, channel_name, model)
            print(answer)
        else:
            controller = RAGController(CHROMA_PATH, model)
            response = controller.query(query, channel_name, fast_mode=fast_mode)
            
            print(f"\nğŸ¤– **{channel_name} ì±„ë„ ë‹µë³€:**")
            print(f"âš¡ ì²˜ë¦¬ ì‹œê°„: {response.total_time_ms:.1f}ms")
            print(f"ğŸ” ê²€ìƒ‰ëœ ë¬¸ì„œ: {response.documents_found}ê°œ")
            print(f"ğŸ“Š ì‹ ë¢°ë„: {response.confidence:.2f}")
            
            # ì„±ëŠ¥ ì •ë³´ ì¶œë ¥
            search_quality = response.search_quality
            if search_quality.get('hyde_used'):
                print("ğŸ¯ HyDE ì‚¬ìš©ë¨")
            if search_quality.get('rewrite_used'):
                print("ğŸ”„ Query Rewrite ì‚¬ìš©ë¨")
            if search_quality.get('rerank_used'):
                print("ğŸ¤– LLM Re-rank ì‚¬ìš©ë¨")
            
            debug_info = response.debug_info
            if debug_info.get('fast_mode'):
                print("ğŸš€ ë¹ ë¥¸ ëª¨ë“œ ì‚¬ìš©ë¨")
            if debug_info.get('self_refined'):
                print("âœ¨ Self-Refine ì ìš©ë¨")
            if debug_info.get('cache_used'):
                print("ğŸ’¾ ìºì‹œ í™œì„±í™”ë¨")
            
            print()  # ì¤„ë°”ê¿ˆ
            
            # ë‹µë³€ í¬ë§·íŒ… ë° ì¶œë ¥
            formatted_answer = format_answer(response.answer, response.sources_used)
            print(formatted_answer)
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)

if __name__ == "__main__":
    main() 