#!/usr/bin/env python3
"""
DeepSeek RAG ì‹œìŠ¤í…œ - ì±„ë„ë³„ ì™„ì „ ê²©ë¦¬ ê²€ìƒ‰
ê°œë–¡ê°™ì´ ë§í•´ë„ ì°°ë–¡ê°™ì´ ì•Œì•„ë“£ëŠ” ì‹œìŠ¤í…œ v6.0 - ì±„ë„ë³„ ì™„ì „ ê²©ë¦¬ + HyDE + Query Rewriting
"""

import os
import sys
from pathlib import Path
from dotenv import load_dotenv
import chromadb
from chromadb.config import Settings as ChromaSettings
from openai import OpenAI
import re
from prompt_manager import PromptManager

# ---------------- ê°œì„ ëœ Prompt template ----------------
PROMPT_TEMPLATE = """ë‹¹ì‹ ì€ ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ì ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì•„ë˜ëŠ” **{channel_name} ì±„ë„**ì—ì„œ ì°¾ì€ **ê°€ì¥ ê´€ë ¨ì„± ë†’ì€** ë‚´ìš©ë“¤ì…ë‹ˆë‹¤. ì§ì ‘ì ì¸ ì–¸ê¸‰ì´ ì—†ì–´ë„ **ë¹„ìŠ·í•œ íŒ¨í„´, íˆ¬ì ì›ì¹™, ì§€ì—­ íŠ¹ì„±**ì„ ë°”íƒ•ìœ¼ë¡œ ìµœëŒ€í•œ ë„ì›€ë˜ëŠ” ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”.

## ì»¨í…ìŠ¤íŠ¸ (ê´€ë ¨ ì˜ìƒë“¤)
{context}

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

## ë‹µë³€ ì‘ì„± ì§€ì¹¨
1. **{channel_name} ì±„ë„ì˜ ì •ë³´ë§Œ í™œìš©**í•˜ì—¬ ì§‘ì¤‘ëœ ì¡°ì–¸ ì œê³µ
2. **5ê°œ ì´í•˜ í•µì‹¬ bullet**(`- `)ë¡œ ì‘ì„±í•˜ê³ , ê° bullet ëì— `[ì˜ìƒ n]` í‘œì‹œ
3. ì§ì ‘ ì–¸ê¸‰ì´ ì—†ì–´ë„ **"ì´ ì±„ë„ì˜ ë‹¤ë¥¸ ì‚¬ë¡€ë¡œ ìœ ì¶”í•˜ë©´..."** ì‹ìœ¼ë¡œ ì—°ê²°í•´ì„œ ì¡°ì–¸
4. **êµ¬ì²´ì  ìˆ˜ì¹˜, ì§€ì—­ëª…, íˆ¬ì ì „ëµ**ì„ í¬í•¨í•˜ì—¬ ì‹¤ìš©ì„± ë†’ì´ê¸°
5. ë§ˆì§€ë§‰ì— `### ğŸ’¡ í•œ ì¤„ ìš”ì•½:` í˜•ì‹ìœ¼ë¡œ í•µì‹¬ ì •ë¦¬
6. **ë¬´ì¡°ê±´ ë„ì›€ë˜ëŠ” ë‹µë³€**ì„ ë§Œë“¤ì–´ì•¼ í•¨ - "ëª¨ë¥´ê² ë‹¤" ê¸ˆì§€

**ì¤‘ìš”**: ì˜ìƒì—ì„œ ì§ì ‘ ì–¸ê¸‰ë˜ì§€ ì•Šì€ ì§€ì—­ì´ë¼ë„, ì´ ì±„ë„ì˜ ë‹¤ë¥¸ íˆ¬ì íŒ¨í„´ì´ë‚˜ ì›ì¹™ì„ ì ìš©í•´ì„œ ì¡°ì–¸í•´ì£¼ì„¸ìš”.
"""

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# DeepSeek í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
def create_deepseek_client():
    """DeepSeek API í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    api_key = os.getenv('DEEPSEEK_API_KEY')
    if not api_key:
        raise ValueError("âŒ DEEPSEEK_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    
    client = OpenAI(
        api_key=api_key,
        base_url="https://api.deepseek.com/v1"
    )
    return client

# ê²½ë¡œ ì„¤ì •
VAULT_ROOT = Path(__file__).parent.parent
CHROMA_PATH = VAULT_ROOT / "90_indices" / "chroma"

def sanitize_collection_name(name: str) -> str:
    """ChromaDB ì»¬ë ‰ì…˜ ì´ë¦„ ì •ë¦¬ (íŠ¹ìˆ˜ë¬¸ì ì œê±°)"""
    sanitized = re.sub(r'[^\wê°€-í£]', '_', name)
    sanitized = re.sub(r'_+', '_', sanitized).strip('_')
    return sanitized[:50] if sanitized else "unknown_channel"

class ChannelRAG:
    def __init__(self, model: str = "deepseek-chat"):
        """ì±„ë„ë³„ ê²©ë¦¬ RAG ì‹œìŠ¤í…œ ì´ˆê¸°í™”"""
        # ëª¨ë¸ëª… ì €ì¥
        self.model = model
        print(f"ğŸ¤– ì‚¬ìš© ëª¨ë¸: {model}")
        
        # DeepSeek í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.client = create_deepseek_client()
            print("âœ… DeepSeek API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
        except Exception as e:
            raise ValueError(f"âŒ DeepSeek API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        
        # ChromaDB í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        try:
            self.chroma_client = chromadb.PersistentClient(
                path=str(CHROMA_PATH),
                settings=ChromaSettings(anonymized_telemetry=False)
            )
            print(f"âœ… ChromaDB ì—°ê²°ë¨: {CHROMA_PATH}")
        except Exception as e:
            raise ValueError(f"âŒ ChromaDB ë¡œë“œ ì‹¤íŒ¨: {e}\n'python embed.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
        
        # í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™”
        try:
            self.prompt_manager = PromptManager(chroma_path=CHROMA_PATH)
            print(f"âœ… PromptManager ì´ˆê¸°í™” ì™„ë£Œ: {CHROMA_PATH.parent}/prompts")
        except Exception as e:
            print(f"âš ï¸ í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì € ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self.prompt_manager = None
    
    def list_available_channels(self):
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ëª©ë¡ ë°˜í™˜"""
        try:
            collections = self.chroma_client.list_collections()
            channels = []
            
            for collection in collections:
                if collection.name.startswith("channel_"):
                    try:
                        data = collection.get()
                        if data['metadatas'] and len(data['metadatas']) > 0:
                            channel_name = data['metadatas'][0].get('channel', 'Unknown')
                            video_count = len(data['ids']) if data['ids'] else 0
                            isolated = data['metadatas'][0].get('isolated_channel', False)
                            
                            channels.append({
                                'name': channel_name,
                                'collection_name': collection.name,
                                'video_count': video_count,
                                'isolated': isolated
                            })
                    except Exception:
                        continue
            
            return sorted(channels, key=lambda x: x['video_count'], reverse=True)
        except Exception as e:
            print(f"âš ï¸ ì±„ë„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def get_collection_by_channel(self, channel_name: str):
        """ì±„ë„ëª…ìœ¼ë¡œ ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸°"""
        try:
            collections = self.chroma_client.list_collections()
            
            for collection in collections:
                if collection.name.startswith("channel_"):
                    # ì»¬ë ‰ì…˜ì—ì„œ ìƒ˜í”Œ ë°ì´í„° ê°€ì ¸ì™€ì„œ ì±„ë„ëª… í™•ì¸
                    try:
                        sample = collection.get(limit=1, include=['metadatas'])
                        if sample['metadatas'] and sample['metadatas'][0]:
                            metadata_channel = sample['metadatas'][0].get('channel', '')
                            if metadata_channel == channel_name:
                                return collection
                    except:
                        continue
            
            return None
        except Exception as e:
            print(f"âŒ ì»¬ë ‰ì…˜ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return None

    def generate_channel_specific_hyde(self, query: str, channel_name: str, channel_prompt: dict = None):
        """ì±„ë„ íŠ¹í™” HyDE ë¬¸ì„œ ìƒì„±"""
        if not channel_prompt and self.prompt_manager:
            channel_prompt = self.prompt_manager.get_channel_prompt(channel_name)
        
        try:
            persona = channel_prompt.get('persona', 'ì „ë¬¸ê°€') if channel_prompt else 'ì „ë¬¸ê°€'
            tone = channel_prompt.get('tone', 'ì „ë¬¸ì ì¸ ìŠ¤íƒ€ì¼') if channel_prompt else 'ì „ë¬¸ì ì¸ ìŠ¤íƒ€ì¼'
            
            prompt = f"""ë‹¹ì‹ ì€ {channel_name} ì±„ë„ì˜ {persona}ì…ë‹ˆë‹¤. 
{tone}ë¡œ ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ì™„ë²½í•œ ë‹µë³€ì´ ë‹´ê¸´ 150í† í° ë‚´ì™¸ì˜ ê°€ìƒ ë¬¸ì„œë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ì§ˆë¬¸: {query}

ì´ ì±„ë„ì˜ ê´€ì ì—ì„œ êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì§€ì—­ëª…, ì „ëµì´ í¬í•¨ëœ ë‹µë³€ì„ ì‘ì„±í•´ì£¼ì„¸ìš”."""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=150,
                temperature=0.7
            )
            
            hyde_doc = response.choices[0].message.content.strip()
            print(f"ğŸ¯ {channel_name} ì±„ë„ íŠ¹í™” HyDE: {hyde_doc[:50]}...")
            return hyde_doc
            
        except Exception as e:
            print(f"âš ï¸ ì±„ë„ íŠ¹í™” HyDE ìƒì„± ì‹¤íŒ¨: {e}")
            return None

    def generate_hyde_documents(self, query: str, channel_name: str, n_docs=1):
        """ê¸°ì¡´ HyDE + ì±„ë„ íŠ¹í™” HyDE"""
        hyde_docs = []
        
        # 1. ì±„ë„ íŠ¹í™” HyDE
        if self.prompt_manager:
            channel_hyde = self.generate_channel_specific_hyde(query, channel_name)
            if channel_hyde:
                hyde_docs.append(channel_hyde)
        
        # 2. ê¸°ì¡´ ë°©ì‹ HyDE (ë³´ì™„ìš©)
        for i in range(n_docs):
            try:
                response = self.client.chat.completions.create(
                    model=self.model,
                    messages=[
                        {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ì˜ ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                        {"role": "user", "content": f"ë‹¤ìŒ ì§ˆë¬¸ì— ëŒ€í•œ ì™„ë²½í•œ ë‹µë³€ì´ ë‹´ê¸´ ë¬¸ì„œë¥¼ {channel_name} ì±„ë„ ê´€ì ì—ì„œ ì‘ì„±í•´ì£¼ì„¸ìš”: '{query}'\n\në‹µë³€ì—ëŠ” êµ¬ì²´ì ì¸ ìˆ˜ì¹˜, ì§€ì—­ëª…, íˆ¬ì ì „ëµì´ í¬í•¨ë˜ì–´ì•¼ í•©ë‹ˆë‹¤."}
                    ],
                    max_tokens=150,
                    temperature=0.7
                )
                
                hyde_doc = response.choices[0].message.content.strip()
                hyde_docs.append(hyde_doc)
                print(f"ğŸ¯ {channel_name} ê¸°ë³¸ HyDE {i+1}: {hyde_doc[:50]}...")
                
            except Exception as e:
                print(f"âš ï¸ HyDE ë¬¸ì„œ ìƒì„± ì‹¤íŒ¨: {e}")
                continue
        
        return hyde_docs if hyde_docs else [None]

    def rewrite_query(self, query: str, channel_name: str, context_sample: str = ""):
        """Query Rewriting: íŠ¹ì • ì±„ë„ ë§¥ë½ì—ì„œ ê²€ìƒ‰ ìµœì í™”"""
        # ì±„ë„ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸°
        channel_prompt = {}
        if self.prompt_manager:
            channel_prompt = self.prompt_manager.get_channel_prompt(channel_name)
        
        try:
            # ì±„ë„ íŠ¹ì„± ë°˜ì˜
            expertise_keywords = channel_prompt.get('expertise_keywords', [])
            keywords_hint = f"ì£¼ìš” í‚¤ì›Œë“œ: {', '.join(expertise_keywords[:5])}" if expertise_keywords else ""
            
            prompt = f"""ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ ê²€ìƒ‰ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì„ ì´ ì±„ë„ì˜ ì»¨í…ì¸ ì—ì„œ ê²€ìƒ‰í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ì¬ì‘ì„±í•˜ì„¸ìš”.

## ì›ë³¸ ì§ˆë¬¸
{query}

## ì±„ë„ ì»¨í…ìŠ¤íŠ¸
{context_sample[:200]}

## ì±„ë„ íŠ¹ì„±
{keywords_hint}

### ì§€ì‹œì‚¬í•­
{channel_name} ì±„ë„ì˜ ì˜ìƒì—ì„œ ì°¾ì„ ìˆ˜ ìˆëŠ” í•µì‹¬ í‚¤ì›Œë“œì™€ ê°œë…ì„ í¬í•¨í•œ ê²€ìƒ‰ ì¿¼ë¦¬ë¡œ ì¬ì‘ì„±í•˜ì„¸ìš”.
**60í† í° ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”.**
"""
            
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ ê²€ìƒ‰ ì§ˆì˜ ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=60,
                temperature=0.3
            )
            
            rewritten = response.choices[0].message.content.strip()
            print(f"ğŸ”„ {channel_name} Query Rewriting: {rewritten}")
            return rewritten
            
        except Exception as e:
            print(f"âš ï¸ Query Rewriting ì‹¤íŒ¨: {e}")
            return query

    def channel_search(self, query: str, channel_name: str):
        """ì±„ë„ë³„ ê²©ë¦¬ ê²€ìƒ‰ (HyDE + Query Rewriting)"""
        collection = self.get_collection_by_channel(channel_name)
        if not collection:
            return []
        
        print(f"ğŸ” {channel_name} ì±„ë„ ê²€ìƒ‰ ì‹œì‘")
        
        all_results = []
        
        # 1ì°¨: ì›ë³¸ ì§ˆë¬¸
        print(f"  ğŸ“ 1ì°¨ ê²€ìƒ‰: '{query}'")
        results1 = self._single_search_on_collection(collection, query, n_results=3)
        if results1:
            all_results.extend(self._format_results(results1, f"ì›ë³¸ì§ˆë¬¸", channel_name))
        
        # 2ì°¨: HyDE
        hyde_docs = self.generate_hyde_documents(query, channel_name, n_docs=1)
        for hyde_doc in hyde_docs:
            if hyde_doc:
                print(f"  ğŸ¯ HyDE ê²€ìƒ‰")
                hyde_results = self._single_search_on_collection(collection, hyde_doc, n_results=3)
                if hyde_results:
                    all_results.extend(self._format_results(hyde_results, f"HyDE", channel_name))
        
        # 3ì°¨: Query Rewriting
        context_sample = all_results[0]['content'] if all_results else ""
        rewritten_query = self.rewrite_query(query, channel_name, context_sample)
        if rewritten_query != query:
            print(f"  ğŸ”„ Rewritten ê²€ìƒ‰")
            rewritten_results = self._single_search_on_collection(collection, rewritten_query, n_results=3)
            if rewritten_results:
                all_results.extend(self._format_results(rewritten_results, f"Rewritten", channel_name))
        
        # ì¤‘ë³µ ì œê±° ë° ì ìˆ˜ìˆœ ì •ë ¬
        unique_results = self._deduplicate_results(all_results)
        
        # LLM Re-Ranker
        if len(unique_results) > 5:
            candidates = unique_results[:8]
            filtered_results = self._llm_rerank_filter(query, candidates, channel_name)
        else:
            filtered_results = self._llm_rerank_filter(query, unique_results, channel_name)
            if len(filtered_results) < 2:
                print("âš ï¸ LLM í•„í„° ê²°ê³¼ ë¶€ì¡±, ìœ ì‚¬ë„ 0.25+ fallback")
                filtered_results = [r for r in unique_results if r['similarity'] > 0.25]
        
        print(f"ğŸ“Š {channel_name} ê²€ìƒ‰ ì™„ë£Œ: {len(unique_results)} â†’ {len(filtered_results)}")
        
        return filtered_results[:5]

    def _single_search_on_collection(self, collection, query: str, n_results: int = 5):
        """ë‹¨ì¼ ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            results = collection.query(
                query_texts=[query],
                n_results=n_results,
                include=["distances", "metadatas", "documents"]
            )
            return results if results["documents"][0] else None
        except Exception as e:
            print(f"âš ï¸ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return None

    def _format_results(self, results, search_type, channel_name):
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í†µí•© í¬ë§·ìœ¼ë¡œ ë³€í™˜"""
        formatted = []
        for i, (doc, metadata, distance) in enumerate(zip(
            results['documents'][0],
            results['metadatas'][0], 
            results['distances'][0]
        )):
            duration = metadata.get('duration', 'N/A') if metadata else 'N/A'
            
            formatted.append({
                'video_id': metadata.get('video_id', 'unknown') if metadata else 'unknown',
                'title': metadata.get('title', 'Unknown Title') if metadata else 'Unknown Title',
                'content': doc,
                'metadata': metadata if metadata else {},
                'distance': distance,
                'search_type': search_type,
                'similarity': 1 - distance,
                'duration': duration,
                'channel': channel_name
            })
        return formatted

    def _deduplicate_results(self, all_results):
        """video_id ê¸°ì¤€ìœ¼ë¡œ ì¤‘ë³µ ì œê±° ë° ìµœê³  ì ìˆ˜ ìœ ì§€"""
        seen_videos = {}
        for result in all_results:
            video_id = result['video_id']
            if video_id not in seen_videos or result['similarity'] > seen_videos[video_id]['similarity']:
                seen_videos[video_id] = result
        
        return sorted(seen_videos.values(), key=lambda x: x['similarity'], reverse=True)

    def _llm_rerank_filter(self, query: str, candidates: list, channel_name: str):
        """LLM Re-Ranker: ì±„ë„ë³„ ê´€ë ¨ì„± íŒë‹¨"""
        if not candidates:
            return []
        
        try:
            candidate_info = []
            for i, result in enumerate(candidates):
                candidate_info.append(
                    f"ì˜ìƒ {i+1}: {result['title']}\n"
                    f"ë‚´ìš©: {result['content'][:200]}...\n"
                    f"ìœ ì‚¬ë„: {result['similarity']:.3f}"
                )
            
            candidates_text = "\n---\n".join(candidate_info)
            
            prompt = f"""ë‹¹ì‹ ì€ {channel_name} ì±„ë„ì˜ ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ì ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ì ì§ˆë¬¸ì— ê°€ì¥ ë„ì›€ì´ ë  ì´ ì±„ë„ì˜ ì˜ìƒë“¤ì„ ì„ ë³„í•´ì£¼ì„¸ìš”.

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

## {channel_name} ì±„ë„ í›„ë³´ ì˜ìƒë“¤
{candidates_text}

### í‰ê°€ ê¸°ì¤€
1. **{channel_name} ì±„ë„ì˜ ê´€ì **ì—ì„œ ì§ˆë¬¸ê³¼ ì§ì ‘ ê´€ë ¨ëœ ë‚´ìš©
2. **ì´ ì±„ë„ì˜ íˆ¬ì ì² í•™**ê³¼ ì¼ì¹˜í•˜ëŠ” ê°„ì ‘ì  ìœ ìš©ì„±
3. **ì‹¤ìš©ì  ê°€ì¹˜**: êµ¬ì²´ì  ìˆ˜ì¹˜, ì „ëµ, ê²½í—˜ë‹´ í¬í•¨
4. **ì±„ë„ ì¼ê´€ì„±**: ì´ ì±„ë„ì˜ ë‹¤ë¥¸ ì˜ìƒê³¼ ì—°ê²°ë˜ëŠ” ë‚´ìš©

### ì¶œë ¥ í˜•ì‹
ì„ ë³„ëœ ì˜ìƒ ë²ˆí˜¸ë¥¼ ìš°ì„ ìˆœìœ„ëŒ€ë¡œ ë‚˜ì—´í•˜ì„¸ìš”. (ì˜ˆ: 1,3,5,2)
ìµœëŒ€ 5ê°œê¹Œì§€ ì„ íƒí•˜ë˜, ì •ë§ ê´€ë ¨ ì—†ëŠ” ì˜ìƒì€ ì œì™¸í•˜ì„¸ìš”."""

            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ ì»¨í…ì¸  ê´€ë ¨ì„± í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=50,
                temperature=0.1
            )
            
            selection = response.choices[0].message.content.strip()
            print(f"ğŸ¤– {channel_name} LLM ì„ ë³„: {selection}")
            
            try:
                selected_indices = [int(x.strip()) - 1 for x in selection.replace(' ', '').split(',') if x.strip().isdigit()]
                filtered = [candidates[i] for i in selected_indices if 0 <= i < len(candidates)]
                
                if len(filtered) >= 2:
                    return filtered
                else:
                    print("âš ï¸ LLM ì„ ë³„ ê²°ê³¼ ë¶€ì¡±, ìœ ì‚¬ë„ ê¸°ë°˜ fallback")
                    return [r for r in candidates if r['similarity'] > 0.3][:5]
                    
            except Exception:
                print("âš ï¸ LLM ì„ ë³„ íŒŒì‹± ì‹¤íŒ¨, ìœ ì‚¬ë„ ê¸°ë°˜ fallback")
                return [r for r in candidates if r['similarity'] > 0.3][:5]
                
        except Exception as e:
            print(f"âš ï¸ LLM Re-Ranking ì‹¤íŒ¨: {e}")
            return [r for r in candidates if r['similarity'] > 0.3][:5]

    def generate_answer_with_channel_prompt(self, query: str, search_results: list, channel_name: str):
        """ì±„ë„ë³„ í”„ë¡¬í”„íŠ¸ë¥¼ í™œìš©í•œ ë‹µë³€ ìƒì„±"""
        if not search_results:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. {channel_name} ì±„ë„ì—ì„œ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
        
        # ì±„ë„ë³„ í”„ë¡¬í”„íŠ¸ ë¡œë“œ
        channel_prompt = {}
        if self.prompt_manager:
            channel_prompt = self.prompt_manager.get_channel_prompt(channel_name)
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_parts = []
        for i, result in enumerate(search_results):
            title = result['title']
            content_preview = result['content'][:600]
            video_id = result.get('video_id', '')
            context_parts.append(f"[ì˜ìƒ {i+1}] {title}\në‚´ìš©: {content_preview}\nì˜ìƒID: {video_id}")
        
        context = "\n\n".join(context_parts)
        
        # ì±„ë„ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_prompt = channel_prompt.get('system_prompt', '').replace('{{channel_name}}', channel_name)
        if not system_prompt:
            system_prompt = f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."
        
        rules = "\n".join([f"- {rule}" for rule in channel_prompt.get('rules', [])])
        output_format = channel_prompt.get('output_format', {})
        structure = output_format.get('structure', 'ë‹µë³€ â†’ ê·¼ê±° â†’ ìš”ì•½')
        
        final_prompt = f"""{system_prompt}

## ë‹µë³€ ê·œì¹™
{rules}

## ë‹µë³€ êµ¬ì¡°
{structure}

## ê²€ìƒ‰ëœ ì»¨í…ìŠ¤íŠ¸ ({channel_name} ì±„ë„)
{context}

## ì‚¬ìš©ì ì§ˆë¬¸
{query}

ìœ„ ê·œì¹™ê³¼ êµ¬ì¡°ì— ë”°ë¼ {channel_name} ì±„ë„ì˜ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤."},
                    {"role": "user", "content": final_prompt}
                ],
                max_tokens=800,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    def generate_answer(self, query: str, search_results: list, channel_name: str):
        """ê¸°ì¡´ ë‹µë³€ ìƒì„± (í˜¸í™˜ì„± ìœ ì§€)"""
        if self.prompt_manager:
            return self.generate_answer_with_channel_prompt(query, search_results, channel_name)
        
        # í”„ë¡¬í”„íŠ¸ ë§¤ë‹ˆì €ê°€ ì—†ëŠ” ê²½ìš° ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©
        if not search_results:
            return f"ì£„ì†¡í•©ë‹ˆë‹¤. {channel_name} ì±„ë„ì—ì„œ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”."
        
        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_parts = []
        for i, result in enumerate(search_results):
            title = result['title']
            content_preview = result['content'][:800]
            context_parts.append(f"[ì˜ìƒ {i+1}] {title}\n{content_preview}")
        
        context = "\n\n".join(context_parts)
        
        prompt = PROMPT_TEMPLATE.format(
            context=context,
            query=query,
            channel_name=channel_name
        )
        
        try:
            response = self.client.chat.completions.create(
                model=self.model,
                messages=[
                    {"role": "system", "content": f"ë‹¹ì‹ ì€ {channel_name} ì±„ë„ ì „ë¬¸ ì¼ë³¸ ë¶€ë™ì‚° íˆ¬ì AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì´ ì±„ë„ì˜ ì •ë³´ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ì‹¤ìš©ì ì´ê³  êµ¬ì²´ì ì¸ ì¡°ì–¸ì„ ì œê³µí•˜ì„¸ìš”."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=800,
                temperature=0.7
            )
            
            return response.choices[0].message.content.strip()
            
        except Exception as e:
            return f"ë‹µë³€ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {e}"

    def chat(self, query: str, channel_name: str, show_progress: bool = False):
        """ë©”ì¸ ëŒ€í™” í•¨ìˆ˜ - ì±„ë„ë³„ ê²©ë¦¬ ê²€ìƒ‰"""
        if show_progress:
            # ì§„í–‰ ìƒí™© ì¶œë ¥
            import json
            import sys
            import time
            
            # 1. ë²¡í„° ê²€ìƒ‰ ì‹œì‘
            progress_data = {
                "step": "ë²¡í„° ê²€ìƒ‰",
                "message": f"ğŸ” {channel_name} ì±„ë„ì—ì„œ ë²¡í„° ê²€ìƒ‰ ì¤‘...",
                "progress": 10.0,
                "details": f"ì§ˆë¬¸: {query[:50]}..."
            }
            print(f"PROGRESS:{json.dumps(progress_data, ensure_ascii=False)}")
            sys.stdout.flush()
            time.sleep(0.5)
            
        print(f"ğŸ¤” ì§ˆë¬¸: {query}")
        print(f"ğŸ¯ ì±„ë„: {channel_name}")
        
        # ì±„ë„ë³„ ê²€ìƒ‰ ì‹¤í–‰
        search_results = self.channel_search(query, channel_name)
        
        if show_progress:
            # 2. ë‹µë³€ ìƒì„± ì‹œì‘
            progress_data = {
                "step": "ë‹µë³€ ìƒì„±",
                "message": f"ğŸ¤– DeepSeekìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘...",
                "progress": 80.0,
                "details": f"ê²€ìƒ‰ ê²°ê³¼: {len(search_results)}ê°œ"
            }
            print(f"PROGRESS:{json.dumps(progress_data, ensure_ascii=False)}")
            sys.stdout.flush()
            time.sleep(0.5)
        
        if not search_results:
            return f"{channel_name} ì±„ë„ì—ì„œ ê´€ë ¨ëœ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ë‹¤ë¥¸ í‚¤ì›Œë“œë¡œ ì‹œë„í•´ë³´ì„¸ìš”."
        
        # ë‹µë³€ ìƒì„±
        answer = self.generate_answer(query, search_results, channel_name)
        
        if show_progress:
            # 3. ì™„ë£Œ
            progress_data = {
                "step": "ì™„ë£Œ",
                "message": "âœ… ë‹µë³€ ìƒì„± ì™„ë£Œ",
                "progress": 100.0,
                "details": None
            }
            print(f"PROGRESS:{json.dumps(progress_data, ensure_ascii=False)}")
            sys.stdout.flush()
            print("FINAL_ANSWER:")
            sys.stdout.flush()
        
        return answer

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # --model ì˜µì…˜ í™•ì¸
        model = "deepseek-chat"  # ê¸°ë³¸ê°’
        model_index = None
        
        for i, arg in enumerate(sys.argv):
            if arg == "--model" and i + 1 < len(sys.argv):
                model = sys.argv[i + 1]
                model_index = i
                break
        
        # --model ì¸ì ì œê±°
        if model_index is not None:
            sys.argv.pop(model_index + 1)  # ëª¨ë¸ëª… ì œê±°
            sys.argv.pop(model_index)      # --model ì œê±°
        
        rag = ChannelRAG(model=model)
        
        if len(sys.argv) < 2:
            print("ğŸ¤– Y-Data House RAG v6.0 (ì±„ë„ë³„ ì™„ì „ ê²©ë¦¬)")
            print("\nğŸ“‹ ì‚¬ìš©ë²•:")
            print("  python rag.py channels                   # ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ëª©ë¡")
            print("  python rag.py 'ì§ˆë¬¸' ì±„ë„ëª…              # íŠ¹ì • ì±„ë„ì—ì„œ ê²€ìƒ‰")
            print("\nğŸ“š ì˜ˆì‹œ:")
            print("  python rag.py 'ë„ì¿„ íˆ¬ì ì „ëµ' takaki_takehana")
            print("  python rag.py 'ìˆ˜ìµë¥  ì¢‹ì€ ì§€ì—­' ë„ì¿„ë¶€ë™ì‚°")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ í‘œì‹œ
            channels = rag.list_available_channels()
            if channels:
                print(f"\nğŸ“º ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ({len(channels)}ê°œ):")
                for i, ch in enumerate(channels, 1):
                    status = "ğŸ” ê²©ë¦¬ë¨" if ch['isolated'] else "ğŸ“‚ ì¼ë°˜"
                    print(f"  {i}. {ch['name']} ({ch['video_count']}ê°œ ì˜ìƒ) {status}")
            
            return
        
        command = sys.argv[1]
        
        if command == "channels":
            # ì±„ë„ ëª©ë¡ ì¶œë ¥
            channels = rag.list_available_channels()
            if channels:
                print(f"ğŸ“º ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ({len(channels)}ê°œ):")
                for i, ch in enumerate(channels, 1):
                    status = "ğŸ” ê²©ë¦¬ë¨" if ch['isolated'] else "ğŸ“‚ ì¼ë°˜"
                    print(f"  {i}. {ch['name']} ({ch['video_count']}ê°œ ì˜ìƒ) {status}")
            else:
                print("ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤. 'python embed.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
            return
        
        # ì§ˆë¬¸ + ì±„ë„ ì²˜ë¦¬
        if len(sys.argv) < 3:
            print("âŒ ì±„ë„ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            print("ì‚¬ìš©ë²•: python rag.py 'ì§ˆë¬¸' ì±„ë„ëª… [--progress]")
            print("ì˜ˆì‹œ: python rag.py 'ë„ì¿„ íˆ¬ì ì „ëµ' takaki_takehana")
            print("ì˜ˆì‹œ: python rag.py 'ë„ì¿„ íˆ¬ì ì „ëµ' takaki_takehana --progress")
            return
        
        query = command
        channel_name = sys.argv[2]
        
        # --progress ì˜µì…˜ í™•ì¸
        show_progress = "--progress" in sys.argv
        
        # ì±„ë„ ì¡´ì¬ í™•ì¸
        if not rag.get_collection_by_channel(channel_name):
            print(f"âŒ ì±„ë„ '{channel_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
            # ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ì œì•ˆ
            channels = rag.list_available_channels()
            if channels:
                print(f"\nì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„:")
                for ch in channels:
                    print(f"  - {ch['name']}")
            return
        
        # RAG ê²€ìƒ‰ ë° ë‹µë³€ ìƒì„±
        answer = rag.chat(query, channel_name, show_progress)
        
        if not show_progress:
            print(f"\nğŸ¤– **{channel_name} ì±„ë„ ë‹µë³€:**")
        print(answer)
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main() 