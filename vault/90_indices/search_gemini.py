#!/usr/bin/env python3
"""
Gemini ê¸°ë°˜ ê³ ê¸‰ ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ
í†µí•© ê²€ìƒ‰, ì±„ë„ë³„ í•„í„°ë§, ì˜ë¯¸ë¡ ì  ê²€ìƒ‰ ë“± ë‹¤ì–‘í•œ ê²€ìƒ‰ ê¸°ëŠ¥ ì œê³µ

ê¸°ëŠ¥:
1. í†µí•© ê²€ìƒ‰: ëª¨ë“  ì±„ë„ì—ì„œ ê²€ìƒ‰
2. ì±„ë„ë³„ í•„í„°ë§: íŠ¹ì • ì±„ë„ì—ì„œë§Œ ê²€ìƒ‰  
3. ì‹œê°„ í•„í„°ë§: íŠ¹ì • ê¸°ê°„ ì˜ìƒë§Œ ê²€ìƒ‰
4. ìœ ì‚¬ë„ ê¸°ë°˜ ì •ë ¬: ê´€ë ¨ì„± ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
5. ìƒì„¸ ê²°ê³¼ í‘œì‹œ: ì»¨í…ìŠ¤íŠ¸ì™€ í•¨ê»˜ í‘œì‹œ
"""

import sys
import os
from pathlib import Path
import chromadb
from chromadb.config import Settings as ChromaSettings
from local_gemini import LocalGeminiClient
from dotenv import load_dotenv
import argparse
import json
from typing import List, Dict, Optional, Any
import logging
from datetime import datetime
import re
from session_manager import SearchSessionManager, save_search_to_session

# í™˜ê²½ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# ê²½ë¡œ ì„¤ì •
VAULT_ROOT = Path(__file__).parent.parent
CHROMA_GEMINI_PATH = VAULT_ROOT / "90_indices" / "chroma_gemini"

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

class GeminiSearchEngine:
    """Gemini ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ ì—”ì§„"""
    
    def __init__(self):
        self.client = None
        self.collection = None
        self._setup_api()
        self._setup_database()
    
    def _setup_api(self):
        """ë¡œì»¬ Gemini ì„¤ì •"""
        # ë¡œì»¬ gemini ì‚¬ìš©ìœ¼ë¡œ API í‚¤ ë¶ˆí•„ìš”
        logger.info("âœ… ë¡œì»¬ Gemini ì„¤ì • ì™„ë£Œ")
    
    def _setup_database(self):
        """ChromaDB ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •"""
        try:
            self.client = chromadb.PersistentClient(
                path=str(CHROMA_GEMINI_PATH),
                settings=ChromaSettings(anonymized_telemetry=False)
            )
            
            logger.info("âœ… Gemini ê²€ìƒ‰ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì™„ë£Œ (ì±„ë„ë³„ ê²©ë¦¬ ëª¨ë“œ)")
            
        except Exception as e:
            raise ValueError(f"âŒ ê²€ìƒ‰ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}\n'python vault/90_indices/embed_gemini.py'ë¥¼ ë¨¼ì € ì‹¤í–‰í•˜ì„¸ìš”.")
    
    def _get_query_embedding(self, query: str) -> List[float]:
        """ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (ë¡œì»¬ geminiëŠ” ì„ë² ë”© ë¯¸ì§€ì›, OpenAI ì‚¬ìš©)"""
        try:
            # ë¡œì»¬ geminiëŠ” ì„ë² ë”© ì§€ì›í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ OpenAI ì‚¬ìš©
            from openai import OpenAI
            client = OpenAI()
            result = client.embeddings.create(
                model="text-embedding-3-small",
                input=query
            )
            return result.data[0].embedding
        except Exception as e:
            logger.error(f"ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± ì‹¤íŒ¨: {e}")
            return None
    
    def get_collection_by_channel(self, channel_name: str):
        """ì±„ë„ëª…ìœ¼ë¡œ Gemini ì»¬ë ‰ì…˜ ê°€ì ¸ì˜¤ê¸° (DeepSeek ë°©ì‹ê³¼ ë™ì¼)"""
        from embed_gemini import sanitize_collection_name
        collection_name = f"gemini_channel_{sanitize_collection_name(channel_name)}"
        try:
            return self.client.get_collection(collection_name)
        except Exception:
            return None
    
    def search(self, 
               query: str, 
               n_results: int = 10,
               channel_filter: Optional[str] = None,
               year_filter: Optional[str] = None,
               min_similarity: float = 0.0,
               save_to_session: bool = True,
               session_id: Optional[str] = None) -> List[Dict[str, Any]]:
        """ì±„ë„ë³„ ê²©ë¦¬ ê²€ìƒ‰ ì‹¤í–‰"""
        
        logger.info(f"ğŸ” Gemini ê²€ìƒ‰ ì‹œì‘: '{query}'")
        if channel_filter:
            logger.info(f"ğŸ“º ì±„ë„ í•„í„°: {channel_filter}")
        if year_filter:
            logger.info(f"ğŸ“… ì—°ë„ í•„í„°: {year_filter}")
        
        # ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
        query_embedding = self._get_query_embedding(query)
        if query_embedding is None:
            return []
        
        all_results = []
        
        if channel_filter:
            # íŠ¹ì • ì±„ë„ì—ì„œë§Œ ê²€ìƒ‰
            collection = self.get_collection_by_channel(channel_filter)
            if not collection:
                logger.error(f"âŒ ì±„ë„ '{channel_filter}' ì»¬ë ‰ì…˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            results = self._search_in_collection(collection, query_embedding, n_results * 2)
            all_results.extend(results)
            
        else:
            # ëª¨ë“  ì±„ë„ì—ì„œ ê²€ìƒ‰ (ì±„ë„ë³„ ê²©ë¦¬ ìœ ì§€)
            collections = self.client.list_collections()
            gemini_collections = [c for c in collections if c.name.startswith("gemini_channel_")]
            
            if not gemini_collections:
                logger.info("âŒ ê²€ìƒ‰ ê°€ëŠ¥í•œ Gemini ì»¬ë ‰ì…˜ì´ ì—†ìŠµë‹ˆë‹¤.")
                return []
            
            logger.info(f"ğŸ” {len(gemini_collections)}ê°œ ì±„ë„ì—ì„œ ê²€ìƒ‰ ì¤‘...")
            
            for collection in gemini_collections:
                try:
                    results = self._search_in_collection(collection, query_embedding, n_results)
                    all_results.extend(results)
                except Exception as e:
                    logger.warning(f"âš ï¸ {collection.name} ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
                    continue
        
        if not all_results:
            logger.info("âŒ ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        # ìœ ì‚¬ë„ ê¸°ë°˜ ì •ë ¬ ë° í•„í„°ë§
        filtered_results = []
        for result in all_results:
            # ìœ ì‚¬ë„ í•„í„°
            if result['similarity'] < min_similarity:
                continue
            
            # ì—°ë„ í•„í„° (ì±„ë„ í•„í„°ëŠ” ì´ë¯¸ ìœ„ì—ì„œ ì²˜ë¦¬ë¨)
            if year_filter and year_filter not in result.get('video_year', ''):
                continue
            
            # ì¿¼ë¦¬ ê¸°ë°˜ ìŠ¤ë‹ˆí« ìƒì„±
            result['content_snippet'] = self._create_content_snippet(result['content'], query)
            filtered_results.append(result)
        
        # ìœ ì‚¬ë„ ê¸°ì¤€ ì •ë ¬ ë° ì¤‘ë³µ ì œê±°
        unique_results = {}
        for result in filtered_results:
            video_id = result['video_id']
            if video_id not in unique_results or result['similarity'] > unique_results[video_id]['similarity']:
                unique_results[video_id] = result
        
        final_results = sorted(unique_results.values(), key=lambda x: x['similarity'], reverse=True)
        
        # ìˆœìœ„ ì¬ì •ë ¬
        for i, result in enumerate(final_results[:n_results], 1):
            result['rank'] = i
        
        logger.info(f"ğŸ“Š Gemini ê²€ìƒ‰ ì™„ë£Œ: {len(all_results)} â†’ {len(final_results[:n_results])}")
        
        # ì„¸ì…˜ì— ê²€ìƒ‰ ê²°ê³¼ ì €ì¥ (ì˜µì…˜)
        if save_to_session and final_results[:n_results]:
            try:
                search_entry = save_search_to_session(
                    query=query,
                    results=final_results[:n_results],
                    channel_filter=channel_filter,
                    year_filter=year_filter,
                    session_id=session_id
                )
                logger.info(f"ğŸ’¾ ê²€ìƒ‰ ê²°ê³¼ ì„¸ì…˜ ì €ì¥ ì™„ë£Œ: {search_entry['search_id']}")
            except Exception as e:
                logger.warning(f"âš ï¸ ì„¸ì…˜ ì €ì¥ ì‹¤íŒ¨: {e}")
        
        return final_results[:n_results]
    
    def _search_in_collection(self, collection, query_embedding: List[float], n_results: int) -> List[Dict[str, Any]]:
        """ë‹¨ì¼ ì»¬ë ‰ì…˜ì—ì„œ ê²€ìƒ‰ ì‹¤í–‰"""
        try:
            search_results = collection.query(
                query_embeddings=[query_embedding],
                n_results=n_results,
                include=["documents", "metadatas", "distances"]
            )
            
            if not search_results["documents"][0]:
                return []
            
            results = []
            for doc, metadata, distance in zip(
                search_results['documents'][0],
                search_results['metadatas'][0],
                search_results['distances'][0]
            ):
                similarity = 1 - distance
                
                result = {
                    'title': metadata.get('title', 'Unknown'),
                    'channel': metadata.get('channel', 'Unknown'),
                    'upload': metadata.get('upload', ''),
                    'video_year': metadata.get('video_year', ''),
                    'video_id': metadata.get('video_id', ''),
                    'source_url': metadata.get('source_url', ''),
                    'file_path': metadata.get('file_path', ''),
                    'content': doc,
                    'similarity': similarity,
                    'distance': distance,
                    'chunk_info': self._get_chunk_info(metadata),
                    'metadata': metadata
                }
                
                results.append(result)
            
            return results
            
        except Exception as e:
            logger.error(f"ì»¬ë ‰ì…˜ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _create_content_snippet(self, content: str, query: str, snippet_length: int = 400) -> str:
        """ê²€ìƒ‰ì–´ ì£¼ë³€ ì»¨í…ìŠ¤íŠ¸ë¥¼ í¬í•¨í•œ ìŠ¤ë‹ˆí« ìƒì„±"""
        content_lower = content.lower()
        query_lower = query.lower()
        
        # ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ìœ„ì¹˜ ì°¾ê¸°
        query_terms = query_lower.split()
        best_position = 0
        max_matches = 0
        
        # ìœˆë„ìš°ë¥¼ ìŠ¬ë¼ì´ë”©í•˜ë©´ì„œ ê°€ì¥ ë§ì€ ê²€ìƒ‰ì–´ê°€ í¬í•¨ëœ ìœ„ì¹˜ ì°¾ê¸°
        window_size = snippet_length // 2
        for i in range(0, len(content) - window_size, 50):
            window = content_lower[i:i + window_size]
            matches = sum(1 for term in query_terms if term in window)
            if matches > max_matches:
                max_matches = matches
                best_position = i
        
        # ìŠ¤ë‹ˆí« ìƒì„±
        start = max(0, best_position - snippet_length // 4)
        end = min(len(content), start + snippet_length)
        snippet = content[start:end]
        
        # ì•ë’¤ ë§ì¤„ì„í‘œ ì¶”ê°€
        if start > 0:
            snippet = "..." + snippet
        if end < len(content):
            snippet = snippet + "..."
        
        return snippet.strip()
    
    def _get_chunk_info(self, metadata: Dict) -> str:
        """ì²­í¬ ì •ë³´ í¬ë§·íŒ…"""
        chunk_index = metadata.get('chunk_index', 0)
        total_chunks = metadata.get('total_chunks', 1)
        
        if total_chunks > 1:
            return f"ì²­í¬ {chunk_index + 1}/{total_chunks}"
        else:
            return "ì „ì²´"
    
    def get_available_channels(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ëª©ë¡ ë°˜í™˜ (ì±„ë„ë³„ ê²©ë¦¬ ë°©ì‹)"""
        try:
            collections = self.client.list_collections()
            channels = []
            
            for collection in collections:
                if collection.name.startswith("gemini_channel_"):
                    try:
                        data = collection.get()
                        if data['metadatas'] and len(data['metadatas']) > 0:
                            channel_name = data['metadatas'][0].get('channel', 'Unknown')
                            video_count = len(data['ids']) if data['ids'] else 0
                            
                            channels.append({
                                'name': channel_name,
                                'collection_name': collection.name,
                                'video_count': video_count
                            })
                    except Exception:
                        continue
            
            return sorted([ch['name'] for ch in channels])
        except Exception as e:
            logger.error(f"ì±„ë„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_available_years(self) -> List[str]:
        """ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ë„ ëª©ë¡ ë°˜í™˜ (ëª¨ë“  ì±„ë„ì—ì„œ)"""
        try:
            collections = self.client.list_collections()
            years = set()
            
            for collection in collections:
                if collection.name.startswith("gemini_channel_"):
                    try:
                        data = collection.get()
                        for metadata in data['metadatas']:
                            year = metadata.get('video_year', '')
                            if year and year != 'unknown':
                                years.add(year)
                    except Exception:
                        continue
            
            return sorted(list(years), reverse=True)
        except Exception as e:
            logger.error(f"ì—°ë„ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_database_stats(self) -> Dict[str, Any]:
        """ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ ì •ë³´ (ì±„ë„ë³„ ê²©ë¦¬ ë°©ì‹)"""
        try:
            collections = self.client.list_collections()
            gemini_collections = [c for c in collections if c.name.startswith("gemini_channel_")]
            
            total_documents = 0
            total_channels = len(gemini_collections)
            channel_stats = {}
            year_stats = {}
            unique_videos = set()
            
            for collection in gemini_collections:
                try:
                    data = collection.get()
                    if not data['metadatas']:
                        continue
                    
                    channel_name = data['metadatas'][0].get('channel', 'Unknown')
                    channel_docs = len(data['ids'])
                    total_documents += channel_docs
                    channel_stats[channel_name] = channel_docs
                    
                    # ì—°ë„ë³„ í†µê³„ ë° ê³ ìœ  ë¹„ë””ì˜¤ ìˆ˜ì§‘
                    for metadata in data['metadatas']:
                        year = metadata.get('video_year', 'unknown')
                        year_stats[year] = year_stats.get(year, 0) + 1
                        
                        video_id = metadata.get('video_id', '')
                        if video_id:
                            unique_videos.add(video_id)
                            
                except Exception as e:
                    logger.warning(f"ì»¬ë ‰ì…˜ {collection.name} í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
                    continue
            
            return {
                'total_documents': total_documents,
                'unique_videos': len(unique_videos),
                'channels': total_channels,
                'channel_distribution': dict(sorted(channel_stats.items(), key=lambda x: x[1], reverse=True)),
                'year_distribution': dict(sorted(year_stats.items(), key=lambda x: x[0], reverse=True)),
                'embedding_model': 'gemini-text-embedding-004',
                'isolation_mode': True
            }
        except Exception as e:
            logger.error(f"í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}

def print_search_results(results: List[Dict], show_content: bool = False, format_type: str = "detailed"):
    """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…í•˜ì—¬ ì¶œë ¥"""
    if not results:
        print("ğŸ” ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ” ê²€ìƒ‰ ê²°ê³¼: {len(results)}ê°œ ë°œê²¬")
    print("=" * 100)
    
    for result in results:
        if format_type == "simple":
            print(f"{result['rank']}. {result['title']} ({result['channel']}) - ìœ ì‚¬ë„: {result['similarity']:.3f}")
        
        elif format_type == "detailed":
            print(f"\n{result['rank']}. ğŸ“º {result['title']}")
            print(f"   ğŸ  ì±„ë„: {result['channel']}")
            print(f"   ğŸ“… ì—…ë¡œë“œ: {result['upload']} ({result['video_year']})")
            print(f"   ğŸ“Š ìœ ì‚¬ë„: {result['similarity']:.3f}")
            print(f"   ğŸ”— ì²­í¬: {result['chunk_info']}")
            print(f"   ğŸ“ ìŠ¤ë‹ˆí«: {result['content_snippet']}")
            print(f"   ğŸŒ ë§í¬: {result['source_url']}")
            
            if show_content:
                print(f"   ğŸ“„ ì „ì²´ ë‚´ìš©:")
                content_lines = result['content'].split('\n')
                for line in content_lines[:5]:  # ì²˜ìŒ 5ì¤„ë§Œ í‘œì‹œ
                    print(f"      {line}")
                if len(content_lines) > 5:
                    print(f"      ... ({len(content_lines) - 5}ì¤„ ë”)")
            
            print("-" * 80)
        
        elif format_type == "json":
            # JSON í˜•íƒœë¡œ ì¶œë ¥ (APIë‚˜ ìë™í™”ì— ìœ ìš©)
            print(json.dumps(result, ensure_ascii=False, indent=2))

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description="Gemini ê¸°ë°˜ ë²¡í„° ê²€ìƒ‰ ì‹œìŠ¤í…œ")
    
    # ì„œë¸Œì»¤ë§¨ë“œ ì„¤ì •
    subparsers = parser.add_subparsers(dest='command', help='ì‚¬ìš© ê°€ëŠ¥í•œ ëª…ë ¹ì–´')
    
    # ê²€ìƒ‰ ëª…ë ¹ì–´
    search_parser = subparsers.add_parser('search', help='ë²¡í„° ê²€ìƒ‰ ì‹¤í–‰')
    search_parser.add_argument('query', help='ê²€ìƒ‰ì–´')
    search_parser.add_argument('-n', '--num-results', type=int, default=10, help='ê²°ê³¼ ê°œìˆ˜ (ê¸°ë³¸: 10)')
    search_parser.add_argument('-c', '--channel', help='íŠ¹ì • ì±„ë„ì—ì„œë§Œ ê²€ìƒ‰')
    search_parser.add_argument('-y', '--year', help='íŠ¹ì • ì—°ë„ ì˜ìƒë§Œ ê²€ìƒ‰')
    search_parser.add_argument('-s', '--min-similarity', type=float, default=0.0, help='ìµœì†Œ ìœ ì‚¬ë„ (0.0-1.0)')
    search_parser.add_argument('--show-content', action='store_true', help='ì „ì²´ ë‚´ìš© í‘œì‹œ')
    search_parser.add_argument('--format', choices=['simple', 'detailed', 'json'], default='detailed', help='ì¶œë ¥ í˜•ì‹')
    
    # ì±„ë„ ëª©ë¡ ëª…ë ¹ì–´
    subparsers.add_parser('channels', help='ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ëª©ë¡ í‘œì‹œ')
    
    # ì—°ë„ ëª©ë¡ ëª…ë ¹ì–´
    subparsers.add_parser('years', help='ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ë„ ëª©ë¡ í‘œì‹œ')
    
    # í†µê³„ ëª…ë ¹ì–´
    subparsers.add_parser('stats', help='ë°ì´í„°ë² ì´ìŠ¤ í†µê³„ í‘œì‹œ')
    
    args = parser.parse_args()
    
    if not args.command:
        parser.print_help()
        return
    
    try:
        # ê²€ìƒ‰ ì—”ì§„ ì´ˆê¸°í™”
        search_engine = GeminiSearchEngine()
        
        if args.command == 'search':
            # ê²€ìƒ‰ ì‹¤í–‰
            results = search_engine.search(
                query=args.query,
                n_results=args.num_results,
                channel_filter=args.channel,
                year_filter=args.year,
                min_similarity=args.min_similarity,
                save_to_session=True  # ìë™ ì„¸ì…˜ ì €ì¥ í™œì„±í™”
            )
            
            # ê²°ê³¼ ì¶œë ¥
            print_search_results(results, args.show_content, args.format)
            
        elif args.command == 'channels':
            # ì±„ë„ ëª©ë¡ í‘œì‹œ
            channels = search_engine.get_available_channels()
            print(f"\nğŸ“º ì‚¬ìš© ê°€ëŠ¥í•œ ì±„ë„ ({len(channels)}ê°œ):")
            for i, channel in enumerate(channels, 1):
                print(f"  {i}. {channel}")
            
        elif args.command == 'years':
            # ì—°ë„ ëª©ë¡ í‘œì‹œ
            years = search_engine.get_available_years()
            print(f"\nğŸ“… ì‚¬ìš© ê°€ëŠ¥í•œ ì—°ë„ ({len(years)}ê°œ):")
            for year in years:
                print(f"  - {year}")
            
        elif args.command == 'stats':
            # í†µê³„ ì •ë³´ í‘œì‹œ
            stats = search_engine.get_database_stats()
            print(f"\nğŸ“Š Gemini ê²€ìƒ‰ ë°ì´í„°ë² ì´ìŠ¤ í†µê³„:")
            print(f"  ğŸ“„ ì´ ë¬¸ì„œ ìˆ˜: {stats.get('total_documents', 0):,}ê°œ")
            print(f"  ğŸ¬ ê³ ìœ  ë¹„ë””ì˜¤ ìˆ˜: {stats.get('unique_videos', 0):,}ê°œ")
            print(f"  ğŸ“º ì±„ë„ ìˆ˜: {stats.get('channels', 0)}ê°œ")
            print(f"  ğŸ¤– ì„ë² ë”© ëª¨ë¸: {stats.get('embedding_model', 'N/A')}")
            
            # ì±„ë„ë³„ ë¶„í¬
            channel_dist = stats.get('channel_distribution', {})
            if channel_dist:
                print(f"\nğŸ“º ì±„ë„ë³„ ë¬¸ì„œ ë¶„í¬ (ìƒìœ„ 10ê°œ):")
                for i, (channel, count) in enumerate(list(channel_dist.items())[:10], 1):
                    print(f"  {i}. {channel}: {count:,}ê°œ")
            
            # ì—°ë„ë³„ ë¶„í¬
            year_dist = stats.get('year_distribution', {})
            if year_dist:
                print(f"\nğŸ“… ì—°ë„ë³„ ë¬¸ì„œ ë¶„í¬:")
                for year, count in year_dist.items():
                    if year != 'unknown':
                        print(f"  {year}: {count:,}ê°œ")
            
    except Exception as e:
        logger.error(f"âŒ ê²€ìƒ‰ ì—”ì§„ ì˜¤ë¥˜: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()